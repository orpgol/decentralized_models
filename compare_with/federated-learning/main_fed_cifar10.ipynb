{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from utils.options import args_parser\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar\n",
    "from models.Fed import FedAvg\n",
    "from models.test import test_img\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['','--iid','--num_channels','3','--model','cnn','--epochs','100',\n",
    "            '--gpu','0','--num_users','3','--dataset', 'cifar', '--lr','0.01', \n",
    "            '--local_ep','1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = args_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(bs=128, dataset='cifar', epochs=100, frac=0.1, gpu=0, iid=True, kernel_num=9, kernel_sizes='3,4,5', local_bs=10, local_ep=1, lr=0.01, max_pool='True', model='cnn', momentum=0.5, norm='batch_norm', num_channels=3, num_classes=10, num_filters=32, num_users=3, seed=1, split='user', stopping_rounds=10, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classDict = {'plane':0, 'car':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}\n",
    "\n",
    "# Define a function to separate CIFAR classes by class index\n",
    "\n",
    "def get_class_i(x, y, i):\n",
    "    \"\"\"\n",
    "    x: trainset.train_data or testset.test_data\n",
    "    y: trainset.train_labels or testset.test_labels\n",
    "    i: class label, a number between 0 to 9\n",
    "    return: x_i\n",
    "    \"\"\"\n",
    "    # Convert to a numpy array\n",
    "    y = np.array(y)\n",
    "    # Locate position of labels that equal to i\n",
    "    pos_i = np.argwhere(y == i)\n",
    "    # Convert the result into a 1-D list\n",
    "    pos_i = list(pos_i[:,0])\n",
    "    # Collect all data that match the desired label\n",
    "#     x_i = [x[j] for j in pos_i]\n",
    "    \n",
    "    return pos_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(dataset_train):\n",
    "    \n",
    "    frac = int(len(dataset_train.data) * 0.05)\n",
    "    x_reserve = dataset_train.data[:frac]\n",
    "    y_reserve = dataset_train.targets[:frac]\n",
    "    x_train = dataset_train.data[frac:]\n",
    "    y_train = dataset_train.targets[frac:]\n",
    "    \n",
    "    reserved = get_class_i(x_reserve, y_reserve, classDict['plane']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['car']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['bird']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['cat']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['deer']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['dog']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['frog']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['horse']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['ship']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['truck'])\n",
    "\n",
    "    train1 = get_class_i(x_train, y_train, classDict['plane']) \\\n",
    "             +get_class_i(x_train, y_train, classDict['car']) \\\n",
    "             +get_class_i(x_train, y_train, classDict['bird'])\n",
    "\n",
    "    train2 = get_class_i(x_train, y_train, classDict['cat']) \\\n",
    "             +get_class_i(x_train, y_train, classDict['deer']) \\\n",
    "             +get_class_i(x_train, y_train, classDict['dog'])\n",
    "    train3 = get_class_i(x_train, y_train, classDict['frog']) \\\n",
    "             +get_class_i(x_train, y_train, classDict['horse']) \\\n",
    "             +get_class_i(x_train, y_train, classDict['ship']) \\\n",
    "             +get_class_i(x_train, y_train, classDict['truck'])\n",
    "    \n",
    "    dict_users = {0: set(reserved+train3), 1:set(train1), 2:set(train2)}\n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CNNCifar(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Round   0, Average loss 2.001\n",
      "Testing accuracy: 37.00\n",
      "Round   1, Average loss 1.637\n",
      "Testing accuracy: 42.00\n",
      "Round   2, Average loss 1.503\n",
      "Testing accuracy: 45.00\n",
      "Round   3, Average loss 1.412\n",
      "Testing accuracy: 47.00\n",
      "Round   4, Average loss 1.417\n",
      "Testing accuracy: 50.00\n",
      "Round   5, Average loss 1.295\n",
      "Testing accuracy: 50.00\n",
      "Round   6, Average loss 1.306\n",
      "Testing accuracy: 52.00\n",
      "Round   7, Average loss 1.199\n",
      "Testing accuracy: 54.00\n",
      "Round   8, Average loss 1.215\n",
      "Testing accuracy: 57.00\n",
      "Round   9, Average loss 1.131\n",
      "Testing accuracy: 55.00\n",
      "Round  10, Average loss 1.053\n",
      "Testing accuracy: 55.00\n",
      "Round  11, Average loss 1.204\n",
      "Testing accuracy: 57.00\n",
      "Round  12, Average loss 1.126\n",
      "Testing accuracy: 58.00\n",
      "Round  13, Average loss 1.021\n",
      "Testing accuracy: 58.00\n",
      "Round  14, Average loss 1.110\n",
      "Testing accuracy: 59.00\n",
      "Round  15, Average loss 1.056\n",
      "Testing accuracy: 59.00\n",
      "Round  16, Average loss 1.028\n",
      "Testing accuracy: 59.00\n",
      "Round  17, Average loss 0.993\n",
      "Testing accuracy: 59.00\n",
      "Round  18, Average loss 0.977\n",
      "Testing accuracy: 60.00\n",
      "Round  19, Average loss 0.942\n",
      "Testing accuracy: 60.00\n",
      "Round  20, Average loss 0.861\n",
      "Testing accuracy: 59.00\n",
      "Round  21, Average loss 0.808\n",
      "Testing accuracy: 59.00\n",
      "Round  22, Average loss 0.985\n",
      "Testing accuracy: 59.00\n",
      "Round  23, Average loss 1.044\n",
      "Testing accuracy: 61.00\n",
      "Round  24, Average loss 0.803\n",
      "Testing accuracy: 60.00\n",
      "Round  25, Average loss 0.909\n",
      "Testing accuracy: 61.00\n",
      "Round  26, Average loss 0.779\n",
      "Testing accuracy: 60.00\n",
      "Round  27, Average loss 1.004\n",
      "Testing accuracy: 60.00\n",
      "Round  28, Average loss 0.806\n",
      "Testing accuracy: 60.00\n",
      "Round  29, Average loss 0.798\n",
      "Testing accuracy: 58.00\n",
      "Round  30, Average loss 0.670\n",
      "Testing accuracy: 58.00\n",
      "Round  31, Average loss 0.604\n",
      "Testing accuracy: 60.00\n",
      "Round  32, Average loss 0.545\n",
      "Testing accuracy: 59.00\n",
      "Round  33, Average loss 0.877\n",
      "Testing accuracy: 59.00\n",
      "Round  34, Average loss 1.006\n",
      "Testing accuracy: 61.00\n",
      "Round  35, Average loss 0.632\n",
      "Testing accuracy: 60.00\n",
      "Round  36, Average loss 0.502\n",
      "Testing accuracy: 60.00\n",
      "Round  37, Average loss 0.442\n",
      "Testing accuracy: 59.00\n",
      "Round  38, Average loss 1.030\n",
      "Testing accuracy: 60.00\n",
      "Round  39, Average loss 0.855\n",
      "Testing accuracy: 61.00\n",
      "Round  40, Average loss 0.867\n",
      "Testing accuracy: 61.00\n",
      "Round  41, Average loss 0.566\n",
      "Testing accuracy: 59.00\n",
      "Round  42, Average loss 0.431\n",
      "Testing accuracy: 59.00\n",
      "Round  43, Average loss 0.897\n",
      "Testing accuracy: 59.00\n",
      "Round  44, Average loss 0.457\n",
      "Testing accuracy: 59.00\n",
      "Round  45, Average loss 0.823\n",
      "Testing accuracy: 57.00\n",
      "Round  46, Average loss 0.454\n",
      "Testing accuracy: 60.00\n",
      "Round  47, Average loss 0.761\n",
      "Testing accuracy: 59.00\n",
      "Round  48, Average loss 0.906\n",
      "Testing accuracy: 60.00\n",
      "Round  49, Average loss 0.512\n",
      "Testing accuracy: 61.00\n",
      "Round  50, Average loss 0.806\n",
      "Testing accuracy: 60.00\n",
      "Round  51, Average loss 0.667\n",
      "Testing accuracy: 60.00\n",
      "Round  52, Average loss 0.807\n",
      "Testing accuracy: 60.00\n",
      "Round  53, Average loss 0.644\n",
      "Testing accuracy: 60.00\n",
      "Round  54, Average loss 0.600\n",
      "Testing accuracy: 60.00\n",
      "Round  55, Average loss 0.726\n",
      "Testing accuracy: 61.00\n",
      "Round  56, Average loss 0.696\n",
      "Testing accuracy: 60.00\n",
      "Round  57, Average loss 0.548\n",
      "Testing accuracy: 59.00\n",
      "Round  58, Average loss 0.383\n",
      "Testing accuracy: 60.00\n",
      "Round  59, Average loss 0.761\n",
      "Testing accuracy: 59.00\n",
      "Round  60, Average loss 0.443\n",
      "Testing accuracy: 60.00\n",
      "Round  61, Average loss 0.341\n",
      "Testing accuracy: 59.00\n",
      "Round  62, Average loss 0.294\n",
      "Testing accuracy: 59.00\n",
      "Round  63, Average loss 0.282\n",
      "Testing accuracy: 58.00\n",
      "Round  64, Average loss 0.847\n",
      "Testing accuracy: 57.00\n",
      "Round  65, Average loss 0.632\n",
      "Testing accuracy: 59.00\n",
      "Round  66, Average loss 0.879\n",
      "Testing accuracy: 59.00\n",
      "Round  67, Average loss 0.592\n",
      "Testing accuracy: 59.00\n",
      "Round  68, Average loss 0.517\n",
      "Testing accuracy: 58.00\n",
      "Round  69, Average loss 0.471\n",
      "Testing accuracy: 59.00\n",
      "Round  70, Average loss 0.634\n",
      "Testing accuracy: 58.00\n",
      "Round  71, Average loss 0.884\n",
      "Testing accuracy: 59.00\n",
      "Round  72, Average loss 0.673\n",
      "Testing accuracy: 59.00\n",
      "Round  73, Average loss 0.511\n",
      "Testing accuracy: 60.00\n",
      "Round  74, Average loss 0.346\n",
      "Testing accuracy: 58.00\n",
      "Round  75, Average loss 0.671\n",
      "Testing accuracy: 57.00\n",
      "Round  76, Average loss 0.508\n",
      "Testing accuracy: 59.00\n",
      "Round  77, Average loss 0.445\n",
      "Testing accuracy: 58.00\n",
      "Round  78, Average loss 0.577\n",
      "Testing accuracy: 58.00\n",
      "Round  79, Average loss 0.383\n",
      "Testing accuracy: 58.00\n",
      "Round  80, Average loss 0.318\n",
      "Testing accuracy: 58.00\n",
      "Round  81, Average loss 0.303\n",
      "Testing accuracy: 59.00\n",
      "Round  82, Average loss 0.692\n",
      "Testing accuracy: 57.00\n",
      "Round  83, Average loss 0.931\n",
      "Testing accuracy: 57.00\n",
      "Round  84, Average loss 0.524\n",
      "Testing accuracy: 59.00\n",
      "Round  85, Average loss 0.441\n",
      "Testing accuracy: 58.00\n",
      "Round  86, Average loss 0.534\n",
      "Testing accuracy: 58.00\n",
      "Round  87, Average loss 0.345\n",
      "Testing accuracy: 58.00\n",
      "Round  88, Average loss 0.542\n",
      "Testing accuracy: 59.00\n",
      "Round  89, Average loss 0.413\n",
      "Testing accuracy: 57.00\n",
      "Round  90, Average loss 0.539\n",
      "Testing accuracy: 58.00\n",
      "Round  91, Average loss 0.959\n",
      "Testing accuracy: 57.00\n",
      "Round  92, Average loss 0.421\n",
      "Testing accuracy: 59.00\n",
      "Round  93, Average loss 0.835\n",
      "Testing accuracy: 58.00\n",
      "Round  94, Average loss 0.342\n",
      "Testing accuracy: 59.00\n",
      "Round  95, Average loss 0.574\n",
      "Testing accuracy: 58.00\n",
      "Round  96, Average loss 0.420\n",
      "Testing accuracy: 59.00\n",
      "Round  97, Average loss 0.864\n",
      "Testing accuracy: 58.00\n",
      "Round  98, Average loss 0.449\n",
      "Testing accuracy: 58.00\n",
      "Round  99, Average loss 0.525\n",
      "Testing accuracy: 59.00\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    writer = SummaryWriter('runs/') \n",
    "    \n",
    "    # parse args\n",
    "    args = args_parser()\n",
    "    args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "\n",
    "    # load dataset and split users\n",
    "    if args.dataset == 'mnist':\n",
    "        trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset_train = datasets.MNIST('../data/mnist/', train=True, download=True, transform=trans_mnist)\n",
    "        dataset_test = datasets.MNIST('../data/mnist/', train=False, download=True, transform=trans_mnist)\n",
    "        # sample users\n",
    "        if args.iid:\n",
    "            dict_users = mnist_iid(dataset_train, args.num_users)\n",
    "        else:\n",
    "            dict_users = mnist_noniid(dataset_train, args.num_users)\n",
    "    elif args.dataset == 'cifar':\n",
    "        trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        dataset_train = datasets.CIFAR10('../data/cifar', train=True, download=True, transform=trans_cifar)\n",
    "        dataset_test = datasets.CIFAR10('../data/cifar', train=False, download=True, transform=trans_cifar)\n",
    "        if args.iid:\n",
    "#             dict_users = cifar_iid(dataset_train, args.num_users)\n",
    "            dict_users = create_dict(dataset_train)\n",
    "        else:\n",
    "            exit('Error: only consider IID setting in CIFAR10')\n",
    "    else:\n",
    "        exit('Error: unrecognized dataset')\n",
    "    img_size = dataset_train[0][0].shape\n",
    "\n",
    "    # build model\n",
    "    if args.model == 'cnn' and args.dataset == 'cifar':\n",
    "        net_glob = CNNCifar(args=args).to(args.device)\n",
    "    elif args.model == 'resnet' and args.dataset == 'cifar':\n",
    "        net_glob = models.resnet18(pretrained=True)\n",
    "        num_ftrs = net_glob.fc.in_features\n",
    "        net_glob.fc = torch.nn.Linear(num_ftrs, 10)\n",
    "        net_glob.to(args.device)\n",
    "    elif args.model == 'cnn' and args.dataset == 'mnist':\n",
    "        net_glob = CNNMnist(args=args).to(args.device)\n",
    "    elif args.model == 'mlp':\n",
    "        len_in = 1\n",
    "        for x in img_size:\n",
    "            len_in *= x\n",
    "        net_glob = MLP(dim_in=len_in, dim_hidden=200, dim_out=args.num_classes).to(args.device)\n",
    "    else:\n",
    "        exit('Error: unrecognized model')\n",
    "    print(net_glob)\n",
    "    net_glob.train()\n",
    "\n",
    "    # copy weights\n",
    "    w_glob = net_glob.state_dict()\n",
    "\n",
    "    # training\n",
    "    loss_train = []\n",
    "    cv_loss, cv_acc = [], []\n",
    "    val_loss_pre, counter = 0, 0\n",
    "    net_best = None\n",
    "    best_loss = None\n",
    "    val_acc_list, net_list = [], []\n",
    "\n",
    "    for iter in range(args.epochs):\n",
    "        w_locals, loss_locals = [], []\n",
    "        m = max(int(args.frac * args.num_users), 1)\n",
    "        idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "        for idx in idxs_users:\n",
    "            local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "            w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "            w_locals.append(copy.deepcopy(w))\n",
    "            loss_locals.append(copy.deepcopy(loss))\n",
    "        # update global weights\n",
    "        w_glob = FedAvg(w_locals)\n",
    "\n",
    "        # copy weight to net_glob\n",
    "        net_glob.load_state_dict(w_glob)\n",
    "\n",
    "        # print loss\n",
    "        loss_avg = sum(loss_locals) / len(loss_locals)\n",
    "        print('Round {:3d}, Average loss {:.3f}'.format(iter, loss_avg))\n",
    "        loss_train.append(loss_avg)\n",
    "        \n",
    "        # testing\n",
    "        net_glob.eval()\n",
    "        acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "        print(\"Testing accuracy: {:.2f}\".format(acc_test))\n",
    "\n",
    "        writer.add_scalar('train/loss_federated', loss_avg, iter)\n",
    "        writer.add_scalar('valid/accuracy_federated', acc_test.data.numpy()/100., iter)\n",
    "        \n",
    "        net_glob.train()\n",
    "\n",
    "    # plot loss curve\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(loss_train)), loss_train)\n",
    "    plt.ylabel('train_loss')\n",
    "    plt.savefig('./save/fed_{}_{}_{}_C{}_iid{}.png'.format(args.dataset, args.model, args.epochs, args.frac, args.iid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
