{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from utils.options import args_parser\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar\n",
    "from models.Fed import FedAvg\n",
    "from models.test import test_img\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['','--iid','--num_channels','3','--model','cnn','--epochs','70',\n",
    "            '--gpu','0','--num_users','3','--dataset', 'cifar', '--lr','0.01', \n",
    "            '--local_ep','1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = args_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(bs=128, dataset='cifar', epochs=70, frac=0.1, gpu=0, iid=True, kernel_num=9, kernel_sizes='3,4,5', local_bs=10, local_ep=1, lr=0.01, max_pool='True', model='cnn', momentum=0.5, norm='batch_norm', num_channels=3, num_classes=10, num_filters=32, num_users=3, seed=1, split='user', stopping_rounds=10, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classDict = {'plane':0, 'car':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}\n",
    "\n",
    "# Define a function to separate CIFAR classes by class index\n",
    "\n",
    "def get_class_i(x, y, i):\n",
    "    \"\"\"\n",
    "    x: trainset.train_data or testset.test_data\n",
    "    y: trainset.train_labels or testset.test_labels\n",
    "    i: class label, a number between 0 to 9\n",
    "    return: x_i\n",
    "    \"\"\"\n",
    "    # Convert to a numpy array\n",
    "    y = np.array(y)\n",
    "    # Locate position of labels that equal to i\n",
    "    pos_i = np.argwhere(y == i)\n",
    "    # Convert the result into a 1-D list\n",
    "    pos_i = list(pos_i[:,0])\n",
    "    # Collect all data that match the desired label\n",
    "#     x_i = [x[j] for j in pos_i]\n",
    "    \n",
    "    return pos_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(dataset_train):\n",
    "    \n",
    "    frac = int(len(dataset_train.data) * 0.05)\n",
    "    x_reserve = dataset_train.data[:frac]\n",
    "    y_reserve = dataset_train.targets[:frac]\n",
    "    x_train = dataset_train.data[frac:]\n",
    "    y_train = dataset_train.targets[frac:]\n",
    "    \n",
    "    reserved = get_class_i(x_reserve, y_reserve, classDict['plane']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['car']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['bird']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['cat']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['deer']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['dog']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['frog']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['horse']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['ship']) \\\n",
    "               +get_class_i(x_reserve, y_reserve, classDict['truck'])\n",
    "\n",
    "    train1 = get_class_i(x_train, y_train, classDict['plane']) \\\n",
    "             +get_class_i(x_train, y_train, classDict['car']) \\\n",
    "             +get_class_i(x_train, y_train, classDict['bird'])\n",
    "\n",
    "    train2 = get_class_i(x_train, y_train, classDict['cat']) \\\n",
    "             +get_class_i(x_train, y_train, classDict['deer']) \\\n",
    "             +get_class_i(x_train, y_train, classDict['dog'])\n",
    "    train3 = get_class_i(x_train, y_train, classDict['frog']) \\\n",
    "             +get_class_i(x_train, y_train, classDict['horse']) \\\n",
    "             +get_class_i(x_train, y_train, classDict['ship']) \\\n",
    "             +get_class_i(x_train, y_train, classDict['truck'])\n",
    "    \n",
    "    dict_users = {0: set(reserved+train3), 1:set(train1), 2:set(train2)}\n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CNNCifar(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Round   0, Average loss 2.104\n",
      "Testing accuracy: 34.00\n",
      "Round   1, Average loss 1.676\n",
      "Testing accuracy: 45.00\n",
      "Round   2, Average loss 1.517\n",
      "Testing accuracy: 49.00\n",
      "Round   3, Average loss 1.421\n",
      "Testing accuracy: 51.00\n",
      "Round   4, Average loss 1.350\n",
      "Testing accuracy: 54.00\n",
      "Round   5, Average loss 1.286\n",
      "Testing accuracy: 56.00\n",
      "Round   6, Average loss 1.229\n",
      "Testing accuracy: 58.00\n",
      "Round   7, Average loss 1.180\n",
      "Testing accuracy: 59.00\n",
      "Round   8, Average loss 1.139\n",
      "Testing accuracy: 60.00\n",
      "Round   9, Average loss 1.103\n",
      "Testing accuracy: 61.00\n",
      "Round  10, Average loss 1.062\n",
      "Testing accuracy: 62.00\n",
      "Round  11, Average loss 1.030\n",
      "Testing accuracy: 62.00\n",
      "Round  12, Average loss 0.997\n",
      "Testing accuracy: 63.00\n",
      "Round  13, Average loss 0.972\n",
      "Testing accuracy: 63.00\n",
      "Round  14, Average loss 0.940\n",
      "Testing accuracy: 63.00\n",
      "Round  15, Average loss 0.918\n",
      "Testing accuracy: 64.00\n",
      "Round  16, Average loss 0.896\n",
      "Testing accuracy: 63.00\n",
      "Round  17, Average loss 0.872\n",
      "Testing accuracy: 64.00\n",
      "Round  18, Average loss 0.854\n",
      "Testing accuracy: 64.00\n",
      "Round  19, Average loss 0.836\n",
      "Testing accuracy: 64.00\n",
      "Round  20, Average loss 0.815\n",
      "Testing accuracy: 64.00\n",
      "Round  21, Average loss 0.801\n",
      "Testing accuracy: 64.00\n",
      "Round  22, Average loss 0.779\n",
      "Testing accuracy: 64.00\n",
      "Round  23, Average loss 0.761\n",
      "Testing accuracy: 64.00\n",
      "Round  24, Average loss 0.749\n",
      "Testing accuracy: 63.00\n",
      "Round  25, Average loss 0.736\n",
      "Testing accuracy: 64.00\n",
      "Round  26, Average loss 0.718\n",
      "Testing accuracy: 63.00\n",
      "Round  27, Average loss 0.703\n",
      "Testing accuracy: 63.00\n",
      "Round  28, Average loss 0.691\n",
      "Testing accuracy: 63.00\n",
      "Round  29, Average loss 0.679\n",
      "Testing accuracy: 63.00\n",
      "Round  30, Average loss 0.666\n",
      "Testing accuracy: 63.00\n",
      "Round  31, Average loss 0.653\n",
      "Testing accuracy: 63.00\n",
      "Round  32, Average loss 0.643\n",
      "Testing accuracy: 64.00\n",
      "Round  33, Average loss 0.626\n",
      "Testing accuracy: 63.00\n",
      "Round  34, Average loss 0.616\n",
      "Testing accuracy: 62.00\n",
      "Round  35, Average loss 0.612\n",
      "Testing accuracy: 63.00\n",
      "Round  36, Average loss 0.597\n",
      "Testing accuracy: 63.00\n",
      "Round  37, Average loss 0.592\n",
      "Testing accuracy: 62.00\n",
      "Round  38, Average loss 0.582\n",
      "Testing accuracy: 62.00\n",
      "Round  39, Average loss 0.571\n",
      "Testing accuracy: 63.00\n",
      "Round  40, Average loss 0.565\n",
      "Testing accuracy: 62.00\n",
      "Round  41, Average loss 0.556\n",
      "Testing accuracy: 62.00\n",
      "Round  42, Average loss 0.553\n",
      "Testing accuracy: 62.00\n",
      "Round  43, Average loss 0.542\n",
      "Testing accuracy: 62.00\n",
      "Round  44, Average loss 0.536\n",
      "Testing accuracy: 62.00\n",
      "Round  45, Average loss 0.523\n",
      "Testing accuracy: 62.00\n",
      "Round  46, Average loss 0.520\n",
      "Testing accuracy: 61.00\n",
      "Round  47, Average loss 0.522\n",
      "Testing accuracy: 62.00\n",
      "Round  48, Average loss 0.516\n",
      "Testing accuracy: 61.00\n",
      "Round  49, Average loss 0.506\n",
      "Testing accuracy: 61.00\n",
      "Round  50, Average loss 0.499\n",
      "Testing accuracy: 62.00\n",
      "Round  51, Average loss 0.490\n",
      "Testing accuracy: 62.00\n",
      "Round  52, Average loss 0.488\n",
      "Testing accuracy: 61.00\n",
      "Round  53, Average loss 0.480\n",
      "Testing accuracy: 61.00\n",
      "Round  54, Average loss 0.472\n",
      "Testing accuracy: 61.00\n",
      "Round  55, Average loss 0.471\n",
      "Testing accuracy: 61.00\n",
      "Round  56, Average loss 0.477\n",
      "Testing accuracy: 61.00\n",
      "Round  57, Average loss 0.466\n",
      "Testing accuracy: 61.00\n",
      "Round  58, Average loss 0.462\n",
      "Testing accuracy: 61.00\n",
      "Round  59, Average loss 0.466\n",
      "Testing accuracy: 61.00\n",
      "Round  60, Average loss 0.462\n",
      "Testing accuracy: 61.00\n",
      "Round  61, Average loss 0.450\n",
      "Testing accuracy: 61.00\n",
      "Round  62, Average loss 0.453\n",
      "Testing accuracy: 61.00\n",
      "Round  63, Average loss 0.435\n",
      "Testing accuracy: 61.00\n",
      "Round  64, Average loss 0.442\n",
      "Testing accuracy: 61.00\n",
      "Round  65, Average loss 0.435\n",
      "Testing accuracy: 61.00\n",
      "Round  66, Average loss 0.430\n",
      "Testing accuracy: 61.00\n",
      "Round  67, Average loss 0.427\n",
      "Testing accuracy: 61.00\n",
      "Round  68, Average loss 0.434\n",
      "Testing accuracy: 60.00\n",
      "Round  69, Average loss 0.420\n",
      "Testing accuracy: 60.00\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    writer = SummaryWriter('../../runs/') \n",
    "    \n",
    "    # parse args\n",
    "    args = args_parser()\n",
    "    args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "\n",
    "    # load dataset and split users\n",
    "    if args.dataset == 'mnist':\n",
    "        trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset_train = datasets.MNIST('../data/mnist/', train=True, download=True, transform=trans_mnist)\n",
    "        dataset_test = datasets.MNIST('../data/mnist/', train=False, download=True, transform=trans_mnist)\n",
    "        # sample users\n",
    "        if args.iid:\n",
    "            dict_users = mnist_iid(dataset_train, args.num_users)\n",
    "        else:\n",
    "            dict_users = mnist_noniid(dataset_train, args.num_users)\n",
    "    elif args.dataset == 'cifar':\n",
    "        trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        dataset_train = datasets.CIFAR10('../data/cifar', train=True, download=True, transform=trans_cifar)\n",
    "        dataset_test = datasets.CIFAR10('../data/cifar', train=False, download=True, transform=trans_cifar)\n",
    "        if args.iid:\n",
    "#             dict_users = cifar_iid(dataset_train, args.num_users)\n",
    "            dict_users = create_dict(dataset_train)\n",
    "        else:\n",
    "            exit('Error: only consider IID setting in CIFAR10')\n",
    "    else:\n",
    "        exit('Error: unrecognized dataset')\n",
    "    img_size = dataset_train[0][0].shape\n",
    "\n",
    "    # build model\n",
    "    if args.model == 'cnn' and args.dataset == 'cifar':\n",
    "        net_glob = CNNCifar(args=args).to(args.device)\n",
    "    elif args.model == 'resnet' and args.dataset == 'cifar':\n",
    "        net_glob = models.resnet18(pretrained=True)\n",
    "        num_ftrs = net_glob.fc.in_features\n",
    "        net_glob.fc = torch.nn.Linear(num_ftrs, 10)\n",
    "        net_glob.to(args.device)\n",
    "    elif args.model == 'cnn' and args.dataset == 'mnist':\n",
    "        net_glob = CNNMnist(args=args).to(args.device)\n",
    "    elif args.model == 'mlp':\n",
    "        len_in = 1\n",
    "        for x in img_size:\n",
    "            len_in *= x\n",
    "        net_glob = MLP(dim_in=len_in, dim_hidden=200, dim_out=args.num_classes).to(args.device)\n",
    "    else:\n",
    "        exit('Error: unrecognized model')\n",
    "    print(net_glob)\n",
    "    net_glob.train()\n",
    "\n",
    "    # copy weights\n",
    "    w_glob = net_glob.state_dict()\n",
    "\n",
    "    # training\n",
    "    loss_train = []\n",
    "    cv_loss, cv_acc = [], []\n",
    "    val_loss_pre, counter = 0, 0\n",
    "    net_best = None\n",
    "    best_loss = None\n",
    "    val_acc_list, net_list = [], []\n",
    "\n",
    "    for iter in range(args.epochs):\n",
    "        w_locals, loss_locals = [], []\n",
    "        m = max(int(args.frac * args.num_users), 3)\n",
    "        idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "        for idx in idxs_users:\n",
    "            local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "            w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "            w_locals.append(copy.deepcopy(w))\n",
    "            loss_locals.append(copy.deepcopy(loss))\n",
    "        # update global weights\n",
    "        w_glob = FedAvg(w_locals)\n",
    "\n",
    "        # copy weight to net_glob\n",
    "        net_glob.load_state_dict(w_glob)\n",
    "\n",
    "        # print loss\n",
    "        loss_avg = sum(loss_locals) / len(loss_locals)\n",
    "        print('Round {:3d}, Average loss {:.3f}'.format(iter, loss_avg))\n",
    "        loss_train.append(loss_avg)\n",
    "        \n",
    "        # testing\n",
    "        net_glob.eval()\n",
    "        acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "        print(\"Testing accuracy: {:.2f}\".format(acc_test))\n",
    "\n",
    "        writer.add_scalar('train/loss_federated2', loss_avg, iter)\n",
    "        writer.add_scalar('valid/accuracy_federated2', acc_test.data.numpy()/100., iter)\n",
    "        \n",
    "        net_glob.train()\n",
    "\n",
    "    # plot loss curve\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(loss_train)), loss_train)\n",
    "    plt.ylabel('train_loss')\n",
    "    plt.savefig('./save/fed_{}_{}_{}_C{}_iid{}.png'.format(args.dataset, args.model, args.epochs, args.frac, args.iid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "confusion_matrix = torch.zeros(10, 10)\n",
    "net_glob.eval()\n",
    "# testing\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "data_loader = DataLoader(dataset_test, batch_size=args.bs)\n",
    "l = len(data_loader)\n",
    "for idx, (data, target) in enumerate(data_loader):\n",
    "    if args.gpu != -1:\n",
    "        data, target = data.to(args.device), target.to(args.device)\n",
    "    log_probs = net_glob(data)\n",
    "    # sum up batch loss\n",
    "    test_loss += F.cross_entropy(log_probs, target, reduction='sum').item()\n",
    "    # get the index of the max log-probability\n",
    "    y_pred = log_probs.data.max(1, keepdim=True)[1]\n",
    "    correct += y_pred.eq(target.data.view_as(y_pred)).long().cpu().sum()\n",
    "\n",
    "    for t, p in zip(target.data, y_pred.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[588.,  43.,  61.,  44.,  42.,  15.,  14.,  16., 111.,  66.],\n",
      "        [ 15., 791.,   7.,  10.,   5.,  13.,   9.,  14.,  36., 100.],\n",
      "        [ 58.,   5., 467., 112., 105.,  90.,  61.,  55.,  36.,  11.],\n",
      "        [ 27.,  13.,  74., 435.,  88., 182.,  71.,  62.,  20.,  28.],\n",
      "        [ 22.,   7., 117., 102., 507.,  69.,  51.,  90.,  23.,  12.],\n",
      "        [ 19.,   5.,  60., 253.,  60., 475.,  28.,  75.,  13.,  12.],\n",
      "        [  5.,  13.,  72.,  99.,  63.,  51., 659.,  13.,  11.,  14.],\n",
      "        [ 21.,   6.,  33.,  76.,  76.,  80.,  11., 663.,   7.,  27.],\n",
      "        [ 61.,  49.,  15.,  29.,  18.,  12.,   7.,   9., 763.,  37.],\n",
      "        [ 30., 116.,  10.,  40.,  12.,  13.,  15.,  18.,  54., 692.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
