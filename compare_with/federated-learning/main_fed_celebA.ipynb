{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from utils.options import args_parser\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar\n",
    "from models.Fed import FedAvg\n",
    "from models.test import test_img\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['','--num_channels','3','--model','resnet','--epochs','60',\n",
    "            '--gpu','2','--num_users','3','--dataset', 'cifar', '--lr','0.01', \n",
    "            '--local_ep','1', '--bs', '32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = args_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(bs=32, dataset='cifar', epochs=60, frac=0.1, gpu=2, iid=False, kernel_num=9, kernel_sizes='3,4,5', local_bs=10, local_ep=1, lr=0.1, max_pool='True', model='resnet', momentum=0.5, norm='batch_norm', num_channels=3, num_classes=10, num_filters=32, num_users=3, seed=1, split='user', stopping_rounds=10, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, main_dir, x, y, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        self.y = y\n",
    "        self.all_imgs = x\n",
    "#         self.total_imgs = natsort.natsorted(all_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.all_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image,self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classDict = {'not_smiling':0, 'smiling':1}\n",
    "\n",
    "# Define a function to separate CIFAR classes by class index\n",
    "\n",
    "def get_class_i(x, y, i):\n",
    "    \"\"\"\n",
    "    x: trainset.train_data or testset.test_data\n",
    "    y: trainset.train_labels or testset.test_labels\n",
    "    i: class label, a number between 0 to 9\n",
    "    return: x_i\n",
    "    \"\"\"\n",
    "    # Convert to a numpy array\n",
    "    y = np.array(y)\n",
    "    # Locate position of labels that equal to i\n",
    "    pos_i = np.argwhere(y == i)\n",
    "    # Convert the result into a 1-D list\n",
    "    pos_i = list(pos_i[:,0])\n",
    "    # Collect all data that match the desired label\n",
    "#     x_i = [x[j] for j in pos_i]\n",
    "    \n",
    "    return pos_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Standard transformations for improving celebA. \n",
    "# Transformations A\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop((218,178), padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Transformations B\n",
    "RC   = transforms.RandomCrop((218,178), padding=4)\n",
    "RHF  = transforms.RandomHorizontalFlip()\n",
    "RVF  = transforms.RandomVerticalFlip()\n",
    "NRM  = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "TT   = transforms.ToTensor()\n",
    "TPIL = transforms.ToPILImage()\n",
    "\n",
    "# Transforms object for trainset with augmentation\n",
    "transform_with_aug = transforms.Compose([RC, RHF, TT, NRM])\n",
    "# Transforms object for testset with NO augmentation\n",
    "transform_no_aug   = transforms.Compose([TT, NRM])\n",
    "\n",
    "# Downloading/Louding CELEBA data\n",
    "trainset = torchvision.datasets.CelebA(root='../../../data/celebA', split = 'train',\n",
    "                                        download=True, transform=transform_with_aug)\n",
    "\n",
    "testset = torchvision.datasets.CelebA(root='../../../data/celebA', split='test',\n",
    "                                       download=True, transform=transform_no_aug)\n",
    "\n",
    "classDict = {'not_smiling':0, 'smiling':1}\n",
    "\n",
    "# Separating trainset/testset data/label\n",
    "x_train  = trainset\n",
    "x_test   = testset\n",
    "y_train  = trainset.attr[:,31] ## 31 is smile\n",
    "y_test   = testset.attr[:,31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test):\n",
    "    # If we are saving a fraction of random data to be used in training\n",
    "    frac1 = int(len(x_test) * 0.316666666667)\n",
    "    frac2 = int(len(x_test) * 0.633333333333)\n",
    "\n",
    "    x_train1 = list(range(0,frac1))\n",
    "    x_train2 = list(range(frac1,frac2))\n",
    "    x_train3 = list(range(frac2,len(x_test)))\n",
    "    \n",
    "#     trainset1 = CustomDataSet('../../../data/celebA/celeba/img_align_celeba',x=x_train1,y=y_train1, transform=transform_with_aug)\n",
    "#     trainset2 = CustomDataSet('../../../data/celebA/celeba/img_align_celeba',x=x_train2,y=y_train2, transform=transform_with_aug)\n",
    "#     trainset3 = CustomDataSet('../../../data/celebA/celeba/img_align_celeba',x=x_train3,y=y_train3, transform=transform_with_aug)\n",
    "#     testset = CustomDataSet('../../../data/celebA/celeba/img_align_celeba',x=x_test,y=y_test, transform=transform_no_aug)\n",
    "\n",
    "    \n",
    "    dict_users = {0: x_train3, 1:x_train1, 2:x_train2}\n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "Round   0, Average loss 0.885\n",
      "Testing accuracy: 49.97\n",
      "Round   1, Average loss 0.708\n",
      "Testing accuracy: 50.03\n",
      "Round   2, Average loss 0.697\n",
      "Testing accuracy: 50.03\n",
      "Round   3, Average loss 0.695\n",
      "Testing accuracy: 49.97\n",
      "Round   4, Average loss 0.694\n",
      "Testing accuracy: 52.73\n",
      "Round   5, Average loss 0.681\n",
      "Testing accuracy: 49.97\n",
      "Round   6, Average loss 0.549\n",
      "Testing accuracy: 79.38\n",
      "Round   7, Average loss 0.428\n",
      "Testing accuracy: 86.16\n",
      "Round   8, Average loss 0.346\n",
      "Testing accuracy: 89.36\n",
      "Round   9, Average loss 0.308\n",
      "Testing accuracy: 89.77\n",
      "Round  10, Average loss 0.285\n",
      "Testing accuracy: 90.79\n",
      "Round  11, Average loss 0.269\n",
      "Testing accuracy: 90.66\n",
      "Round  12, Average loss 0.258\n",
      "Testing accuracy: 90.22\n",
      "Round  13, Average loss 0.252\n",
      "Testing accuracy: 90.87\n",
      "Round  14, Average loss 0.253\n",
      "Testing accuracy: 90.94\n",
      "Round  15, Average loss 0.243\n",
      "Testing accuracy: 91.25\n",
      "Round  16, Average loss 0.233\n",
      "Testing accuracy: 91.34\n",
      "Round  17, Average loss 0.236\n",
      "Testing accuracy: 91.22\n",
      "Round  18, Average loss 0.229\n",
      "Testing accuracy: 91.14\n",
      "Round  19, Average loss 0.222\n",
      "Testing accuracy: 91.56\n",
      "Round  20, Average loss 0.221\n",
      "Testing accuracy: 91.53\n",
      "Round  21, Average loss 0.215\n",
      "Testing accuracy: 91.76\n",
      "Round  22, Average loss 0.220\n",
      "Testing accuracy: 90.91\n",
      "Round  23, Average loss 0.213\n",
      "Testing accuracy: 91.40\n",
      "Round  24, Average loss 0.211\n",
      "Testing accuracy: 91.81\n",
      "Round  25, Average loss 0.207\n",
      "Testing accuracy: 91.83\n",
      "Round  26, Average loss 0.205\n",
      "Testing accuracy: 91.71\n",
      "Round  27, Average loss 0.203\n",
      "Testing accuracy: 91.59\n",
      "Round  28, Average loss 0.200\n",
      "Testing accuracy: 91.95\n",
      "Round  29, Average loss 0.197\n",
      "Testing accuracy: 92.18\n",
      "Round  30, Average loss 0.198\n",
      "Testing accuracy: 92.04\n",
      "Round  31, Average loss 0.195\n",
      "Testing accuracy: 91.86\n",
      "Round  32, Average loss 0.191\n",
      "Testing accuracy: 91.92\n",
      "Round  33, Average loss 0.190\n",
      "Testing accuracy: 91.16\n",
      "Round  34, Average loss 0.193\n",
      "Testing accuracy: 92.21\n",
      "Round  35, Average loss 0.198\n",
      "Testing accuracy: 91.49\n",
      "Round  36, Average loss 0.191\n",
      "Testing accuracy: 92.00\n",
      "Round  37, Average loss 0.190\n",
      "Testing accuracy: 91.64\n",
      "Round  38, Average loss 0.191\n",
      "Testing accuracy: 91.54\n",
      "Round  39, Average loss 0.186\n",
      "Testing accuracy: 91.64\n",
      "Round  40, Average loss 0.187\n",
      "Testing accuracy: 92.24\n",
      "Round  41, Average loss 0.185\n",
      "Testing accuracy: 91.53\n",
      "Round  42, Average loss 0.184\n",
      "Testing accuracy: 92.27\n",
      "Round  43, Average loss 0.183\n",
      "Testing accuracy: 92.52\n",
      "Round  44, Average loss 0.181\n",
      "Testing accuracy: 92.41\n",
      "Round  45, Average loss 0.183\n",
      "Testing accuracy: 92.13\n",
      "Round  46, Average loss 0.185\n",
      "Testing accuracy: 53.58\n",
      "Round  47, Average loss 0.188\n",
      "Testing accuracy: 92.53\n",
      "Round  48, Average loss 0.177\n",
      "Testing accuracy: 92.37\n",
      "Round  49, Average loss 0.176\n",
      "Testing accuracy: 92.19\n",
      "Round  50, Average loss 0.175\n",
      "Testing accuracy: 91.94\n",
      "Round  51, Average loss 0.175\n",
      "Testing accuracy: 92.31\n",
      "Round  52, Average loss 0.173\n",
      "Testing accuracy: 92.49\n",
      "Round  53, Average loss 0.171\n",
      "Testing accuracy: 92.45\n",
      "Round  54, Average loss 0.172\n",
      "Testing accuracy: 91.45\n",
      "Round  55, Average loss 0.169\n",
      "Testing accuracy: 92.38\n",
      "Round  56, Average loss 0.168\n",
      "Testing accuracy: 92.32\n",
      "Round  57, Average loss 0.170\n",
      "Testing accuracy: 92.48\n",
      "Round  58, Average loss 0.170\n",
      "Testing accuracy: 92.24\n",
      "Round  59, Average loss 0.167\n",
      "Testing accuracy: 92.59\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "#     writer = SummaryWriter('../../runs/') \n",
    "    reslist = []\n",
    "    # parse args\n",
    "    args = args_parser()\n",
    "    args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "    reslist = []\n",
    "    # load dataset and split users\n",
    "    if args.dataset == 'mnist':\n",
    "        trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset_train = datasets.MNIST('../data/mnist/', train=True, download=True, transform=trans_mnist)\n",
    "        dataset_test = datasets.MNIST('../data/mnist/', train=False, download=True, transform=trans_mnist)\n",
    "        # sample users\n",
    "        if args.iid:\n",
    "            dict_users = mnist_iid(dataset_train, args.num_users)\n",
    "        else:\n",
    "            dict_users = mnist_noniid(dataset_train, args.num_users)\n",
    "    elif args.dataset == 'cifar':\n",
    "        trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        if args.iid:\n",
    "            dataset_train = datasets.CIFAR10('../../../data/celebA', train=True, download=True, transform=trans_cifar)\n",
    "            dataset_test = datasets.CIFAR10('../../../data/celebA', train=False, download=True, transform=trans_cifar)\n",
    "            dict_users = cifar_iid(dataset_train, args.num_users)\n",
    "        else:\n",
    "            dataset_train=CustomDataSet('../../../data/celebA/celeba/img_align_celeba',x=x_train.filename,y=y_train, transform=transform_with_aug)\n",
    "            dataset_test=CustomDataSet('../../../data/celebA/celeba/img_align_celeba',x=x_test.filename,y=y_test, transform=transform_no_aug)\n",
    "            dict_users = create_dict()\n",
    "    else:\n",
    "        exit('Error: unrecognized dataset')\n",
    "    img_size = dataset_train[0][0].shape\n",
    "\n",
    "    # build model\n",
    "    if args.model == 'cnn' and args.dataset == 'cifar':\n",
    "        net_glob = CNNCifar(args=args).to(args.device)\n",
    "    elif args.model == 'resnet' and args.dataset == 'cifar':\n",
    "        net_glob = models.resnet50(pretrained=True)\n",
    "        num_ftrs = net_glob.fc.in_features\n",
    "        net_glob.fc = torch.nn.Linear(num_ftrs, 2)\n",
    "        net_glob.to(args.device)\n",
    "    elif args.model == 'cnn' and args.dataset == 'mnist':\n",
    "        net_glob = CNNMnist(args=args).to(args.device)\n",
    "    elif args.model == 'mlp':\n",
    "        len_in = 1\n",
    "        for x in img_size:\n",
    "            len_in *= x\n",
    "        net_glob = MLP(dim_in=len_in, dim_hidden=200, dim_out=args.num_classes).to(args.device)\n",
    "    else:\n",
    "        exit('Error: unrecognized model')\n",
    "    print(net_glob)\n",
    "    net_glob.train()\n",
    "\n",
    "    # copy weights\n",
    "    w_glob = net_glob.state_dict()\n",
    "\n",
    "    # training\n",
    "    loss_train = []\n",
    "    cv_loss, cv_acc = [], []\n",
    "    val_loss_pre, counter = 0, 0\n",
    "    net_best = None\n",
    "    best_loss = None\n",
    "    val_acc_list, net_list = [], []\n",
    "\n",
    "    for iter in range(args.epochs):\n",
    "        w_locals, loss_locals = [], []\n",
    "        m = max(int(args.frac * args.num_users), 3)\n",
    "        idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "        for idx in idxs_users:\n",
    "            local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "            w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "            w_locals.append(copy.deepcopy(w))\n",
    "            loss_locals.append(copy.deepcopy(loss))\n",
    "        # update global weights\n",
    "        w_glob = FedAvg(w_locals)\n",
    "\n",
    "        # copy weight to net_glob\n",
    "        net_glob.load_state_dict(w_glob)\n",
    "\n",
    "        # print loss\n",
    "        loss_avg = sum(loss_locals) / len(loss_locals)\n",
    "        print('Round {:3d}, Average loss {:.3f}'.format(iter, loss_avg))\n",
    "        loss_train.append(loss_avg)\n",
    "        \n",
    "        # testing\n",
    "        net_glob.eval()\n",
    "        acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "        print(\"Testing accuracy: {:.2f}\".format(acc_test))\n",
    "\n",
    "#         writer.add_scalar('train/loss_federated', loss_avg, iter)\n",
    "#         writer.add_scalar('valid/accuracy_federated', acc_test.data.numpy()/100., iter)\n",
    "        reslist.append(acc_test.data.numpy()/100.)\n",
    "        net_glob.train()\n",
    "\n",
    "    # plot loss curve\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(loss_train)), loss_train)\n",
    "    plt.ylabel('train_loss')\n",
    "    plt.savefig('./save/fed_{}_{}_{}_C{}_iid{}.png'.format(args.dataset, args.model, args.epochs, args.frac, args.iid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49969944000244143,\n",
       " 0.5003005599975586,\n",
       " 0.5003005599975586,\n",
       " 0.49969944000244143,\n",
       " 0.5273018646240234,\n",
       " 0.49969944000244143,\n",
       " 0.7937581634521484,\n",
       " 0.8616371154785156,\n",
       " 0.8935978698730469,\n",
       " 0.8976555633544921,\n",
       " 0.907925033569336,\n",
       " 0.9066226196289062,\n",
       " 0.9022142028808594,\n",
       " 0.9087265777587891,\n",
       " 0.9094279479980468,\n",
       " 0.9124837493896485,\n",
       " 0.9133854675292968,\n",
       " 0.9121831512451172,\n",
       " 0.9114317321777343,\n",
       " 0.915589599609375,\n",
       " 0.9152890777587891,\n",
       " 0.9175934600830078,\n",
       " 0.9090772247314454,\n",
       " 0.9139865875244141,\n",
       " 0.9180944061279297,\n",
       " 0.9183448791503906,\n",
       " 0.917142562866211,\n",
       " 0.9159403228759766,\n",
       " 0.9194970703125,\n",
       " 0.9217513275146484,\n",
       " 0.9204488372802735,\n",
       " 0.9185953521728516,\n",
       " 0.9191964721679687,\n",
       " 0.911632080078125,\n",
       " 0.9221019744873047,\n",
       " 0.9149383544921875,\n",
       " 0.9199980163574218,\n",
       " 0.9163911437988281,\n",
       " 0.9154393005371094,\n",
       " 0.9164412689208984,\n",
       " 0.9223524475097656,\n",
       " 0.9153391265869141,\n",
       " 0.9226530456542968,\n",
       " 0.9252079010009766,\n",
       " 0.9240557098388672,\n",
       " 0.9212503814697266,\n",
       " 0.5358180618286132,\n",
       " 0.9253080749511718,\n",
       " 0.9236549377441406,\n",
       " 0.9218515014648437,\n",
       " 0.9194469451904297,\n",
       " 0.9231038665771485,\n",
       " 0.9249073028564453,\n",
       " 0.9245065307617187,\n",
       " 0.9145376586914062,\n",
       " 0.9237551116943359,\n",
       " 0.9232041168212891,\n",
       " 0.92480712890625,\n",
       " 0.9223524475097656,\n",
       " 0.9258591461181641]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reslist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "confusion_matrix = torch.zeros(2, 2)\n",
    "net_glob.eval()\n",
    "# testing\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "data_loader = DataLoader(dataset_test, batch_size=args.bs)\n",
    "l = len(data_loader)\n",
    "for idx, (data, target) in enumerate(data_loader):\n",
    "    if args.gpu != -1:\n",
    "        data, target = data.to(args.device), target.to(args.device)\n",
    "    log_probs = net_glob(data)\n",
    "    # sum up batch loss\n",
    "    test_loss += F.cross_entropy(log_probs, target, reduction='sum').item()\n",
    "    # get the index of the max log-probability\n",
    "    y_pred = log_probs.data.max(1, keepdim=True)[1]\n",
    "    correct += y_pred.eq(target.data.view_as(y_pred)).long().cpu().sum()\n",
    "\n",
    "    for t, p in zip(target.data, y_pred.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9327.,  648.],\n",
      "        [ 832., 9155.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
