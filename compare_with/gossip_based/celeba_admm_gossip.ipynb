{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from optimizer import PruneAdam\n",
    "from model import LeNet, AlexNet\n",
    "from utils import regularized_nll_loss, admm_loss, \\\n",
    "    initialize_Z_and_U, update_X, update_Z, update_Z_l1, update_U, \\\n",
    "    print_convergence, print_prune, apply_prune, apply_l1_prune\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from tqdm import tqdm\n",
    "from Fed import FedAvg\n",
    "import copy\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, main_dir, x, y, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        self.y = y\n",
    "        self.all_imgs = x\n",
    "#         self.total_imgs = natsort.natsorted(all_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.all_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image,self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--dataset', type=str, default=\"cifar10\", choices=[\"mnist\", \"cifar10\"],\n",
    "                    metavar='D', help='training dataset (mnist or cifar10)')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--percent', type=list, default=[0.8, 0.92, 0.991, 0.93],\n",
    "                    metavar='P', help='pruning percentage (default: 0.8)')\n",
    "parser.add_argument('--alpha', type=float, default=5e-4, metavar='L',\n",
    "                    help='l2 norm weight (default: 5e-4)')\n",
    "parser.add_argument('--rho', type=float, default=1e-2, metavar='R',\n",
    "                    help='cardinality weight (default: 1e-2)')\n",
    "parser.add_argument('--l1', default=False, action='store_true',\n",
    "                    help='prune weights with l1 regularization instead of cardinality')\n",
    "parser.add_argument('--l2', default=False, action='store_true',\n",
    "                    help='apply l2 regularization')\n",
    "parser.add_argument('--num_pre_epochs', type=int, default=3, metavar='P',\n",
    "                    help='number of epochs to pretrain (default: 3)')\n",
    "parser.add_argument('--num_epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--num_re_epochs', type=int, default=3, metavar='R',\n",
    "                    help='number of epochs to retrain (default: 3)')\n",
    "parser.add_argument('--lr', type=float, default=1e-3, metavar='LR',\n",
    "                    help='learning rate (default: 1e-2)')\n",
    "parser.add_argument('--adam_epsilon', type=float, default=1e-8, metavar='E',\n",
    "                    help='adam epsilon (default: 1e-8)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--save-model', action='store_true', default=False,\n",
    "                    help='For Saving the current Model')\n",
    "parser.add_argument('--num_users', action='store_true', default=1,\n",
    "                    help='Number of users in network')\n",
    "parser.add_argument('--model', action='store_true', default='resnet',\n",
    "                    help='Model to train')\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classDict = {'not_smiling':0, 'smiling':1}\n",
    "\n",
    "# Define a function to separate CIFAR classes by class index\n",
    "\n",
    "def get_class_i(x, y, i):\n",
    "    \"\"\"\n",
    "    x: trainset.train_data or testset.test_data\n",
    "    y: trainset.train_labels or testset.test_labels\n",
    "    i: class label, a number between 0 to 9\n",
    "    return: x_i\n",
    "    \"\"\"\n",
    "    # Convert to a numpy array\n",
    "    y = np.array(y)\n",
    "    # Locate position of labels that equal to i\n",
    "    pos_i = np.argwhere(y == i)\n",
    "    # Convert the result into a 1-D list\n",
    "    pos_i = list(pos_i[:,0])\n",
    "    # Collect all data that match the desired label\n",
    "#     x_i = [x[j] for j in pos_i]\n",
    "    \n",
    "    return pos_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Standard transformations for improving celebA. \n",
    "# Transformations A\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop((218,178), padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Transformations B\n",
    "RC   = transforms.RandomCrop((218,178), padding=4)\n",
    "RHF  = transforms.RandomHorizontalFlip()\n",
    "RVF  = transforms.RandomVerticalFlip()\n",
    "NRM  = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "TT   = transforms.ToTensor()\n",
    "TPIL = transforms.ToPILImage()\n",
    "\n",
    "# Transforms object for trainset with augmentation\n",
    "transform_with_aug = transforms.Compose([RC, RHF, TT, NRM])\n",
    "# Transforms object for testset with NO augmentation\n",
    "transform_no_aug   = transforms.Compose([TT, NRM])\n",
    "\n",
    "# Downloading/Louding CELEBA data\n",
    "trainset = torchvision.datasets.CelebA(root='../../../data/celebA', split = 'train',\n",
    "                                        download=True, transform=transform_with_aug)\n",
    "\n",
    "testset = torchvision.datasets.CelebA(root='../../../data/celebA', split='test',\n",
    "                                       download=True, transform=transform_no_aug)\n",
    "\n",
    "classDict = {'not_smiling':0, 'smiling':1}\n",
    "\n",
    "# Separating trainset/testset data/label\n",
    "x_train  = trainset\n",
    "x_test   = testset\n",
    "y_train  = trainset.attr[:,31] ## 31 is smile\n",
    "y_test   = testset.attr[:,31] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test):\n",
    "    # If we are saving a fraction of random data to be used in training\n",
    "    frac1 = int(len(x_test) * 0.316666666667)\n",
    "    frac2 = int(len(x_test) * 0.633333333333)\n",
    "\n",
    "    x_train1 = list(range(0,frac1))\n",
    "    x_train2 = list(range(frac1,frac2))\n",
    "    x_train3 = list(range(frac2,len(x_test)))\n",
    "    \n",
    "#     trainset1 = CustomDataSet('../../../data/celebA/celeba/img_align_celeba',x=x_train1,y=y_train1, transform=transform_with_aug)\n",
    "#     trainset2 = CustomDataSet('../../../data/celebA/celeba/img_align_celeba',x=x_train2,y=y_train2, transform=transform_with_aug)\n",
    "#     trainset3 = CustomDataSet('../../../data/celebA/celeba/img_align_celeba',x=x_train3,y=y_train3, transform=transform_with_aug)\n",
    "#     testset = CustomDataSet('../../../data/celebA/celeba/img_align_celeba',x=x_test,y=y_test, transform=transform_no_aug)\n",
    "\n",
    "    \n",
    "    dict_users = {0: x_train3, 1:x_train1, 2:x_train2}\n",
    "    return dict_users\n",
    "\n",
    "class DatasetSplit(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gossip = []\n",
    "\n",
    "def pretrain(args, model, device, train_loader, test_loader, optimizer):\n",
    "    for epoch in range(args.num_pre_epochs):\n",
    "        print('Pre epoch: {}'.format(epoch + 1))\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = regularized_nll_loss(args, model, output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        test(args, model, device, test_loader)\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, test_loader, optimizer, Z, U, report=False):\n",
    "    model.train()\n",
    "    print('Epoch: {}'.format(epoch + 1))\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = admm_loss(args, device, model, Z, U, output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    X = update_X(model)\n",
    "    Z = update_Z_l1(X, U, args) if args.l1 else update_Z(X, U, args)\n",
    "    U = update_U(U, X, Z)\n",
    "    print_convergence(model, X, Z)\n",
    "    test(args, model, device, test_loader, report)\n",
    "\n",
    "\n",
    "iter = 0\n",
    "def test(args, model, device, test_loader, report=False):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    global iter\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    gossip.append(correct / len(test_loader.dataset))\n",
    "    \n",
    "    if report:\n",
    "#         writer.add_scalar('train/loss_gossip_admm4', test_loss, iter)\n",
    "#         writer.add_scalar('valid/accuracy_gossip_admm4', correct / len(test_loader.dataset), iter)\n",
    "        iter+=1\n",
    "\n",
    "\n",
    "def retrain(args, model, mask, device, train_loader, test_loader, optimizer):\n",
    "    for epoch in range(args.num_re_epochs):\n",
    "        print('Re epoch: {}'.format(epoch + 1))\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.prune_step(mask)\n",
    "\n",
    "        test(args, model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN\n",
    "\n",
    "what_gpu = 2\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device('cuda:{}'.format(what_gpu) if torch.cuda.is_available() else 'cpu')\n",
    "kwargs = {'num_workers': 5, 'pin_memory': True}\n",
    "\n",
    "args.percent = [0.6, 0.7, 0.8, 0.94, 0.95, 0.99, 0.99, 0.93]\n",
    "args.num_pre_epochs = 1\n",
    "args.num_epochs = 60\n",
    "args.num_re_epochs = 5\n",
    "args.num_users = 3\n",
    "args.dataset = 'cifar10'\n",
    "args.model = 'resnet'\n",
    "args.l1 = True\n",
    "args.l2 = False\n",
    "\n",
    "trainset=CustomDataSet('../../../data/celebA/celeba/img_align_celeba',x=x_train.filename,y=y_train, transform=transform_with_aug)\n",
    "testset=CustomDataSet('../../../data/celebA/celeba/img_align_celeba',x=x_test.filename,y=y_test, transform=transform_no_aug)\n",
    "test_loader = torch.utils.data.DataLoader(testset , batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "dict_users = create_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:25<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -365.3359, Accuracy: 17946/19962 (90%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:43<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -281.9503, Accuracy: 14033/19962 (70%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:44<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -302.1027, Accuracy: 17813/19962 (89%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:58<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized norm of (weight - projection)\n",
      "(conv1.weight): 0.3044\n",
      "(bn1.weight): 0.1847\n",
      "(layer1.0.conv1.weight): 0.4445\n",
      "(layer1.0.bn1.weight): 0.2322\n",
      "(layer1.0.conv2.weight): 0.7406\n",
      "(layer1.0.bn2.weight): 0.2892\n",
      "(layer1.0.conv3.weight): 0.6960\n",
      "(layer1.0.bn3.weight): 0.2676\n",
      "(layer1.0.downsample.0.weight): 0.5076\n",
      "(layer1.0.downsample.1.weight): 0.1921\n",
      "(layer1.1.conv1.weight): 0.7803\n",
      "(layer1.1.bn1.weight): 0.2457\n",
      "(layer1.1.conv2.weight): 0.8045\n",
      "(layer1.1.bn2.weight): 0.2702\n",
      "(layer1.1.conv3.weight): 0.7395\n",
      "(layer1.1.bn3.weight): 0.4125\n",
      "(layer1.2.conv1.weight): 0.8133\n",
      "(layer1.2.bn1.weight): 0.2749\n",
      "(layer1.2.conv2.weight): 0.8166\n",
      "(layer1.2.bn2.weight): 0.2232\n",
      "(layer1.2.conv3.weight): 0.7408\n",
      "(layer1.2.bn3.weight): 0.3204\n",
      "(layer2.0.conv1.weight): 0.7481\n",
      "(layer2.0.bn1.weight): 0.2420\n",
      "(layer2.0.conv2.weight): 0.9055\n",
      "(layer2.0.bn2.weight): 0.2454\n",
      "(layer2.0.conv3.weight): 0.7835\n",
      "(layer2.0.bn3.weight): 0.3009\n",
      "(layer2.0.downsample.0.weight): 0.7950\n",
      "(layer2.0.downsample.1.weight): 0.2909\n",
      "(layer2.1.conv1.weight): 0.8924\n",
      "(layer2.1.bn1.weight): 0.4201\n",
      "(layer2.1.conv2.weight): 0.8777\n",
      "(layer2.1.bn2.weight): 0.2984\n",
      "(layer2.1.conv3.weight): 0.8133\n",
      "(layer2.1.bn3.weight): 0.2851\n",
      "(layer2.2.conv1.weight): 0.8602\n",
      "(layer2.2.bn1.weight): 0.2891\n",
      "(layer2.2.conv2.weight): 0.8888\n",
      "(layer2.2.bn2.weight): 0.2717\n",
      "(layer2.2.conv3.weight): 0.8405\n",
      "(layer2.2.bn3.weight): 0.3952\n",
      "(layer2.3.conv1.weight): 0.8817\n",
      "(layer2.3.bn1.weight): 0.2909\n",
      "(layer2.3.conv2.weight): 0.9130\n",
      "(layer2.3.bn2.weight): 0.2490\n",
      "(layer2.3.conv3.weight): 0.8582\n",
      "(layer2.3.bn3.weight): 0.3833\n",
      "(layer3.0.conv1.weight): 0.8065\n",
      "(layer3.0.bn1.weight): 0.2147\n",
      "(layer3.0.conv2.weight): 0.9449\n",
      "(layer3.0.bn2.weight): 0.2721\n",
      "(layer3.0.conv3.weight): 0.8839\n",
      "(layer3.0.bn3.weight): 0.3480\n",
      "(layer3.0.downsample.0.weight): 0.9299\n",
      "(layer3.0.downsample.1.weight): 0.4331\n",
      "(layer3.1.conv1.weight): 0.9489\n",
      "(layer3.1.bn1.weight): 0.3206\n",
      "(layer3.1.conv2.weight): 0.9566\n",
      "(layer3.1.bn2.weight): 0.2660\n",
      "(layer3.1.conv3.weight): 0.9056\n",
      "(layer3.1.bn3.weight): 0.4459\n",
      "(layer3.2.conv1.weight): 0.9399\n",
      "(layer3.2.bn1.weight): 0.3272\n",
      "(layer3.2.conv2.weight): 0.9665\n",
      "(layer3.2.bn2.weight): 0.2722\n",
      "(layer3.2.conv3.weight): 0.9276\n",
      "(layer3.2.bn3.weight): 0.4650\n",
      "(layer3.3.conv1.weight): 0.9391\n",
      "(layer3.3.bn1.weight): 0.3062\n",
      "(layer3.3.conv2.weight): 0.9722\n",
      "(layer3.3.bn2.weight): 0.2881\n",
      "(layer3.3.conv3.weight): 0.9403\n",
      "(layer3.3.bn3.weight): 0.4326\n",
      "(layer3.4.conv1.weight): 0.9415\n",
      "(layer3.4.bn1.weight): 0.3026\n",
      "(layer3.4.conv2.weight): 0.9700\n",
      "(layer3.4.bn2.weight): 0.2772\n",
      "(layer3.4.conv3.weight): 0.9342\n",
      "(layer3.4.bn3.weight): 0.4070\n",
      "(layer3.5.conv1.weight): 0.9356\n",
      "(layer3.5.bn1.weight): 0.2737\n",
      "(layer3.5.conv2.weight): 0.9631\n",
      "(layer3.5.bn2.weight): 0.2539\n",
      "(layer3.5.conv3.weight): 0.9330\n",
      "(layer3.5.bn3.weight): 0.3290\n",
      "(layer4.0.conv1.weight): 0.9239\n",
      "(layer4.0.bn1.weight): 0.2239\n",
      "(layer4.0.conv2.weight): 0.9709\n",
      "(layer4.0.bn2.weight): 0.2470\n",
      "(layer4.0.conv3.weight): 0.9626\n",
      "(layer4.0.bn3.weight): 0.0772\n",
      "(layer4.0.downsample.0.weight): 0.9767\n",
      "(layer4.0.downsample.1.weight): 0.0899\n",
      "(layer4.1.conv1.weight): 0.9852\n",
      "(layer4.1.bn1.weight): 0.2586\n",
      "(layer4.1.conv2.weight): 0.9783\n",
      "(layer4.1.bn2.weight): 0.2298\n",
      "(layer4.1.conv3.weight): 0.9645\n",
      "(layer4.1.bn3.weight): 0.0776\n",
      "(layer4.2.conv1.weight): 0.9698\n",
      "(layer4.2.bn1.weight): 0.2307\n",
      "(layer4.2.conv2.weight): 0.9655\n",
      "(layer4.2.bn2.weight): 0.2298\n",
      "(layer4.2.conv3.weight): 0.9593\n",
      "(layer4.2.bn3.weight): 0.0496\n",
      "(fc.weight): 0.2057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -1197.1880, Accuracy: 9988/19962 (50%)\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [01:05<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized norm of (weight - projection)\n",
      "(conv1.weight): 0.3086\n",
      "(bn1.weight): 0.1838\n",
      "(layer1.0.conv1.weight): 0.4489\n",
      "(layer1.0.bn1.weight): 0.2291\n",
      "(layer1.0.conv2.weight): 0.7461\n",
      "(layer1.0.bn2.weight): 0.2905\n",
      "(layer1.0.conv3.weight): 0.6929\n",
      "(layer1.0.bn3.weight): 0.2698\n",
      "(layer1.0.downsample.0.weight): 0.5116\n",
      "(layer1.0.downsample.1.weight): 0.1894\n",
      "(layer1.1.conv1.weight): 0.7754\n",
      "(layer1.1.bn1.weight): 0.2467\n",
      "(layer1.1.conv2.weight): 0.7999\n",
      "(layer1.1.bn2.weight): 0.2695\n",
      "(layer1.1.conv3.weight): 0.7457\n",
      "(layer1.1.bn3.weight): 0.4236\n",
      "(layer1.2.conv1.weight): 0.8145\n",
      "(layer1.2.bn1.weight): 0.2709\n",
      "(layer1.2.conv2.weight): 0.8130\n",
      "(layer1.2.bn2.weight): 0.2227\n",
      "(layer1.2.conv3.weight): 0.7460\n",
      "(layer1.2.bn3.weight): 0.3300\n",
      "(layer2.0.conv1.weight): 0.7482\n",
      "(layer2.0.bn1.weight): 0.2388\n",
      "(layer2.0.conv2.weight): 0.8969\n",
      "(layer2.0.bn2.weight): 0.2456\n",
      "(layer2.0.conv3.weight): 0.7817\n",
      "(layer2.0.bn3.weight): 0.3054\n",
      "(layer2.0.downsample.0.weight): 0.8059\n",
      "(layer2.0.downsample.1.weight): 0.2901\n",
      "(layer2.1.conv1.weight): 0.8966\n",
      "(layer2.1.bn1.weight): 0.4245\n",
      "(layer2.1.conv2.weight): 0.8787\n",
      "(layer2.1.bn2.weight): 0.2951\n",
      "(layer2.1.conv3.weight): 0.8241\n",
      "(layer2.1.bn3.weight): 0.2919\n",
      "(layer2.2.conv1.weight): 0.8575\n",
      "(layer2.2.bn1.weight): 0.2886\n",
      "(layer2.2.conv2.weight): 0.8833\n",
      "(layer2.2.bn2.weight): 0.2720\n",
      "(layer2.2.conv3.weight): 0.8354\n",
      "(layer2.2.bn3.weight): 0.3791\n",
      "(layer2.3.conv1.weight): 0.8674\n",
      "(layer2.3.bn1.weight): 0.2897\n",
      "(layer2.3.conv2.weight): 0.8992\n",
      "(layer2.3.bn2.weight): 0.2478\n",
      "(layer2.3.conv3.weight): 0.8560\n",
      "(layer2.3.bn3.weight): 0.3787\n",
      "(layer3.0.conv1.weight): 0.7999\n",
      "(layer3.0.bn1.weight): 0.2135\n",
      "(layer3.0.conv2.weight): 0.9334\n",
      "(layer3.0.bn2.weight): 0.2714\n",
      "(layer3.0.conv3.weight): 0.8712\n",
      "(layer3.0.bn3.weight): 0.3416\n",
      "(layer3.0.downsample.0.weight): 0.9215\n",
      "(layer3.0.downsample.1.weight): 0.4285\n",
      "(layer3.1.conv1.weight): 0.9364\n",
      "(layer3.1.bn1.weight): 0.3125\n",
      "(layer3.1.conv2.weight): 0.9436\n",
      "(layer3.1.bn2.weight): 0.2647\n",
      "(layer3.1.conv3.weight): 0.8962\n",
      "(layer3.1.bn3.weight): 0.4407\n",
      "(layer3.2.conv1.weight): 0.9347\n",
      "(layer3.2.bn1.weight): 0.3199\n",
      "(layer3.2.conv2.weight): 0.9509\n",
      "(layer3.2.bn2.weight): 0.2705\n",
      "(layer3.2.conv3.weight): 0.9152\n",
      "(layer3.2.bn3.weight): 0.4636\n",
      "(layer3.3.conv1.weight): 0.9271\n",
      "(layer3.3.bn1.weight): 0.2990\n",
      "(layer3.3.conv2.weight): 0.9591\n",
      "(layer3.3.bn2.weight): 0.2850\n",
      "(layer3.3.conv3.weight): 0.9285\n",
      "(layer3.3.bn3.weight): 0.4162\n",
      "(layer3.4.conv1.weight): 0.9271\n",
      "(layer3.4.bn1.weight): 0.3020\n",
      "(layer3.4.conv2.weight): 0.9586\n",
      "(layer3.4.bn2.weight): 0.2756\n",
      "(layer3.4.conv3.weight): 0.9277\n",
      "(layer3.4.bn3.weight): 0.3899\n",
      "(layer3.5.conv1.weight): 0.9249\n",
      "(layer3.5.bn1.weight): 0.2729\n",
      "(layer3.5.conv2.weight): 0.9551\n",
      "(layer3.5.bn2.weight): 0.2574\n",
      "(layer3.5.conv3.weight): 0.9249\n",
      "(layer3.5.bn3.weight): 0.3160\n",
      "(layer4.0.conv1.weight): 0.9203\n",
      "(layer4.0.bn1.weight): 0.2259\n",
      "(layer4.0.conv2.weight): 0.9671\n",
      "(layer4.0.bn2.weight): 0.2460\n",
      "(layer4.0.conv3.weight): 0.9593\n",
      "(layer4.0.bn3.weight): 0.0711\n",
      "(layer4.0.downsample.0.weight): 0.9770\n",
      "(layer4.0.downsample.1.weight): 0.0818\n",
      "(layer4.1.conv1.weight): 0.9863\n",
      "(layer4.1.bn1.weight): 0.2624\n",
      "(layer4.1.conv2.weight): 0.9751\n",
      "(layer4.1.bn2.weight): 0.2341\n",
      "(layer4.1.conv3.weight): 0.9571\n",
      "(layer4.1.bn3.weight): 0.0718\n",
      "(layer4.2.conv1.weight): 0.9690\n",
      "(layer4.2.bn1.weight): 0.2336\n",
      "(layer4.2.conv2.weight): 0.9612\n",
      "(layer4.2.bn2.weight): 0.2310\n",
      "(layer4.2.conv3.weight): 0.9452\n",
      "(layer4.2.bn3.weight): 0.0472\n",
      "(fc.weight): 0.1699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -1255.6199, Accuracy: 10769/19962 (54%)\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:43<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized norm of (weight - projection)\n",
      "(conv1.weight): 0.3115\n",
      "(bn1.weight): 0.1821\n",
      "(layer1.0.conv1.weight): 0.4528\n",
      "(layer1.0.bn1.weight): 0.2258\n",
      "(layer1.0.conv2.weight): 0.7448\n",
      "(layer1.0.bn2.weight): 0.2848\n",
      "(layer1.0.conv3.weight): 0.6909\n",
      "(layer1.0.bn3.weight): 0.2690\n",
      "(layer1.0.downsample.0.weight): 0.5166\n",
      "(layer1.0.downsample.1.weight): 0.1885\n",
      "(layer1.1.conv1.weight): 0.7722\n",
      "(layer1.1.bn1.weight): 0.2462\n",
      "(layer1.1.conv2.weight): 0.7981\n",
      "(layer1.1.bn2.weight): 0.2706\n",
      "(layer1.1.conv3.weight): 0.7396\n",
      "(layer1.1.bn3.weight): 0.4279\n",
      "(layer1.2.conv1.weight): 0.8029\n",
      "(layer1.2.bn1.weight): 0.2715\n",
      "(layer1.2.conv2.weight): 0.8025\n",
      "(layer1.2.bn2.weight): 0.2225\n",
      "(layer1.2.conv3.weight): 0.7458\n",
      "(layer1.2.bn3.weight): 0.3309\n",
      "(layer2.0.conv1.weight): 0.7488\n",
      "(layer2.0.bn1.weight): 0.2382\n",
      "(layer2.0.conv2.weight): 0.8960\n",
      "(layer2.0.bn2.weight): 0.2456\n",
      "(layer2.0.conv3.weight): 0.7821\n",
      "(layer2.0.bn3.weight): 0.3038\n",
      "(layer2.0.downsample.0.weight): 0.8059\n",
      "(layer2.0.downsample.1.weight): 0.2899\n",
      "(layer2.1.conv1.weight): 0.8976\n",
      "(layer2.1.bn1.weight): 0.4294\n",
      "(layer2.1.conv2.weight): 0.8752\n",
      "(layer2.1.bn2.weight): 0.2983\n",
      "(layer2.1.conv3.weight): 0.8213\n",
      "(layer2.1.bn3.weight): 0.2929\n",
      "(layer2.2.conv1.weight): 0.8599\n",
      "(layer2.2.bn1.weight): 0.2876\n",
      "(layer2.2.conv2.weight): 0.8859\n",
      "(layer2.2.bn2.weight): 0.2718\n",
      "(layer2.2.conv3.weight): 0.8365\n",
      "(layer2.2.bn3.weight): 0.3845\n",
      "(layer2.3.conv1.weight): 0.8721\n",
      "(layer2.3.bn1.weight): 0.2901\n",
      "(layer2.3.conv2.weight): 0.9045\n",
      "(layer2.3.bn2.weight): 0.2475\n",
      "(layer2.3.conv3.weight): 0.8556\n",
      "(layer2.3.bn3.weight): 0.3874\n",
      "(layer3.0.conv1.weight): 0.8011\n",
      "(layer3.0.bn1.weight): 0.2127\n",
      "(layer3.0.conv2.weight): 0.9366\n",
      "(layer3.0.bn2.weight): 0.2716\n",
      "(layer3.0.conv3.weight): 0.8741\n",
      "(layer3.0.bn3.weight): 0.3534\n",
      "(layer3.0.downsample.0.weight): 0.9201\n",
      "(layer3.0.downsample.1.weight): 0.4344\n",
      "(layer3.1.conv1.weight): 0.9360\n",
      "(layer3.1.bn1.weight): 0.3209\n",
      "(layer3.1.conv2.weight): 0.9411\n",
      "(layer3.1.bn2.weight): 0.2675\n",
      "(layer3.1.conv3.weight): 0.8932\n",
      "(layer3.1.bn3.weight): 0.4545\n",
      "(layer3.2.conv1.weight): 0.9345\n",
      "(layer3.2.bn1.weight): 0.3279\n",
      "(layer3.2.conv2.weight): 0.9524\n",
      "(layer3.2.bn2.weight): 0.2691\n",
      "(layer3.2.conv3.weight): 0.9148\n",
      "(layer3.2.bn3.weight): 0.4649\n",
      "(layer3.3.conv1.weight): 0.9293\n",
      "(layer3.3.bn1.weight): 0.3007\n",
      "(layer3.3.conv2.weight): 0.9552\n",
      "(layer3.3.bn2.weight): 0.2873\n",
      "(layer3.3.conv3.weight): 0.9216\n",
      "(layer3.3.bn3.weight): 0.4208\n",
      "(layer3.4.conv1.weight): 0.9266\n",
      "(layer3.4.bn1.weight): 0.3024\n",
      "(layer3.4.conv2.weight): 0.9525\n",
      "(layer3.4.bn2.weight): 0.2735\n",
      "(layer3.4.conv3.weight): 0.9200\n",
      "(layer3.4.bn3.weight): 0.3953\n",
      "(layer3.5.conv1.weight): 0.9154\n",
      "(layer3.5.bn1.weight): 0.2766\n",
      "(layer3.5.conv2.weight): 0.9441\n",
      "(layer3.5.bn2.weight): 0.2659\n",
      "(layer3.5.conv3.weight): 0.9024\n",
      "(layer3.5.bn3.weight): 0.2876\n",
      "(layer4.0.conv1.weight): 0.9153\n",
      "(layer4.0.bn1.weight): 0.2314\n",
      "(layer4.0.conv2.weight): 0.9429\n",
      "(layer4.0.bn2.weight): 0.2440\n",
      "(layer4.0.conv3.weight): 0.9406\n",
      "(layer4.0.bn3.weight): 0.0581\n",
      "(layer4.0.downsample.0.weight): 0.9516\n",
      "(layer4.0.downsample.1.weight): 0.0650\n",
      "(layer4.1.conv1.weight): 0.9827\n",
      "(layer4.1.bn1.weight): 0.2675\n",
      "(layer4.1.conv2.weight): 0.9616\n",
      "(layer4.1.bn2.weight): 0.2366\n",
      "(layer4.1.conv3.weight): 0.9436\n",
      "(layer4.1.bn3.weight): 0.0587\n",
      "(layer4.2.conv1.weight): 0.9637\n",
      "(layer4.2.bn1.weight): 0.2368\n",
      "(layer4.2.conv2.weight): 0.9540\n",
      "(layer4.2.bn2.weight): 0.2366\n",
      "(layer4.2.conv3.weight): 0.9223\n",
      "(layer4.2.bn3.weight): 0.0412\n",
      "(fc.weight): 0.1145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -2659.3877, Accuracy: 10257/19962 (51%)\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:37<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized norm of (weight - projection)\n",
      "(conv1.weight): 0.3100\n",
      "(bn1.weight): 0.1854\n",
      "(layer1.0.conv1.weight): 0.4440\n",
      "(layer1.0.bn1.weight): 0.2305\n",
      "(layer1.0.conv2.weight): 0.7437\n",
      "(layer1.0.bn2.weight): 0.2850\n",
      "(layer1.0.conv3.weight): 0.6969\n",
      "(layer1.0.bn3.weight): 0.2705\n",
      "(layer1.0.downsample.0.weight): 0.5126\n",
      "(layer1.0.downsample.1.weight): 0.1873\n",
      "(layer1.1.conv1.weight): 0.7674\n",
      "(layer1.1.bn1.weight): 0.2445\n",
      "(layer1.1.conv2.weight): 0.7954\n",
      "(layer1.1.bn2.weight): 0.2685\n",
      "(layer1.1.conv3.weight): 0.7399\n",
      "(layer1.1.bn3.weight): 0.4322\n",
      "(layer1.2.conv1.weight): 0.8055\n",
      "(layer1.2.bn1.weight): 0.2740\n",
      "(layer1.2.conv2.weight): 0.8093\n",
      "(layer1.2.bn2.weight): 0.2225\n",
      "(layer1.2.conv3.weight): 0.7467\n",
      "(layer1.2.bn3.weight): 0.3363\n",
      "(layer2.0.conv1.weight): 0.7457\n",
      "(layer2.0.bn1.weight): 0.2399\n",
      "(layer2.0.conv2.weight): 0.8948\n",
      "(layer2.0.bn2.weight): 0.2453\n",
      "(layer2.0.conv3.weight): 0.7803\n",
      "(layer2.0.bn3.weight): 0.3019\n",
      "(layer2.0.downsample.0.weight): 0.8023\n",
      "(layer2.0.downsample.1.weight): 0.2836\n",
      "(layer2.1.conv1.weight): 0.8866\n",
      "(layer2.1.bn1.weight): 0.4197\n",
      "(layer2.1.conv2.weight): 0.8722\n",
      "(layer2.1.bn2.weight): 0.2995\n",
      "(layer2.1.conv3.weight): 0.8240\n",
      "(layer2.1.bn3.weight): 0.2943\n",
      "(layer2.2.conv1.weight): 0.8564\n",
      "(layer2.2.bn1.weight): 0.2897\n",
      "(layer2.2.conv2.weight): 0.8800\n",
      "(layer2.2.bn2.weight): 0.2725\n",
      "(layer2.2.conv3.weight): 0.8329\n",
      "(layer2.2.bn3.weight): 0.3896\n",
      "(layer2.3.conv1.weight): 0.8664\n",
      "(layer2.3.bn1.weight): 0.2886\n",
      "(layer2.3.conv2.weight): 0.8961\n",
      "(layer2.3.bn2.weight): 0.2495\n",
      "(layer2.3.conv3.weight): 0.8519\n",
      "(layer2.3.bn3.weight): 0.3857\n",
      "(layer3.0.conv1.weight): 0.7974\n",
      "(layer3.0.bn1.weight): 0.2130\n",
      "(layer3.0.conv2.weight): 0.9262\n",
      "(layer3.0.bn2.weight): 0.2720\n",
      "(layer3.0.conv3.weight): 0.8639\n",
      "(layer3.0.bn3.weight): 0.3607\n",
      "(layer3.0.downsample.0.weight): 0.9144\n",
      "(layer3.0.downsample.1.weight): 0.4158\n",
      "(layer3.1.conv1.weight): 0.9295\n",
      "(layer3.1.bn1.weight): 0.3255\n",
      "(layer3.1.conv2.weight): 0.9314\n",
      "(layer3.1.bn2.weight): 0.2662\n",
      "(layer3.1.conv3.weight): 0.8893\n",
      "(layer3.1.bn3.weight): 0.4481\n",
      "(layer3.2.conv1.weight): 0.9297\n",
      "(layer3.2.bn1.weight): 0.3266\n",
      "(layer3.2.conv2.weight): 0.9412\n",
      "(layer3.2.bn2.weight): 0.2679\n",
      "(layer3.2.conv3.weight): 0.9083\n",
      "(layer3.2.bn3.weight): 0.4769\n",
      "(layer3.3.conv1.weight): 0.9208\n",
      "(layer3.3.bn1.weight): 0.3009\n",
      "(layer3.3.conv2.weight): 0.9432\n",
      "(layer3.3.bn2.weight): 0.2824\n",
      "(layer3.3.conv3.weight): 0.9139\n",
      "(layer3.3.bn3.weight): 0.4229\n",
      "(layer3.4.conv1.weight): 0.9127\n",
      "(layer3.4.bn1.weight): 0.3028\n",
      "(layer3.4.conv2.weight): 0.9369\n",
      "(layer3.4.bn2.weight): 0.2749\n",
      "(layer3.4.conv3.weight): 0.9097\n",
      "(layer3.4.bn3.weight): 0.3919\n",
      "(layer3.5.conv1.weight): 0.9055\n",
      "(layer3.5.bn1.weight): 0.2749\n",
      "(layer3.5.conv2.weight): 0.9398\n",
      "(layer3.5.bn2.weight): 0.2671\n",
      "(layer3.5.conv3.weight): 0.9056\n",
      "(layer3.5.bn3.weight): 0.2816\n",
      "(layer4.0.conv1.weight): 0.9104\n",
      "(layer4.0.bn1.weight): 0.2296\n",
      "(layer4.0.conv2.weight): 0.9368\n",
      "(layer4.0.bn2.weight): 0.2432\n",
      "(layer4.0.conv3.weight): 0.9492\n",
      "(layer4.0.bn3.weight): 0.0591\n",
      "(layer4.0.downsample.0.weight): 0.9547\n",
      "(layer4.0.downsample.1.weight): 0.0664\n",
      "(layer4.1.conv1.weight): 0.9824\n",
      "(layer4.1.bn1.weight): 0.2670\n",
      "(layer4.1.conv2.weight): 0.9650\n",
      "(layer4.1.bn2.weight): 0.2355\n",
      "(layer4.1.conv3.weight): 0.9522\n",
      "(layer4.1.bn3.weight): 0.0598\n",
      "(layer4.2.conv1.weight): 0.9651\n",
      "(layer4.2.bn1.weight): 0.2357\n",
      "(layer4.2.conv2.weight): 0.9590\n",
      "(layer4.2.bn2.weight): 0.2350\n",
      "(layer4.2.conv3.weight): 0.9337\n",
      "(layer4.2.bn3.weight): 0.0417\n",
      "(fc.weight): 0.1177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -2422.1152, Accuracy: 10467/19962 (52%)\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:36<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized norm of (weight - projection)\n",
      "(conv1.weight): 0.3039\n",
      "(bn1.weight): 0.1835\n",
      "(layer1.0.conv1.weight): 0.4474\n",
      "(layer1.0.bn1.weight): 0.2304\n",
      "(layer1.0.conv2.weight): 0.7411\n",
      "(layer1.0.bn2.weight): 0.2910\n",
      "(layer1.0.conv3.weight): 0.6935\n",
      "(layer1.0.bn3.weight): 0.2662\n",
      "(layer1.0.downsample.0.weight): 0.5084\n",
      "(layer1.0.downsample.1.weight): 0.1927\n",
      "(layer1.1.conv1.weight): 0.7805\n",
      "(layer1.1.bn1.weight): 0.2507\n",
      "(layer1.1.conv2.weight): 0.8067\n",
      "(layer1.1.bn2.weight): 0.2680\n",
      "(layer1.1.conv3.weight): 0.7374\n",
      "(layer1.1.bn3.weight): 0.4018\n",
      "(layer1.2.conv1.weight): 0.8160\n",
      "(layer1.2.bn1.weight): 0.2733\n",
      "(layer1.2.conv2.weight): 0.8164\n",
      "(layer1.2.bn2.weight): 0.2241\n",
      "(layer1.2.conv3.weight): 0.7357\n",
      "(layer1.2.bn3.weight): 0.3270\n",
      "(layer2.0.conv1.weight): 0.7465\n",
      "(layer2.0.bn1.weight): 0.2405\n",
      "(layer2.0.conv2.weight): 0.9052\n",
      "(layer2.0.bn2.weight): 0.2462\n",
      "(layer2.0.conv3.weight): 0.7822\n",
      "(layer2.0.bn3.weight): 0.3049\n",
      "(layer2.0.downsample.0.weight): 0.7992\n",
      "(layer2.0.downsample.1.weight): 0.2938\n",
      "(layer2.1.conv1.weight): 0.8907\n",
      "(layer2.1.bn1.weight): 0.4298\n",
      "(layer2.1.conv2.weight): 0.8730\n",
      "(layer2.1.bn2.weight): 0.3043\n",
      "(layer2.1.conv3.weight): 0.8116\n",
      "(layer2.1.bn3.weight): 0.2791\n",
      "(layer2.2.conv1.weight): 0.8577\n",
      "(layer2.2.bn1.weight): 0.2901\n",
      "(layer2.2.conv2.weight): 0.8869\n",
      "(layer2.2.bn2.weight): 0.2737\n",
      "(layer2.2.conv3.weight): 0.8423\n",
      "(layer2.2.bn3.weight): 0.3917\n",
      "(layer2.3.conv1.weight): 0.8824\n",
      "(layer2.3.bn1.weight): 0.2926\n",
      "(layer2.3.conv2.weight): 0.9131\n",
      "(layer2.3.bn2.weight): 0.2482\n",
      "(layer2.3.conv3.weight): 0.8585\n",
      "(layer2.3.bn3.weight): 0.3878\n",
      "(layer3.0.conv1.weight): 0.8070\n",
      "(layer3.0.bn1.weight): 0.2154\n",
      "(layer3.0.conv2.weight): 0.9432\n",
      "(layer3.0.bn2.weight): 0.2721\n",
      "(layer3.0.conv3.weight): 0.8832\n",
      "(layer3.0.bn3.weight): 0.3478\n",
      "(layer3.0.downsample.0.weight): 0.9298\n",
      "(layer3.0.downsample.1.weight): 0.4331\n",
      "(layer3.1.conv1.weight): 0.9481\n",
      "(layer3.1.bn1.weight): 0.3185\n",
      "(layer3.1.conv2.weight): 0.9545\n",
      "(layer3.1.bn2.weight): 0.2655\n",
      "(layer3.1.conv3.weight): 0.9049\n",
      "(layer3.1.bn3.weight): 0.4400\n",
      "(layer3.2.conv1.weight): 0.9394\n",
      "(layer3.2.bn1.weight): 0.3227\n",
      "(layer3.2.conv2.weight): 0.9645\n",
      "(layer3.2.bn2.weight): 0.2726\n",
      "(layer3.2.conv3.weight): 0.9269\n",
      "(layer3.2.bn3.weight): 0.4629\n",
      "(layer3.3.conv1.weight): 0.9410\n",
      "(layer3.3.bn1.weight): 0.3043\n",
      "(layer3.3.conv2.weight): 0.9728\n",
      "(layer3.3.bn2.weight): 0.2861\n",
      "(layer3.3.conv3.weight): 0.9399\n",
      "(layer3.3.bn3.weight): 0.4374\n",
      "(layer3.4.conv1.weight): 0.9395\n",
      "(layer3.4.bn1.weight): 0.3060\n",
      "(layer3.4.conv2.weight): 0.9687\n",
      "(layer3.4.bn2.weight): 0.2735\n",
      "(layer3.4.conv3.weight): 0.9341\n",
      "(layer3.4.bn3.weight): 0.4018\n",
      "(layer3.5.conv1.weight): 0.9343\n",
      "(layer3.5.bn1.weight): 0.2758\n",
      "(layer3.5.conv2.weight): 0.9609\n",
      "(layer3.5.bn2.weight): 0.2539\n",
      "(layer3.5.conv3.weight): 0.9285\n",
      "(layer3.5.bn3.weight): 0.3226\n",
      "(layer4.0.conv1.weight): 0.9229\n",
      "(layer4.0.bn1.weight): 0.2241\n",
      "(layer4.0.conv2.weight): 0.9678\n",
      "(layer4.0.bn2.weight): 0.2479\n",
      "(layer4.0.conv3.weight): 0.9635\n",
      "(layer4.0.bn3.weight): 0.0773\n",
      "(layer4.0.downsample.0.weight): 0.9799\n",
      "(layer4.0.downsample.1.weight): 0.0900\n",
      "(layer4.1.conv1.weight): 0.9851\n",
      "(layer4.1.bn1.weight): 0.2592\n",
      "(layer4.1.conv2.weight): 0.9737\n",
      "(layer4.1.bn2.weight): 0.2304\n",
      "(layer4.1.conv3.weight): 0.9650\n",
      "(layer4.1.bn3.weight): 0.0778\n",
      "(layer4.2.conv1.weight): 0.9689\n",
      "(layer4.2.bn1.weight): 0.2298\n",
      "(layer4.2.conv2.weight): 0.9478\n",
      "(layer4.2.bn2.weight): 0.2310\n",
      "(layer4.2.conv3.weight): 0.9560\n",
      "(layer4.2.bn3.weight): 0.0496\n",
      "(fc.weight): 0.2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -1006.7922, Accuracy: 10487/19962 (53%)\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:42<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized norm of (weight - projection)\n",
      "(conv1.weight): 0.3130\n",
      "(bn1.weight): 0.1805\n",
      "(layer1.0.conv1.weight): 0.4498\n",
      "(layer1.0.bn1.weight): 0.2309\n",
      "(layer1.0.conv2.weight): 0.7400\n",
      "(layer1.0.bn2.weight): 0.2862\n",
      "(layer1.0.conv3.weight): 0.6891\n",
      "(layer1.0.bn3.weight): 0.2695\n",
      "(layer1.0.downsample.0.weight): 0.5154\n",
      "(layer1.0.downsample.1.weight): 0.1878\n",
      "(layer1.1.conv1.weight): 0.7586\n",
      "(layer1.1.bn1.weight): 0.2437\n",
      "(layer1.1.conv2.weight): 0.7859\n",
      "(layer1.1.bn2.weight): 0.2676\n",
      "(layer1.1.conv3.weight): 0.7360\n",
      "(layer1.1.bn3.weight): 0.4389\n",
      "(layer1.2.conv1.weight): 0.7913\n",
      "(layer1.2.bn1.weight): 0.2753\n",
      "(layer1.2.conv2.weight): 0.7917\n",
      "(layer1.2.bn2.weight): 0.2208\n",
      "(layer1.2.conv3.weight): 0.7422\n",
      "(layer1.2.bn3.weight): 0.3402\n",
      "(layer2.0.conv1.weight): 0.7338\n",
      "(layer2.0.bn1.weight): 0.2414\n",
      "(layer2.0.conv2.weight): 0.8758\n",
      "(layer2.0.bn2.weight): 0.2450\n",
      "(layer2.0.conv3.weight): 0.7748\n",
      "(layer2.0.bn3.weight): 0.3024\n",
      "(layer2.0.downsample.0.weight): 0.8003\n",
      "(layer2.0.downsample.1.weight): 0.2856\n",
      "(layer2.1.conv1.weight): 0.8670\n",
      "(layer2.1.bn1.weight): 0.4304\n",
      "(layer2.1.conv2.weight): 0.8627\n",
      "(layer2.1.bn2.weight): 0.2970\n",
      "(layer2.1.conv3.weight): 0.8196\n",
      "(layer2.1.bn3.weight): 0.2970\n",
      "(layer2.2.conv1.weight): 0.8469\n",
      "(layer2.2.bn1.weight): 0.2858\n",
      "(layer2.2.conv2.weight): 0.8708\n",
      "(layer2.2.bn2.weight): 0.2699\n",
      "(layer2.2.conv3.weight): 0.8250\n",
      "(layer2.2.bn3.weight): 0.3857\n",
      "(layer2.3.conv1.weight): 0.8543\n",
      "(layer2.3.bn1.weight): 0.2915\n",
      "(layer2.3.conv2.weight): 0.8833\n",
      "(layer2.3.bn2.weight): 0.2485\n",
      "(layer2.3.conv3.weight): 0.8421\n",
      "(layer2.3.bn3.weight): 0.3877\n",
      "(layer3.0.conv1.weight): 0.7901\n",
      "(layer3.0.bn1.weight): 0.2134\n",
      "(layer3.0.conv2.weight): 0.9185\n",
      "(layer3.0.bn2.weight): 0.2700\n",
      "(layer3.0.conv3.weight): 0.8585\n",
      "(layer3.0.bn3.weight): 0.3553\n",
      "(layer3.0.downsample.0.weight): 0.9038\n",
      "(layer3.0.downsample.1.weight): 0.4179\n",
      "(layer3.1.conv1.weight): 0.9182\n",
      "(layer3.1.bn1.weight): 0.3335\n",
      "(layer3.1.conv2.weight): 0.9165\n",
      "(layer3.1.bn2.weight): 0.2643\n",
      "(layer3.1.conv3.weight): 0.8753\n",
      "(layer3.1.bn3.weight): 0.4623\n",
      "(layer3.2.conv1.weight): 0.9204\n",
      "(layer3.2.bn1.weight): 0.3345\n",
      "(layer3.2.conv2.weight): 0.9302\n",
      "(layer3.2.bn2.weight): 0.2648\n",
      "(layer3.2.conv3.weight): 0.8980\n",
      "(layer3.2.bn3.weight): 0.4705\n",
      "(layer3.3.conv1.weight): 0.9137\n",
      "(layer3.3.bn1.weight): 0.2954\n",
      "(layer3.3.conv2.weight): 0.9331\n",
      "(layer3.3.bn2.weight): 0.2821\n",
      "(layer3.3.conv3.weight): 0.8990\n",
      "(layer3.3.bn3.weight): 0.4239\n",
      "(layer3.4.conv1.weight): 0.8971\n",
      "(layer3.4.bn1.weight): 0.3046\n",
      "(layer3.4.conv2.weight): 0.9065\n",
      "(layer3.4.bn2.weight): 0.2723\n",
      "(layer3.4.conv3.weight): 0.8795\n",
      "(layer3.4.bn3.weight): 0.3761\n",
      "(layer3.5.conv1.weight): 0.8688\n",
      "(layer3.5.bn1.weight): 0.2718\n",
      "(layer3.5.conv2.weight): 0.8887\n",
      "(layer3.5.bn2.weight): 0.2786\n",
      "(layer3.5.conv3.weight): 0.8531\n",
      "(layer3.5.bn3.weight): 0.2526\n",
      "(layer4.0.conv1.weight): 0.8824\n",
      "(layer4.0.bn1.weight): 0.2381\n",
      "(layer4.0.conv2.weight): 0.8840\n",
      "(layer4.0.bn2.weight): 0.2431\n",
      "(layer4.0.conv3.weight): 0.9089\n",
      "(layer4.0.bn3.weight): 0.0481\n",
      "(layer4.0.downsample.0.weight): 0.8807\n",
      "(layer4.0.downsample.1.weight): 0.0529\n",
      "(layer4.1.conv1.weight): 0.9639\n",
      "(layer4.1.bn1.weight): 0.2788\n",
      "(layer4.1.conv2.weight): 0.9308\n",
      "(layer4.1.bn2.weight): 0.2362\n",
      "(layer4.1.conv3.weight): 0.9140\n",
      "(layer4.1.bn3.weight): 0.0488\n",
      "(layer4.2.conv1.weight): 0.9549\n",
      "(layer4.2.bn1.weight): 0.2424\n",
      "(layer4.2.conv2.weight): 0.9280\n",
      "(layer4.2.bn2.weight): 0.2371\n",
      "(layer4.2.conv3.weight): 0.8911\n",
      "(layer4.2.bn3.weight): 0.0361\n",
      "(fc.weight): 0.0829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -5024.0880, Accuracy: 9975/19962 (50%)\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:36<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized norm of (weight - projection)\n",
      "(conv1.weight): 0.3120\n",
      "(bn1.weight): 0.1836\n",
      "(layer1.0.conv1.weight): 0.4486\n",
      "(layer1.0.bn1.weight): 0.2289\n",
      "(layer1.0.conv2.weight): 0.7417\n",
      "(layer1.0.bn2.weight): 0.2794\n",
      "(layer1.0.conv3.weight): 0.6912\n",
      "(layer1.0.bn3.weight): 0.2753\n",
      "(layer1.0.downsample.0.weight): 0.5149\n",
      "(layer1.0.downsample.1.weight): 0.1841\n",
      "(layer1.1.conv1.weight): 0.7643\n",
      "(layer1.1.bn1.weight): 0.2462\n",
      "(layer1.1.conv2.weight): 0.7934\n",
      "(layer1.1.bn2.weight): 0.2690\n",
      "(layer1.1.conv3.weight): 0.7375\n",
      "(layer1.1.bn3.weight): 0.4231\n",
      "(layer1.2.conv1.weight): 0.7851\n",
      "(layer1.2.bn1.weight): 0.2748\n",
      "(layer1.2.conv2.weight): 0.7948\n",
      "(layer1.2.bn2.weight): 0.2225\n",
      "(layer1.2.conv3.weight): 0.7447\n",
      "(layer1.2.bn3.weight): 0.3382\n",
      "(layer2.0.conv1.weight): 0.7355\n",
      "(layer2.0.bn1.weight): 0.2409\n",
      "(layer2.0.conv2.weight): 0.8828\n",
      "(layer2.0.bn2.weight): 0.2468\n",
      "(layer2.0.conv3.weight): 0.7762\n",
      "(layer2.0.bn3.weight): 0.3023\n",
      "(layer2.0.downsample.0.weight): 0.8005\n",
      "(layer2.0.downsample.1.weight): 0.2782\n",
      "(layer2.1.conv1.weight): 0.8828\n",
      "(layer2.1.bn1.weight): 0.4166\n",
      "(layer2.1.conv2.weight): 0.8724\n",
      "(layer2.1.bn2.weight): 0.2994\n",
      "(layer2.1.conv3.weight): 0.8248\n",
      "(layer2.1.bn3.weight): 0.3019\n",
      "(layer2.2.conv1.weight): 0.8511\n",
      "(layer2.2.bn1.weight): 0.2874\n",
      "(layer2.2.conv2.weight): 0.8781\n",
      "(layer2.2.bn2.weight): 0.2732\n",
      "(layer2.2.conv3.weight): 0.8300\n",
      "(layer2.2.bn3.weight): 0.3972\n",
      "(layer2.3.conv1.weight): 0.8635\n",
      "(layer2.3.bn1.weight): 0.2896\n",
      "(layer2.3.conv2.weight): 0.8932\n",
      "(layer2.3.bn2.weight): 0.2483\n",
      "(layer2.3.conv3.weight): 0.8486\n",
      "(layer2.3.bn3.weight): 0.3912\n",
      "(layer3.0.conv1.weight): 0.7945\n",
      "(layer3.0.bn1.weight): 0.2132\n",
      "(layer3.0.conv2.weight): 0.9251\n",
      "(layer3.0.bn2.weight): 0.2734\n",
      "(layer3.0.conv3.weight): 0.8642\n",
      "(layer3.0.bn3.weight): 0.3588\n",
      "(layer3.0.downsample.0.weight): 0.9116\n",
      "(layer3.0.downsample.1.weight): 0.4248\n",
      "(layer3.1.conv1.weight): 0.9313\n",
      "(layer3.1.bn1.weight): 0.3243\n",
      "(layer3.1.conv2.weight): 0.9316\n",
      "(layer3.1.bn2.weight): 0.2687\n",
      "(layer3.1.conv3.weight): 0.8843\n",
      "(layer3.1.bn3.weight): 0.4561\n",
      "(layer3.2.conv1.weight): 0.9255\n",
      "(layer3.2.bn1.weight): 0.3303\n",
      "(layer3.2.conv2.weight): 0.9348\n",
      "(layer3.2.bn2.weight): 0.2688\n",
      "(layer3.2.conv3.weight): 0.9020\n",
      "(layer3.2.bn3.weight): 0.4827\n",
      "(layer3.3.conv1.weight): 0.9202\n",
      "(layer3.3.bn1.weight): 0.2975\n",
      "(layer3.3.conv2.weight): 0.9431\n",
      "(layer3.3.bn2.weight): 0.2824\n",
      "(layer3.3.conv3.weight): 0.9152\n",
      "(layer3.3.bn3.weight): 0.4318\n",
      "(layer3.4.conv1.weight): 0.9196\n",
      "(layer3.4.bn1.weight): 0.3031\n",
      "(layer3.4.conv2.weight): 0.9392\n",
      "(layer3.4.bn2.weight): 0.2731\n",
      "(layer3.4.conv3.weight): 0.9072\n",
      "(layer3.4.bn3.weight): 0.3902\n",
      "(layer3.5.conv1.weight): 0.9010\n",
      "(layer3.5.bn1.weight): 0.2745\n",
      "(layer3.5.conv2.weight): 0.9165\n",
      "(layer3.5.bn2.weight): 0.2787\n",
      "(layer3.5.conv3.weight): 0.8701\n",
      "(layer3.5.bn3.weight): 0.2574\n",
      "(layer4.0.conv1.weight): 0.8930\n",
      "(layer4.0.bn1.weight): 0.2366\n",
      "(layer4.0.conv2.weight): 0.8889\n",
      "(layer4.0.bn2.weight): 0.2424\n",
      "(layer4.0.conv3.weight): 0.9133\n",
      "(layer4.0.bn3.weight): 0.0492\n",
      "(layer4.0.downsample.0.weight): 0.9012\n",
      "(layer4.0.downsample.1.weight): 0.0541\n",
      "(layer4.1.conv1.weight): 0.9691\n",
      "(layer4.1.bn1.weight): 0.2731\n",
      "(layer4.1.conv2.weight): 0.9277\n",
      "(layer4.1.bn2.weight): 0.2355\n",
      "(layer4.1.conv3.weight): 0.9120\n",
      "(layer4.1.bn3.weight): 0.0498\n",
      "(layer4.2.conv1.weight): 0.9565\n",
      "(layer4.2.bn1.weight): 0.2407\n",
      "(layer4.2.conv2.weight): 0.9271\n",
      "(layer4.2.bn2.weight): 0.2364\n",
      "(layer4.2.conv3.weight): 0.8947\n",
      "(layer4.2.bn3.weight): 0.0366\n",
      "(fc.weight): 0.0860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -4516.5071, Accuracy: 9826/19962 (49%)\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:36<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized norm of (weight - projection)\n",
      "(conv1.weight): 0.3108\n",
      "(bn1.weight): 0.1798\n",
      "(layer1.0.conv1.weight): 0.4508\n",
      "(layer1.0.bn1.weight): 0.2298\n",
      "(layer1.0.conv2.weight): 0.7473\n",
      "(layer1.0.bn2.weight): 0.2902\n",
      "(layer1.0.conv3.weight): 0.6913\n",
      "(layer1.0.bn3.weight): 0.2686\n",
      "(layer1.0.downsample.0.weight): 0.5170\n",
      "(layer1.0.downsample.1.weight): 0.1907\n",
      "(layer1.1.conv1.weight): 0.7683\n",
      "(layer1.1.bn1.weight): 0.2495\n",
      "(layer1.1.conv2.weight): 0.7968\n",
      "(layer1.1.bn2.weight): 0.2683\n",
      "(layer1.1.conv3.weight): 0.7406\n",
      "(layer1.1.bn3.weight): 0.4331\n",
      "(layer1.2.conv1.weight): 0.8038\n",
      "(layer1.2.bn1.weight): 0.2751\n",
      "(layer1.2.conv2.weight): 0.8075\n",
      "(layer1.2.bn2.weight): 0.2237\n",
      "(layer1.2.conv3.weight): 0.7411\n",
      "(layer1.2.bn3.weight): 0.3384\n",
      "(layer2.0.conv1.weight): 0.7426\n",
      "(layer2.0.bn1.weight): 0.2435\n",
      "(layer2.0.conv2.weight): 0.8958\n",
      "(layer2.0.bn2.weight): 0.2461\n",
      "(layer2.0.conv3.weight): 0.7813\n",
      "(layer2.0.bn3.weight): 0.3103\n",
      "(layer2.0.downsample.0.weight): 0.8022\n",
      "(layer2.0.downsample.1.weight): 0.2907\n",
      "(layer2.1.conv1.weight): 0.8731\n",
      "(layer2.1.bn1.weight): 0.4249\n",
      "(layer2.1.conv2.weight): 0.8667\n",
      "(layer2.1.bn2.weight): 0.3019\n",
      "(layer2.1.conv3.weight): 0.8204\n",
      "(layer2.1.bn3.weight): 0.2925\n",
      "(layer2.2.conv1.weight): 0.8509\n",
      "(layer2.2.bn1.weight): 0.2900\n",
      "(layer2.2.conv2.weight): 0.8823\n",
      "(layer2.2.bn2.weight): 0.2702\n",
      "(layer2.2.conv3.weight): 0.8327\n",
      "(layer2.2.bn3.weight): 0.3830\n",
      "(layer2.3.conv1.weight): 0.8697\n",
      "(layer2.3.bn1.weight): 0.2918\n",
      "(layer2.3.conv2.weight): 0.8983\n",
      "(layer2.3.bn2.weight): 0.2474\n",
      "(layer2.3.conv3.weight): 0.8524\n",
      "(layer2.3.bn3.weight): 0.3903\n",
      "(layer3.0.conv1.weight): 0.7979\n",
      "(layer3.0.bn1.weight): 0.2145\n",
      "(layer3.0.conv2.weight): 0.9273\n",
      "(layer3.0.bn2.weight): 0.2705\n",
      "(layer3.0.conv3.weight): 0.8684\n",
      "(layer3.0.bn3.weight): 0.3544\n",
      "(layer3.0.downsample.0.weight): 0.9172\n",
      "(layer3.0.downsample.1.weight): 0.4325\n",
      "(layer3.1.conv1.weight): 0.9356\n",
      "(layer3.1.bn1.weight): 0.3272\n",
      "(layer3.1.conv2.weight): 0.9386\n",
      "(layer3.1.bn2.weight): 0.2631\n",
      "(layer3.1.conv3.weight): 0.8889\n",
      "(layer3.1.bn3.weight): 0.4622\n",
      "(layer3.2.conv1.weight): 0.9308\n",
      "(layer3.2.bn1.weight): 0.3273\n",
      "(layer3.2.conv2.weight): 0.9408\n",
      "(layer3.2.bn2.weight): 0.2683\n",
      "(layer3.2.conv3.weight): 0.9075\n",
      "(layer3.2.bn3.weight): 0.4716\n",
      "(layer3.3.conv1.weight): 0.9264\n",
      "(layer3.3.bn1.weight): 0.2993\n",
      "(layer3.3.conv2.weight): 0.9477\n",
      "(layer3.3.bn2.weight): 0.2872\n",
      "(layer3.3.conv3.weight): 0.9189\n",
      "(layer3.3.bn3.weight): 0.4352\n",
      "(layer3.4.conv1.weight): 0.9206\n",
      "(layer3.4.bn1.weight): 0.3053\n",
      "(layer3.4.conv2.weight): 0.9401\n",
      "(layer3.4.bn2.weight): 0.2734\n",
      "(layer3.4.conv3.weight): 0.9062\n",
      "(layer3.4.bn3.weight): 0.3907\n",
      "(layer3.5.conv1.weight): 0.8957\n",
      "(layer3.5.bn1.weight): 0.2748\n",
      "(layer3.5.conv2.weight): 0.9357\n",
      "(layer3.5.bn2.weight): 0.2855\n",
      "(layer3.5.conv3.weight): 0.8944\n",
      "(layer3.5.bn3.weight): 0.2696\n",
      "(layer4.0.conv1.weight): 0.9047\n",
      "(layer4.0.bn1.weight): 0.2373\n",
      "(layer4.0.conv2.weight): 0.9424\n",
      "(layer4.0.bn2.weight): 0.2464\n",
      "(layer4.0.conv3.weight): 0.9447\n",
      "(layer4.0.bn3.weight): 0.0485\n",
      "(layer4.0.downsample.0.weight): 0.9430\n",
      "(layer4.0.downsample.1.weight): 0.0533\n",
      "(layer4.1.conv1.weight): 0.9777\n",
      "(layer4.1.bn1.weight): 0.2768\n",
      "(layer4.1.conv2.weight): 0.9667\n",
      "(layer4.1.bn2.weight): 0.2339\n",
      "(layer4.1.conv3.weight): 0.9480\n",
      "(layer4.1.bn3.weight): 0.0490\n",
      "(layer4.2.conv1.weight): 0.9621\n",
      "(layer4.2.bn1.weight): 0.2396\n",
      "(layer4.2.conv2.weight): 0.9600\n",
      "(layer4.2.bn2.weight): 0.2368\n",
      "(layer4.2.conv3.weight): 0.9345\n",
      "(layer4.2.bn3.weight): 0.0362\n",
      "(fc.weight): 0.0838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -4576.9743, Accuracy: 9975/19962 (50%)\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:43<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized norm of (weight - projection)\n",
      "(conv1.weight): 0.3083\n",
      "(bn1.weight): 0.1817\n",
      "(layer1.0.conv1.weight): 0.4471\n",
      "(layer1.0.bn1.weight): 0.2318\n",
      "(layer1.0.conv2.weight): 0.7420\n",
      "(layer1.0.bn2.weight): 0.2898\n",
      "(layer1.0.conv3.weight): 0.6935\n",
      "(layer1.0.bn3.weight): 0.2699\n",
      "(layer1.0.downsample.0.weight): 0.5114\n",
      "(layer1.0.downsample.1.weight): 0.1904\n",
      "(layer1.1.conv1.weight): 0.7719\n",
      "(layer1.1.bn1.weight): 0.2483\n",
      "(layer1.1.conv2.weight): 0.7993\n",
      "(layer1.1.bn2.weight): 0.2680\n",
      "(layer1.1.conv3.weight): 0.7365\n",
      "(layer1.1.bn3.weight): 0.4271\n",
      "(layer1.2.conv1.weight): 0.8128\n",
      "(layer1.2.bn1.weight): 0.2754\n",
      "(layer1.2.conv2.weight): 0.8153\n",
      "(layer1.2.bn2.weight): 0.2230\n",
      "(layer1.2.conv3.weight): 0.7386\n",
      "(layer1.2.bn3.weight): 0.3296\n",
      "(layer2.0.conv1.weight): 0.7459\n",
      "(layer2.0.bn1.weight): 0.2417\n",
      "(layer2.0.conv2.weight): 0.9034\n",
      "(layer2.0.bn2.weight): 0.2458\n",
      "(layer2.0.conv3.weight): 0.7797\n",
      "(layer2.0.bn3.weight): 0.3003\n",
      "(layer2.0.downsample.0.weight): 0.8002\n",
      "(layer2.0.downsample.1.weight): 0.2884\n",
      "(layer2.1.conv1.weight): 0.8918\n",
      "(layer2.1.bn1.weight): 0.4325\n",
      "(layer2.1.conv2.weight): 0.8718\n",
      "(layer2.1.bn2.weight): 0.3012\n",
      "(layer2.1.conv3.weight): 0.8148\n",
      "(layer2.1.bn3.weight): 0.2826\n",
      "(layer2.2.conv1.weight): 0.8608\n",
      "(layer2.2.bn1.weight): 0.2884\n",
      "(layer2.2.conv2.weight): 0.8876\n",
      "(layer2.2.bn2.weight): 0.2718\n",
      "(layer2.2.conv3.weight): 0.8407\n",
      "(layer2.2.bn3.weight): 0.3937\n",
      "(layer2.3.conv1.weight): 0.8802\n",
      "(layer2.3.bn1.weight): 0.2919\n",
      "(layer2.3.conv2.weight): 0.9131\n",
      "(layer2.3.bn2.weight): 0.2481\n",
      "(layer2.3.conv3.weight): 0.8592\n",
      "(layer2.3.bn3.weight): 0.3907\n",
      "(layer3.0.conv1.weight): 0.8071\n",
      "(layer3.0.bn1.weight): 0.2139\n",
      "(layer3.0.conv2.weight): 0.9429\n",
      "(layer3.0.bn2.weight): 0.2721\n",
      "(layer3.0.conv3.weight): 0.8803\n",
      "(layer3.0.bn3.weight): 0.3564\n",
      "(layer3.0.downsample.0.weight): 0.9264\n",
      "(layer3.0.downsample.1.weight): 0.4321\n",
      "(layer3.1.conv1.weight): 0.9455\n",
      "(layer3.1.bn1.weight): 0.3300\n",
      "(layer3.1.conv2.weight): 0.9508\n",
      "(layer3.1.bn2.weight): 0.2655\n",
      "(layer3.1.conv3.weight): 0.8993\n",
      "(layer3.1.bn3.weight): 0.4614\n",
      "(layer3.2.conv1.weight): 0.9387\n",
      "(layer3.2.bn1.weight): 0.3315\n",
      "(layer3.2.conv2.weight): 0.9618\n",
      "(layer3.2.bn2.weight): 0.2697\n",
      "(layer3.2.conv3.weight): 0.9241\n",
      "(layer3.2.bn3.weight): 0.4766\n",
      "(layer3.3.conv1.weight): 0.9356\n",
      "(layer3.3.bn1.weight): 0.3010\n",
      "(layer3.3.conv2.weight): 0.9647\n",
      "(layer3.3.bn2.weight): 0.2851\n",
      "(layer3.3.conv3.weight): 0.9326\n",
      "(layer3.3.bn3.weight): 0.4342\n",
      "(layer3.4.conv1.weight): 0.9327\n",
      "(layer3.4.bn1.weight): 0.3062\n",
      "(layer3.4.conv2.weight): 0.9551\n",
      "(layer3.4.bn2.weight): 0.2731\n",
      "(layer3.4.conv3.weight): 0.9243\n",
      "(layer3.4.bn3.weight): 0.3967\n",
      "(layer3.5.conv1.weight): 0.9201\n",
      "(layer3.5.bn1.weight): 0.2744\n",
      "(layer3.5.conv2.weight): 0.9439\n",
      "(layer3.5.bn2.weight): 0.2752\n",
      "(layer3.5.conv3.weight): 0.9008\n",
      "(layer3.5.bn3.weight): 0.2761\n",
      "(layer4.0.conv1.weight): 0.9073\n",
      "(layer4.0.bn1.weight): 0.2377\n",
      "(layer4.0.conv2.weight): 0.9391\n",
      "(layer4.0.bn2.weight): 0.2463\n",
      "(layer4.0.conv3.weight): 0.9446\n",
      "(layer4.0.bn3.weight): 0.0506\n",
      "(layer4.0.downsample.0.weight): 0.9338\n",
      "(layer4.0.downsample.1.weight): 0.0557\n",
      "(layer4.1.conv1.weight): 0.9787\n",
      "(layer4.1.bn1.weight): 0.2766\n",
      "(layer4.1.conv2.weight): 0.9667\n",
      "(layer4.1.bn2.weight): 0.2340\n",
      "(layer4.1.conv3.weight): 0.9519\n",
      "(layer4.1.bn3.weight): 0.0508\n",
      "(layer4.2.conv1.weight): 0.9611\n",
      "(layer4.2.bn1.weight): 0.2410\n",
      "(layer4.2.conv2.weight): 0.9578\n",
      "(layer4.2.bn2.weight): 0.2374\n",
      "(layer4.2.conv3.weight): 0.9219\n",
      "(layer4.2.bn3.weight): 0.0371\n",
      "(fc.weight): 0.0879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -4098.6146, Accuracy: 9987/19962 (50%)\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:37<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized norm of (weight - projection)\n",
      "(conv1.weight): 0.3097\n",
      "(bn1.weight): 0.1825\n",
      "(layer1.0.conv1.weight): 0.4502\n",
      "(layer1.0.bn1.weight): 0.2314\n",
      "(layer1.0.conv2.weight): 0.7436\n",
      "(layer1.0.bn2.weight): 0.2829\n",
      "(layer1.0.conv3.weight): 0.6968\n",
      "(layer1.0.bn3.weight): 0.2677\n",
      "(layer1.0.downsample.0.weight): 0.5163\n",
      "(layer1.0.downsample.1.weight): 0.1896\n",
      "(layer1.1.conv1.weight): 0.7654\n",
      "(layer1.1.bn1.weight): 0.2493\n",
      "(layer1.1.conv2.weight): 0.7920\n",
      "(layer1.1.bn2.weight): 0.2690\n",
      "(layer1.1.conv3.weight): 0.7378\n",
      "(layer1.1.bn3.weight): 0.4291\n",
      "(layer1.2.conv1.weight): 0.7959\n",
      "(layer1.2.bn1.weight): 0.2758\n",
      "(layer1.2.conv2.weight): 0.8016\n",
      "(layer1.2.bn2.weight): 0.2213\n",
      "(layer1.2.conv3.weight): 0.7432\n",
      "(layer1.2.bn3.weight): 0.3384\n",
      "(layer2.0.conv1.weight): 0.7414\n",
      "(layer2.0.bn1.weight): 0.2430\n",
      "(layer2.0.conv2.weight): 0.8916\n",
      "(layer2.0.bn2.weight): 0.2467\n",
      "(layer2.0.conv3.weight): 0.7800\n",
      "(layer2.0.bn3.weight): 0.3041\n",
      "(layer2.0.downsample.0.weight): 0.8053\n",
      "(layer2.0.downsample.1.weight): 0.2838\n",
      "(layer2.1.conv1.weight): 0.8781\n",
      "(layer2.1.bn1.weight): 0.4208\n",
      "(layer2.1.conv2.weight): 0.8709\n",
      "(layer2.1.bn2.weight): 0.3006\n",
      "(layer2.1.conv3.weight): 0.8184\n",
      "(layer2.1.bn3.weight): 0.2858\n",
      "(layer2.2.conv1.weight): 0.8524\n",
      "(layer2.2.bn1.weight): 0.2879\n",
      "(layer2.2.conv2.weight): 0.8778\n",
      "(layer2.2.bn2.weight): 0.2730\n",
      "(layer2.2.conv3.weight): 0.8299\n",
      "(layer2.2.bn3.weight): 0.3934\n",
      "(layer2.3.conv1.weight): 0.8663\n",
      "(layer2.3.bn1.weight): 0.2897\n",
      "(layer2.3.conv2.weight): 0.8940\n",
      "(layer2.3.bn2.weight): 0.2489\n",
      "(layer2.3.conv3.weight): 0.8495\n",
      "(layer2.3.bn3.weight): 0.3962\n",
      "(layer3.0.conv1.weight): 0.7955\n",
      "(layer3.0.bn1.weight): 0.2139\n",
      "(layer3.0.conv2.weight): 0.9217\n",
      "(layer3.0.bn2.weight): 0.2718\n",
      "(layer3.0.conv3.weight): 0.8622\n",
      "(layer3.0.bn3.weight): 0.3631\n",
      "(layer3.0.downsample.0.weight): 0.9124\n",
      "(layer3.0.downsample.1.weight): 0.4307\n",
      "(layer3.1.conv1.weight): 0.9285\n",
      "(layer3.1.bn1.weight): 0.3261\n",
      "(layer3.1.conv2.weight): 0.9253\n",
      "(layer3.1.bn2.weight): 0.2645\n",
      "(layer3.1.conv3.weight): 0.8812\n",
      "(layer3.1.bn3.weight): 0.4694\n",
      "(layer3.2.conv1.weight): 0.9266\n",
      "(layer3.2.bn1.weight): 0.3295\n",
      "(layer3.2.conv2.weight): 0.9337\n",
      "(layer3.2.bn2.weight): 0.2670\n",
      "(layer3.2.conv3.weight): 0.8976\n",
      "(layer3.2.bn3.weight): 0.4879\n",
      "(layer3.3.conv1.weight): 0.9202\n",
      "(layer3.3.bn1.weight): 0.3001\n",
      "(layer3.3.conv2.weight): 0.9408\n",
      "(layer3.3.bn2.weight): 0.2879\n",
      "(layer3.3.conv3.weight): 0.9137\n",
      "(layer3.3.bn3.weight): 0.4271\n",
      "(layer3.4.conv1.weight): 0.9118\n",
      "(layer3.4.bn1.weight): 0.3056\n",
      "(layer3.4.conv2.weight): 0.9347\n",
      "(layer3.4.bn2.weight): 0.2729\n",
      "(layer3.4.conv3.weight): 0.9047\n",
      "(layer3.4.bn3.weight): 0.3741\n",
      "(layer3.5.conv1.weight): 0.8913\n",
      "(layer3.5.bn1.weight): 0.2749\n",
      "(layer3.5.conv2.weight): 0.9262\n",
      "(layer3.5.bn2.weight): 0.2930\n",
      "(layer3.5.conv3.weight): 0.8721\n",
      "(layer3.5.bn3.weight): 0.2557\n",
      "(layer4.0.conv1.weight): 0.8981\n",
      "(layer4.0.bn1.weight): 0.2382\n",
      "(layer4.0.conv2.weight): 0.9079\n",
      "(layer4.0.bn2.weight): 0.2429\n",
      "(layer4.0.conv3.weight): 0.9298\n",
      "(layer4.0.bn3.weight): 0.0423\n",
      "(layer4.0.downsample.0.weight): 0.9095\n",
      "(layer4.0.downsample.1.weight): 0.0459\n",
      "(layer4.1.conv1.weight): 0.9754\n",
      "(layer4.1.bn1.weight): 0.2767\n",
      "(layer4.1.conv2.weight): 0.9492\n",
      "(layer4.1.bn2.weight): 0.2339\n",
      "(layer4.1.conv3.weight): 0.9327\n",
      "(layer4.1.bn3.weight): 0.0426\n",
      "(layer4.2.conv1.weight): 0.9642\n",
      "(layer4.2.bn1.weight): 0.2413\n",
      "(layer4.2.conv2.weight): 0.9473\n",
      "(layer4.2.bn2.weight): 0.2364\n",
      "(layer4.2.conv3.weight): 0.9167\n",
      "(layer4.2.bn3.weight): 0.0326\n",
      "(fc.weight): 0.0674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -7020.0787, Accuracy: 9975/19962 (50%)\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:37<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized norm of (weight - projection)\n",
      "(conv1.weight): 0.3127\n",
      "(bn1.weight): 0.1782\n",
      "(layer1.0.conv1.weight): 0.4497\n",
      "(layer1.0.bn1.weight): 0.2268\n",
      "(layer1.0.conv2.weight): 0.7456\n",
      "(layer1.0.bn2.weight): 0.2825\n",
      "(layer1.0.conv3.weight): 0.6865\n",
      "(layer1.0.bn3.weight): 0.2673\n",
      "(layer1.0.downsample.0.weight): 0.5169\n",
      "(layer1.0.downsample.1.weight): 0.1881\n",
      "(layer1.1.conv1.weight): 0.7563\n",
      "(layer1.1.bn1.weight): 0.2451\n",
      "(layer1.1.conv2.weight): 0.7825\n",
      "(layer1.1.bn2.weight): 0.2662\n",
      "(layer1.1.conv3.weight): 0.7327\n",
      "(layer1.1.bn3.weight): 0.4162\n",
      "(layer1.2.conv1.weight): 0.7732\n",
      "(layer1.2.bn1.weight): 0.2729\n",
      "(layer1.2.conv2.weight): 0.7882\n",
      "(layer1.2.bn2.weight): 0.2230\n",
      "(layer1.2.conv3.weight): 0.7375\n",
      "(layer1.2.bn3.weight): 0.3427\n",
      "(layer2.0.conv1.weight): 0.7249\n",
      "(layer2.0.bn1.weight): 0.2402\n",
      "(layer2.0.conv2.weight): 0.8736\n",
      "(layer2.0.bn2.weight): 0.2457\n",
      "(layer2.0.conv3.weight): 0.7729\n",
      "(layer2.0.bn3.weight): 0.3141\n",
      "(layer2.0.downsample.0.weight): 0.7983\n",
      "(layer2.0.downsample.1.weight): 0.2841\n",
      "(layer2.1.conv1.weight): 0.8699\n",
      "(layer2.1.bn1.weight): 0.4155\n",
      "(layer2.1.conv2.weight): 0.8653\n",
      "(layer2.1.bn2.weight): 0.3024\n",
      "(layer2.1.conv3.weight): 0.8193\n",
      "(layer2.1.bn3.weight): 0.2994\n",
      "(layer2.2.conv1.weight): 0.8435\n",
      "(layer2.2.bn1.weight): 0.2888\n",
      "(layer2.2.conv2.weight): 0.8782\n",
      "(layer2.2.bn2.weight): 0.2718\n",
      "(layer2.2.conv3.weight): 0.8272\n",
      "(layer2.2.bn3.weight): 0.3880\n",
      "(layer2.3.conv1.weight): 0.8614\n",
      "(layer2.3.bn1.weight): 0.2905\n",
      "(layer2.3.conv2.weight): 0.8927\n",
      "(layer2.3.bn2.weight): 0.2474\n",
      "(layer2.3.conv3.weight): 0.8459\n",
      "(layer2.3.bn3.weight): 0.3979\n",
      "(layer3.0.conv1.weight): 0.7928\n",
      "(layer3.0.bn1.weight): 0.2159\n",
      "(layer3.0.conv2.weight): 0.9218\n",
      "(layer3.0.bn2.weight): 0.2740\n",
      "(layer3.0.conv3.weight): 0.8600\n",
      "(layer3.0.bn3.weight): 0.3618\n",
      "(layer3.0.downsample.0.weight): 0.9090\n",
      "(layer3.0.downsample.1.weight): 0.4353\n",
      "(layer3.1.conv1.weight): 0.9251\n",
      "(layer3.1.bn1.weight): 0.3351\n",
      "(layer3.1.conv2.weight): 0.9253\n",
      "(layer3.1.bn2.weight): 0.2652\n",
      "(layer3.1.conv3.weight): 0.8836\n",
      "(layer3.1.bn3.weight): 0.4730\n",
      "(layer3.2.conv1.weight): 0.9272\n",
      "(layer3.2.bn1.weight): 0.3301\n",
      "(layer3.2.conv2.weight): 0.9405\n",
      "(layer3.2.bn2.weight): 0.2682\n",
      "(layer3.2.conv3.weight): 0.9073\n",
      "(layer3.2.bn3.weight): 0.4887\n",
      "(layer3.3.conv1.weight): 0.9246\n",
      "(layer3.3.bn1.weight): 0.2998\n",
      "(layer3.3.conv2.weight): 0.9498\n",
      "(layer3.3.bn2.weight): 0.2847\n",
      "(layer3.3.conv3.weight): 0.9170\n",
      "(layer3.3.bn3.weight): 0.4404\n",
      "(layer3.4.conv1.weight): 0.9162\n",
      "(layer3.4.bn1.weight): 0.3033\n",
      "(layer3.4.conv2.weight): 0.9393\n",
      "(layer3.4.bn2.weight): 0.2705\n",
      "(layer3.4.conv3.weight): 0.9053\n",
      "(layer3.4.bn3.weight): 0.3870\n",
      "(layer3.5.conv1.weight): 0.9010\n",
      "(layer3.5.bn1.weight): 0.2766\n",
      "(layer3.5.conv2.weight): 0.9331\n",
      "(layer3.5.bn2.weight): 0.2998\n",
      "(layer3.5.conv3.weight): 0.8759\n",
      "(layer3.5.bn3.weight): 0.2591\n",
      "(layer4.0.conv1.weight): 0.9056\n",
      "(layer4.0.bn1.weight): 0.2379\n",
      "(layer4.0.conv2.weight): 0.9193\n",
      "(layer4.0.bn2.weight): 0.2437\n",
      "(layer4.0.conv3.weight): 0.9312\n",
      "(layer4.0.bn3.weight): 0.0422\n",
      "(layer4.0.downsample.0.weight): 0.9176\n",
      "(layer4.0.downsample.1.weight): 0.0457\n",
      "(layer4.1.conv1.weight): 0.9769\n",
      "(layer4.1.bn1.weight): 0.2766\n",
      "(layer4.1.conv2.weight): 0.9526\n",
      "(layer4.1.bn2.weight): 0.2341\n",
      "(layer4.1.conv3.weight): 0.9336\n",
      "(layer4.1.bn3.weight): 0.0426\n",
      "(layer4.2.conv1.weight): 0.9640\n",
      "(layer4.2.bn1.weight): 0.2410\n",
      "(layer4.2.conv2.weight): 0.9502\n",
      "(layer4.2.bn2.weight): 0.2362\n",
      "(layer4.2.conv3.weight): 0.9197\n",
      "(layer4.2.bn3.weight): 0.0326\n",
      "(fc.weight): 0.0676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -7197.7097, Accuracy: 9975/19962 (50%)\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:37<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized norm of (weight - projection)\n",
      "(conv1.weight): 0.3093\n",
      "(bn1.weight): 0.1833\n",
      "(layer1.0.conv1.weight): 0.4477\n",
      "(layer1.0.bn1.weight): 0.2313\n",
      "(layer1.0.conv2.weight): 0.7434\n",
      "(layer1.0.bn2.weight): 0.2876\n",
      "(layer1.0.conv3.weight): 0.6926\n",
      "(layer1.0.bn3.weight): 0.2701\n",
      "(layer1.0.downsample.0.weight): 0.5150\n",
      "(layer1.0.downsample.1.weight): 0.1939\n",
      "(layer1.1.conv1.weight): 0.7551\n",
      "(layer1.1.bn1.weight): 0.2475\n",
      "(layer1.1.conv2.weight): 0.7826\n",
      "(layer1.1.bn2.weight): 0.2674\n",
      "(layer1.1.conv3.weight): 0.7313\n",
      "(layer1.1.bn3.weight): 0.4322\n",
      "(layer1.2.conv1.weight): 0.7767\n",
      "(layer1.2.bn1.weight): 0.2781\n",
      "(layer1.2.conv2.weight): 0.7862\n",
      "(layer1.2.bn2.weight): 0.2220\n",
      "(layer1.2.conv3.weight): 0.7422\n",
      "(layer1.2.bn3.weight): 0.3238\n",
      "(layer2.0.conv1.weight): 0.7330\n",
      "(layer2.0.bn1.weight): 0.2421\n",
      "(layer2.0.conv2.weight): 0.8848\n",
      "(layer2.0.bn2.weight): 0.2467\n",
      "(layer2.0.conv3.weight): 0.7766\n",
      "(layer2.0.bn3.weight): 0.3104\n",
      "(layer2.0.downsample.0.weight): 0.7987\n",
      "(layer2.0.downsample.1.weight): 0.2863\n",
      "(layer2.1.conv1.weight): 0.8846\n",
      "(layer2.1.bn1.weight): 0.4252\n",
      "(layer2.1.conv2.weight): 0.8717\n",
      "(layer2.1.bn2.weight): 0.3010\n",
      "(layer2.1.conv3.weight): 0.8209\n",
      "(layer2.1.bn3.weight): 0.2870\n",
      "(layer2.2.conv1.weight): 0.8419\n",
      "(layer2.2.bn1.weight): 0.2871\n",
      "(layer2.2.conv2.weight): 0.8730\n",
      "(layer2.2.bn2.weight): 0.2715\n",
      "(layer2.2.conv3.weight): 0.8291\n",
      "(layer2.2.bn3.weight): 0.3836\n",
      "(layer2.3.conv1.weight): 0.8601\n",
      "(layer2.3.bn1.weight): 0.2902\n",
      "(layer2.3.conv2.weight): 0.8886\n",
      "(layer2.3.bn2.weight): 0.2484\n",
      "(layer2.3.conv3.weight): 0.8448\n",
      "(layer2.3.bn3.weight): 0.3962\n",
      "(layer3.0.conv1.weight): 0.7924\n",
      "(layer3.0.bn1.weight): 0.2156\n",
      "(layer3.0.conv2.weight): 0.9198\n",
      "(layer3.0.bn2.weight): 0.2723\n",
      "(layer3.0.conv3.weight): 0.8559\n",
      "(layer3.0.bn3.weight): 0.3527\n",
      "(layer3.0.downsample.0.weight): 0.9054\n",
      "(layer3.0.downsample.1.weight): 0.4453\n",
      "(layer3.1.conv1.weight): 0.9124\n",
      "(layer3.1.bn1.weight): 0.3290\n",
      "(layer3.1.conv2.weight): 0.9147\n",
      "(layer3.1.bn2.weight): 0.2623\n",
      "(layer3.1.conv3.weight): 0.8715\n",
      "(layer3.1.bn3.weight): 0.4487\n",
      "(layer3.2.conv1.weight): 0.9016\n",
      "(layer3.2.bn1.weight): 0.3300\n",
      "(layer3.2.conv2.weight): 0.9256\n",
      "(layer3.2.bn2.weight): 0.2686\n",
      "(layer3.2.conv3.weight): 0.8960\n",
      "(layer3.2.bn3.weight): 0.4660\n",
      "(layer3.3.conv1.weight): 0.9107\n",
      "(layer3.3.bn1.weight): 0.2989\n",
      "(layer3.3.conv2.weight): 0.9315\n",
      "(layer3.3.bn2.weight): 0.2855\n",
      "(layer3.3.conv3.weight): 0.9007\n",
      "(layer3.3.bn3.weight): 0.4264\n",
      "(layer3.4.conv1.weight): 0.9023\n",
      "(layer3.4.bn1.weight): 0.3071\n",
      "(layer3.4.conv2.weight): 0.9310\n",
      "(layer3.4.bn2.weight): 0.2699\n",
      "(layer3.4.conv3.weight): 0.8988\n",
      "(layer3.4.bn3.weight): 0.3956\n",
      "(layer3.5.conv1.weight): 0.8874\n",
      "(layer3.5.bn1.weight): 0.2736\n",
      "(layer3.5.conv2.weight): 0.9305\n",
      "(layer3.5.bn2.weight): 0.2892\n",
      "(layer3.5.conv3.weight): 0.8744\n",
      "(layer3.5.bn3.weight): 0.2566\n",
      "(layer4.0.conv1.weight): 0.8922\n",
      "(layer4.0.bn1.weight): 0.2389\n",
      "(layer4.0.conv2.weight): 0.9143\n",
      "(layer4.0.bn2.weight): 0.2434\n",
      "(layer4.0.conv3.weight): 0.9365\n",
      "(layer4.0.bn3.weight): 0.0407\n",
      "(layer4.0.downsample.0.weight): 0.8915\n",
      "(layer4.0.downsample.1.weight): 0.0439\n",
      "(layer4.1.conv1.weight): 0.9782\n",
      "(layer4.1.bn1.weight): 0.2794\n",
      "(layer4.1.conv2.weight): 0.9560\n",
      "(layer4.1.bn2.weight): 0.2335\n",
      "(layer4.1.conv3.weight): 0.9420\n",
      "(layer4.1.bn3.weight): 0.0408\n",
      "(layer4.2.conv1.weight): 0.9656\n",
      "(layer4.2.bn1.weight): 0.2413\n",
      "(layer4.2.conv2.weight): 0.9544\n",
      "(layer4.2.bn2.weight): 0.2362\n",
      "(layer4.2.conv3.weight): 0.9196\n",
      "(layer4.2.bn3.weight): 0.0315\n",
      "(fc.weight): 0.0629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -7930.7488, Accuracy: 9975/19962 (50%)\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:42<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized norm of (weight - projection)\n",
      "(conv1.weight): 0.3095\n",
      "(bn1.weight): 0.1797\n",
      "(layer1.0.conv1.weight): 0.4565\n",
      "(layer1.0.bn1.weight): 0.2281\n",
      "(layer1.0.conv2.weight): 0.7412\n",
      "(layer1.0.bn2.weight): 0.2856\n",
      "(layer1.0.conv3.weight): 0.6847\n",
      "(layer1.0.bn3.weight): 0.2653\n",
      "(layer1.0.downsample.0.weight): 0.5181\n",
      "(layer1.0.downsample.1.weight): 0.1899\n",
      "(layer1.1.conv1.weight): 0.7560\n",
      "(layer1.1.bn1.weight): 0.2481\n",
      "(layer1.1.conv2.weight): 0.7858\n",
      "(layer1.1.bn2.weight): 0.2667\n",
      "(layer1.1.conv3.weight): 0.7367\n",
      "(layer1.1.bn3.weight): 0.4203\n",
      "(layer1.2.conv1.weight): 0.7919\n",
      "(layer1.2.bn1.weight): 0.2746\n",
      "(layer1.2.conv2.weight): 0.7987\n",
      "(layer1.2.bn2.weight): 0.2215\n",
      "(layer1.2.conv3.weight): 0.7431\n",
      "(layer1.2.bn3.weight): 0.3493\n",
      "(layer2.0.conv1.weight): 0.7336\n",
      "(layer2.0.bn1.weight): 0.2407\n",
      "(layer2.0.conv2.weight): 0.8851\n",
      "(layer2.0.bn2.weight): 0.2455\n",
      "(layer2.0.conv3.weight): 0.7761\n",
      "(layer2.0.bn3.weight): 0.3014\n",
      "(layer2.0.downsample.0.weight): 0.8033\n",
      "(layer2.0.downsample.1.weight): 0.2823\n",
      "(layer2.1.conv1.weight): 0.8801\n",
      "(layer2.1.bn1.weight): 0.4185\n",
      "(layer2.1.conv2.weight): 0.8682\n",
      "(layer2.1.bn2.weight): 0.2992\n",
      "(layer2.1.conv3.weight): 0.8167\n",
      "(layer2.1.bn3.weight): 0.2964\n",
      "(layer2.2.conv1.weight): 0.8484\n",
      "(layer2.2.bn1.weight): 0.2865\n",
      "(layer2.2.conv2.weight): 0.8711\n",
      "(layer2.2.bn2.weight): 0.2722\n",
      "(layer2.2.conv3.weight): 0.8242\n",
      "(layer2.2.bn3.weight): 0.3925\n",
      "(layer2.3.conv1.weight): 0.8560\n",
      "(layer2.3.bn1.weight): 0.2918\n",
      "(layer2.3.conv2.weight): 0.8765\n",
      "(layer2.3.bn2.weight): 0.2484\n",
      "(layer2.3.conv3.weight): 0.8351\n",
      "(layer2.3.bn3.weight): 0.3765\n",
      "(layer3.0.conv1.weight): 0.7856\n",
      "(layer3.0.bn1.weight): 0.2130\n",
      "(layer3.0.conv2.weight): 0.9113\n",
      "(layer3.0.bn2.weight): 0.2719\n",
      "(layer3.0.conv3.weight): 0.8538\n",
      "(layer3.0.bn3.weight): 0.3603\n",
      "(layer3.0.downsample.0.weight): 0.9004\n",
      "(layer3.0.downsample.1.weight): 0.4203\n",
      "(layer3.1.conv1.weight): 0.9212\n",
      "(layer3.1.bn1.weight): 0.3273\n",
      "(layer3.1.conv2.weight): 0.9223\n",
      "(layer3.1.bn2.weight): 0.2676\n",
      "(layer3.1.conv3.weight): 0.8758\n",
      "(layer3.1.bn3.weight): 0.4675\n",
      "(layer3.2.conv1.weight): 0.9009\n",
      "(layer3.2.bn1.weight): 0.3228\n",
      "(layer3.2.conv2.weight): 0.9177\n",
      "(layer3.2.bn2.weight): 0.2684\n",
      "(layer3.2.conv3.weight): 0.8883\n",
      "(layer3.2.bn3.weight): 0.4730\n",
      "(layer3.3.conv1.weight): 0.9059\n",
      "(layer3.3.bn1.weight): 0.2970\n",
      "(layer3.3.conv2.weight): 0.9238\n",
      "(layer3.3.bn2.weight): 0.2827\n",
      "(layer3.3.conv3.weight): 0.9026\n",
      "(layer3.3.bn3.weight): 0.4155\n",
      "(layer3.4.conv1.weight): 0.9047\n",
      "(layer3.4.bn1.weight): 0.3044\n",
      "(layer3.4.conv2.weight): 0.9359\n",
      "(layer3.4.bn2.weight): 0.2716\n",
      "(layer3.4.conv3.weight): 0.9046\n",
      "(layer3.4.bn3.weight): 0.3854\n",
      "(layer3.5.conv1.weight): 0.8861\n",
      "(layer3.5.bn1.weight): 0.2740\n",
      "(layer3.5.conv2.weight): 0.9255\n",
      "(layer3.5.bn2.weight): 0.2931\n",
      "(layer3.5.conv3.weight): 0.8718\n",
      "(layer3.5.bn3.weight): 0.2573\n",
      "(layer4.0.conv1.weight): 0.8965\n",
      "(layer4.0.bn1.weight): 0.2383\n",
      "(layer4.0.conv2.weight): 0.9177\n",
      "(layer4.0.bn2.weight): 0.2431\n",
      "(layer4.0.conv3.weight): 0.9384\n",
      "(layer4.0.bn3.weight): 0.0395\n",
      "(layer4.0.downsample.0.weight): 0.8905\n",
      "(layer4.0.downsample.1.weight): 0.0426\n",
      "(layer4.1.conv1.weight): 0.9789\n",
      "(layer4.1.bn1.weight): 0.2792\n",
      "(layer4.1.conv2.weight): 0.9569\n",
      "(layer4.1.bn2.weight): 0.2334\n",
      "(layer4.1.conv3.weight): 0.9432\n",
      "(layer4.1.bn3.weight): 0.0396\n",
      "(layer4.2.conv1.weight): 0.9660\n",
      "(layer4.2.bn1.weight): 0.2413\n",
      "(layer4.2.conv2.weight): 0.9559\n",
      "(layer4.2.bn2.weight): 0.2361\n",
      "(layer4.2.conv3.weight): 0.9218\n",
      "(layer4.2.bn3.weight): 0.0307\n",
      "(fc.weight): 0.0604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -8447.1964, Accuracy: 9975/19962 (50%)\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:37<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized norm of (weight - projection)\n",
      "(conv1.weight): 0.3086\n",
      "(bn1.weight): 0.1811\n",
      "(layer1.0.conv1.weight): 0.4482\n",
      "(layer1.0.bn1.weight): 0.2283\n",
      "(layer1.0.conv2.weight): 0.7428\n",
      "(layer1.0.bn2.weight): 0.2863\n",
      "(layer1.0.conv3.weight): 0.6910\n",
      "(layer1.0.bn3.weight): 0.2673\n",
      "(layer1.0.downsample.0.weight): 0.5148\n",
      "(layer1.0.downsample.1.weight): 0.1894\n",
      "(layer1.1.conv1.weight): 0.7614\n",
      "(layer1.1.bn1.weight): 0.2473\n",
      "(layer1.1.conv2.weight): 0.7876\n",
      "(layer1.1.bn2.weight): 0.2673\n",
      "(layer1.1.conv3.weight): 0.7380\n",
      "(layer1.1.bn3.weight): 0.4226\n",
      "(layer1.2.conv1.weight): 0.7855\n",
      "(layer1.2.bn1.weight): 0.2788\n",
      "(layer1.2.conv2.weight): 0.7898\n",
      "(layer1.2.bn2.weight): 0.2224\n",
      "(layer1.2.conv3.weight): 0.7438\n",
      "(layer1.2.bn3.weight): 0.3333\n",
      "(layer2.0.conv1.weight): 0.7286\n",
      "(layer2.0.bn1.weight): 0.2416\n",
      "(layer2.0.conv2.weight): 0.8769\n",
      "(layer2.0.bn2.weight): 0.2447\n",
      "(layer2.0.conv3.weight): 0.7732\n",
      "(layer2.0.bn3.weight): 0.3098\n",
      "(layer2.0.downsample.0.weight): 0.7996\n",
      "(layer2.0.downsample.1.weight): 0.2837\n",
      "(layer2.1.conv1.weight): 0.8789\n",
      "(layer2.1.bn1.weight): 0.4160\n",
      "(layer2.1.conv2.weight): 0.8691\n",
      "(layer2.1.bn2.weight): 0.2997\n",
      "(layer2.1.conv3.weight): 0.8231\n",
      "(layer2.1.bn3.weight): 0.2971\n",
      "(layer2.2.conv1.weight): 0.8400\n",
      "(layer2.2.bn1.weight): 0.2892\n",
      "(layer2.2.conv2.weight): 0.8770\n",
      "(layer2.2.bn2.weight): 0.2715\n",
      "(layer2.2.conv3.weight): 0.8297\n",
      "(layer2.2.bn3.weight): 0.3861\n",
      "(layer2.3.conv1.weight): 0.8648\n",
      "(layer2.3.bn1.weight): 0.2903\n",
      "(layer2.3.conv2.weight): 0.8939\n",
      "(layer2.3.bn2.weight): 0.2478\n",
      "(layer2.3.conv3.weight): 0.8507\n",
      "(layer2.3.bn3.weight): 0.3952\n",
      "(layer3.0.conv1.weight): 0.7966\n",
      "(layer3.0.bn1.weight): 0.2157\n",
      "(layer3.0.conv2.weight): 0.9267\n",
      "(layer3.0.bn2.weight): 0.2740\n",
      "(layer3.0.conv3.weight): 0.8639\n",
      "(layer3.0.bn3.weight): 0.3595\n",
      "(layer3.0.downsample.0.weight): 0.9136\n",
      "(layer3.0.downsample.1.weight): 0.4443\n",
      "(layer3.1.conv1.weight): 0.9281\n",
      "(layer3.1.bn1.weight): 0.3318\n",
      "(layer3.1.conv2.weight): 0.9250\n",
      "(layer3.1.bn2.weight): 0.2644\n",
      "(layer3.1.conv3.weight): 0.8795\n",
      "(layer3.1.bn3.weight): 0.4643\n",
      "(layer3.2.conv1.weight): 0.9187\n",
      "(layer3.2.bn1.weight): 0.3264\n",
      "(layer3.2.conv2.weight): 0.9354\n",
      "(layer3.2.bn2.weight): 0.2660\n",
      "(layer3.2.conv3.weight): 0.9022\n",
      "(layer3.2.bn3.weight): 0.4885\n",
      "(layer3.3.conv1.weight): 0.9217\n",
      "(layer3.3.bn1.weight): 0.3000\n",
      "(layer3.3.conv2.weight): 0.9485\n",
      "(layer3.3.bn2.weight): 0.2852\n",
      "(layer3.3.conv3.weight): 0.9161\n",
      "(layer3.3.bn3.weight): 0.4367\n",
      "(layer3.4.conv1.weight): 0.9174\n",
      "(layer3.4.bn1.weight): 0.3051\n",
      "(layer3.4.conv2.weight): 0.9411\n",
      "(layer3.4.bn2.weight): 0.2722\n",
      "(layer3.4.conv3.weight): 0.9021\n",
      "(layer3.4.bn3.weight): 0.3834\n",
      "(layer3.5.conv1.weight): 0.8940\n",
      "(layer3.5.bn1.weight): 0.2762\n",
      "(layer3.5.conv2.weight): 0.9299\n",
      "(layer3.5.bn2.weight): 0.3055\n",
      "(layer3.5.conv3.weight): 0.8654\n",
      "(layer3.5.bn3.weight): 0.2544\n",
      "(layer4.0.conv1.weight): 0.8941\n",
      "(layer4.0.bn1.weight): 0.2389\n",
      "(layer4.0.conv2.weight): 0.9121\n",
      "(layer4.0.bn2.weight): 0.2420\n",
      "(layer4.0.conv3.weight): 0.9339\n",
      "(layer4.0.bn3.weight): 0.0370\n",
      "(layer4.0.downsample.0.weight): 0.8920\n",
      "(layer4.0.downsample.1.weight): 0.0396\n",
      "(layer4.1.conv1.weight): 0.9775\n",
      "(layer4.1.bn1.weight): 0.2805\n",
      "(layer4.1.conv2.weight): 0.9522\n",
      "(layer4.1.bn2.weight): 0.2332\n",
      "(layer4.1.conv3.weight): 0.9374\n",
      "(layer4.1.bn3.weight): 0.0372\n",
      "(layer4.2.conv1.weight): 0.9660\n",
      "(layer4.2.bn1.weight): 0.2414\n",
      "(layer4.2.conv2.weight): 0.9526\n",
      "(layer4.2.bn2.weight): 0.2353\n",
      "(layer4.2.conv3.weight): 0.9208\n",
      "(layer4.2.bn3.weight): 0.0293\n",
      "(fc.weight): 0.0551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -9655.8268, Accuracy: 9975/19962 (50%)\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:37<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized norm of (weight - projection)\n",
      "(conv1.weight): 0.3118\n",
      "(bn1.weight): 0.1800\n",
      "(layer1.0.conv1.weight): 0.4517\n",
      "(layer1.0.bn1.weight): 0.2287\n",
      "(layer1.0.conv2.weight): 0.7401\n",
      "(layer1.0.bn2.weight): 0.2825\n",
      "(layer1.0.conv3.weight): 0.6837\n",
      "(layer1.0.bn3.weight): 0.2635\n",
      "(layer1.0.downsample.0.weight): 0.5183\n",
      "(layer1.0.downsample.1.weight): 0.1912\n",
      "(layer1.1.conv1.weight): 0.7497\n",
      "(layer1.1.bn1.weight): 0.2422\n",
      "(layer1.1.conv2.weight): 0.7789\n",
      "(layer1.1.bn2.weight): 0.2653\n",
      "(layer1.1.conv3.weight): 0.7288\n",
      "(layer1.1.bn3.weight): 0.4281\n",
      "(layer1.2.conv1.weight): 0.7622\n",
      "(layer1.2.bn1.weight): 0.2733\n",
      "(layer1.2.conv2.weight): 0.7779\n",
      "(layer1.2.bn2.weight): 0.2247\n",
      "(layer1.2.conv3.weight): 0.7401\n",
      "(layer1.2.bn3.weight): 0.3506\n",
      "(layer2.0.conv1.weight): 0.7243\n",
      "(layer2.0.bn1.weight): 0.2429\n",
      "(layer2.0.conv2.weight): 0.8596\n",
      "(layer2.0.bn2.weight): 0.2483\n",
      "(layer2.0.conv3.weight): 0.7630\n",
      "(layer2.0.bn3.weight): 0.3078\n",
      "(layer2.0.downsample.0.weight): 0.7893\n",
      "(layer2.0.downsample.1.weight): 0.2757\n",
      "(layer2.1.conv1.weight): 0.8552\n",
      "(layer2.1.bn1.weight): 0.4176\n",
      "(layer2.1.conv2.weight): 0.8580\n",
      "(layer2.1.bn2.weight): 0.2991\n",
      "(layer2.1.conv3.weight): 0.8145\n",
      "(layer2.1.bn3.weight): 0.2934\n",
      "(layer2.2.conv1.weight): 0.8305\n",
      "(layer2.2.bn1.weight): 0.2857\n",
      "(layer2.2.conv2.weight): 0.8596\n",
      "(layer2.2.bn2.weight): 0.2691\n",
      "(layer2.2.conv3.weight): 0.8104\n",
      "(layer2.2.bn3.weight): 0.3959\n",
      "(layer2.3.conv1.weight): 0.8430\n",
      "(layer2.3.bn1.weight): 0.2914\n",
      "(layer2.3.conv2.weight): 0.8775\n",
      "(layer2.3.bn2.weight): 0.2516\n",
      "(layer2.3.conv3.weight): 0.8328\n",
      "(layer2.3.bn3.weight): 0.4027\n",
      "(layer3.0.conv1.weight): 0.7779\n",
      "(layer3.0.bn1.weight): 0.2192\n",
      "(layer3.0.conv2.weight): 0.9070\n",
      "(layer3.0.bn2.weight): 0.2723\n",
      "(layer3.0.conv3.weight): 0.8455\n",
      "(layer3.0.bn3.weight): 0.3674\n",
      "(layer3.0.downsample.0.weight): 0.8829\n",
      "(layer3.0.downsample.1.weight): 0.4316\n",
      "(layer3.1.conv1.weight): 0.8978\n",
      "(layer3.1.bn1.weight): 0.3242\n",
      "(layer3.1.conv2.weight): 0.8970\n",
      "(layer3.1.bn2.weight): 0.2648\n",
      "(layer3.1.conv3.weight): 0.8592\n",
      "(layer3.1.bn3.weight): 0.4685\n",
      "(layer3.2.conv1.weight): 0.8943\n",
      "(layer3.2.bn1.weight): 0.3286\n",
      "(layer3.2.conv2.weight): 0.9104\n",
      "(layer3.2.bn2.weight): 0.2692\n",
      "(layer3.2.conv3.weight): 0.8862\n",
      "(layer3.2.bn3.weight): 0.4599\n",
      "(layer3.3.conv1.weight): 0.8948\n",
      "(layer3.3.bn1.weight): 0.2987\n",
      "(layer3.3.conv2.weight): 0.9099\n",
      "(layer3.3.bn2.weight): 0.2891\n",
      "(layer3.3.conv3.weight): 0.8941\n",
      "(layer3.3.bn3.weight): 0.4221\n",
      "(layer3.4.conv1.weight): 0.9064\n",
      "(layer3.4.bn1.weight): 0.3052\n",
      "(layer3.4.conv2.weight): 0.9321\n",
      "(layer3.4.bn2.weight): 0.2685\n",
      "(layer3.4.conv3.weight): 0.8946\n",
      "(layer3.4.bn3.weight): 0.4032\n",
      "(layer3.5.conv1.weight): 0.8856\n",
      "(layer3.5.bn1.weight): 0.2774\n",
      "(layer3.5.conv2.weight): 0.9250\n",
      "(layer3.5.bn2.weight): 0.3054\n",
      "(layer3.5.conv3.weight): 0.8575\n",
      "(layer3.5.bn3.weight): 0.2548\n",
      "(layer4.0.conv1.weight): 0.8924\n",
      "(layer4.0.bn1.weight): 0.2405\n",
      "(layer4.0.conv2.weight): 0.9119\n",
      "(layer4.0.bn2.weight): 0.2424\n",
      "(layer4.0.conv3.weight): 0.9344\n",
      "(layer4.0.bn3.weight): 0.0366\n",
      "(layer4.0.downsample.0.weight): 0.8784\n",
      "(layer4.0.downsample.1.weight): 0.0393\n",
      "(layer4.1.conv1.weight): 0.9764\n",
      "(layer4.1.bn1.weight): 0.2819\n",
      "(layer4.1.conv2.weight): 0.9518\n",
      "(layer4.1.bn2.weight): 0.2334\n",
      "(layer4.1.conv3.weight): 0.9368\n",
      "(layer4.1.bn3.weight): 0.0369\n",
      "(layer4.2.conv1.weight): 0.9658\n",
      "(layer4.2.bn1.weight): 0.2416\n",
      "(layer4.2.conv2.weight): 0.9530\n",
      "(layer4.2.bn2.weight): 0.2353\n",
      "(layer4.2.conv3.weight): 0.9210\n",
      "(layer4.2.bn3.weight): 0.0291\n",
      "(fc.weight): 0.0546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -10465.6272, Accuracy: 9975/19962 (50%)\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 61/115 [00:22<00:20,  2.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1086c7d58213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0musr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_users\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0musr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdlz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0musr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdlz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0musr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdlz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0musr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdlz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0musr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdlz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0musr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mw_locals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-bb955840854c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_loader, test_loader, optimizer, Z, U, report)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madmm_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/decentralized_models/compare_with/gossip_based/utils.py\u001b[0m in \u001b[0;36madmm_loss\u001b[0;34m(args, device, model, Z, U, output, target)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mdlz = dict()\n",
    "for usr in range(args.num_users):\n",
    "    train_loader = torch.utils.data.DataLoader(DatasetSplit(trainset, dict_users[usr]), batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    if args.model == 'resnet':\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = torch.nn.Linear(num_ftrs, 2)\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model = LeNet().to(device) if args.dataset == \"mnist\" else AlexNet().to(device)\n",
    "    \n",
    "    optimizer = PruneAdam(model.named_parameters(), lr=args.lr, eps=args.adam_epsilon)\n",
    "    pretrain(args, model, device, train_loader, test_loader, optimizer)\n",
    "    Z, U = initialize_Z_and_U(model)\n",
    "    mdlz[usr] = (model, optimizer, Z, U)\n",
    "    \n",
    "for epoch in range(args.num_epochs):\n",
    "    w_locals=[]\n",
    "    idxs_users = np.random.choice(range(args.num_users), 2, replace=False)\n",
    "    for usr in idxs_users:\n",
    "        report = True if usr == 0 else False\n",
    "        train_loader = torch.utils.data.DataLoader(DatasetSplit(trainset, dict_users[usr]), batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "        train(args, mdlz[usr][0], device, train_loader, test_loader, mdlz[usr][1], mdlz[usr][2], mdlz[usr][3], report=report)\n",
    "        w = mdlz[usr][0].state_dict()\n",
    "        w_locals.append(copy.deepcopy(w))\n",
    "\n",
    "    # update global weights\n",
    "    w_glob = FedAvg(w_locals)\n",
    "\n",
    "    for idx in idxs_users:\n",
    "        # copy weight to net_glob\n",
    "        mdlz[idx][0].load_state_dict(w_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Apply pruning\n",
    "for usr in range(args.num_users):\n",
    "    mask = apply_l1_prune(mdlz[usr][0], device, args) if args.l1 else apply_prune(mdlz[usr][0], device, args)\n",
    "    print_prune(model)\n",
    "    test(args, mdlz[usr][0], device, test_loader)\n",
    "    retrain(args, model, mask, device, train_loader, test_loader, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "confusion_matrix = torch.zeros(10, 10)\n",
    "mdlz[0][0].eval()\n",
    "# testing\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "l = len(test_loader)\n",
    "for idx, (data, target) in enumerate(test_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    log_probs = mdlz[0][0](data)\n",
    "    # sum up batch loss\n",
    "    test_loss += F.cross_entropy(log_probs, target, reduction='sum').item()\n",
    "    # get the index of the max log-probability\n",
    "    y_pred = log_probs.data.max(1, keepdim=True)[1]\n",
    "    correct += y_pred.eq(target.data.view_as(y_pred)).long().cpu().sum()\n",
    "\n",
    "    for t, p in zip(target.data, y_pred.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gossip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
