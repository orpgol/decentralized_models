{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import random\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from scipy.stats import entropy, ks_2samp\n",
    "from scipy.special import kl_div\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard\n",
    "\n",
    "import traceback\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logname = 'logs/decentralized_multi_agent'\n",
    "logging.basicConfig(filename=logname,\n",
    "                            filemode='a',\n",
    "                            format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                            datefmt='%H:%M:%S',\n",
    "                            level=logging.DEBUG)\n",
    "\n",
    "logging.info(\"Running Decentralized Learning test\")\n",
    "\n",
    "logger = logging.getLogger('Decentralized_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1448404d50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reproduce randomness for fair comparison\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image  Class\n",
       "0  Image1      0\n",
       "1  Image2      0\n",
       "2  Image3      1\n",
       "3  Image4      1\n",
       "4  Image5      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_df = pd.read_csv('../data/brain_tumor.csv',usecols=[0,1])\n",
    "brain_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2079\n",
       "1    1683\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, main_dir, x, y, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        self.y = y\n",
    "        self.all_imgs = x\n",
    "#         self.total_imgs = natsort.natsorted(all_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.all_imgs[idx]+'.jpg')\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image,self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are saving a fraction of random data to be used in training\n",
    "test_frac = int(len(brain_df.Image) * 0.19)\n",
    "frac1 = int(len(brain_df.Image) * 0.46)\n",
    "frac2 = int(len(brain_df.Image) * 0.73)\n",
    "\n",
    "x_train1 = np.array(brain_df.iloc[test_frac:frac1].Image)\n",
    "y_train1 = np.array(brain_df.iloc[test_frac:frac1].Class)\n",
    "x_train2 = np.array(brain_df.iloc[frac1:frac2].Image)\n",
    "y_train2 = np.array(brain_df.iloc[frac1:frac2].Class)\n",
    "x_train3 = np.array(brain_df.iloc[frac2:].Image)\n",
    "y_train3 = np.array(brain_df.iloc[frac2:].Class)\n",
    "\n",
    "x_test = np.array(brain_df.iloc[:test_frac].Image)\n",
    "y_test = np.array(brain_df.iloc[:test_frac].Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(255),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor()])\n",
    "# train_data = datasets.ImageFolder('../data/brain_tumor_images/', transform=transform)\n",
    "\n",
    "trainset1 = CustomDataSet('../data/brain_tumor_images/brain_tumor/',x=x_train1,y=y_train1, transform=transform)\n",
    "trainset2 = CustomDataSet('../data/brain_tumor_images/brain_tumor/',x=x_train2,y=y_train2, transform=transform)\n",
    "trainset3 = CustomDataSet('../data/brain_tumor_images/brain_tumor/',x=x_train3,y=y_train3, transform=transform)\n",
    "testset = CustomDataSet('../data/brain_tumor_images/brain_tumor/',x=x_test,y=y_test, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader1 = DataLoader(trainset1 , batch_size=16, shuffle=True, num_workers=1, drop_last=False)\n",
    "train_loader2 = DataLoader(trainset2 , batch_size=16, shuffle=True, num_workers=1, drop_last=False)\n",
    "train_loader3 = DataLoader(trainset3 , batch_size=16, shuffle=True, num_workers=1, drop_last=False)\n",
    "test_loader = DataLoader(testset , batch_size=16, shuffle=True, num_workers=1, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.3    # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test that things are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = next(iter(train_loader1))\n",
    "imshow(torchvision.utils.make_grid(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decide on a GPU to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(device)\n",
    "# device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "# device2 = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decentralized Pairwise Knowledge Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models used in knowledge transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_init(m):\n",
    "    if isinstance(m, (torch.nn.Linear)):\n",
    "        torch.nn.init.sparse_(m.weight, sparsity=0.33)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "    elif isinstance(m, (torch.nn.Conv2d)):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "    elif isinstance(m, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d)):\n",
    "        m.weight.data.fill_(1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "class Decenter(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super(Decenter, self).__init__()\n",
    "        if len(shape) == 1:\n",
    "            shape = shape[0]\n",
    "            self.dim = 0\n",
    "        elif len(shape) == 2:\n",
    "            shape = shape[1]\n",
    "            self.dim = 1\n",
    "        self.translation = torch.nn.Sequential(\n",
    "#             torch.nn.Tanh(),\n",
    "            torch.nn.Linear(shape*3, shape)\n",
    "        )\n",
    "\n",
    "#         self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, source1, source2, target):\n",
    "        x = torch.cat((source1, source2, target), self.dim)\n",
    "#         x = torch.cat((torch.flatten(source), torch.flatten(target)), 0)\n",
    "#         x = torch.add(torch.flatten(source).to(\"cpu\"), torch.flatten(target).to(\"cpu\"))\n",
    "        res = self.translation(x)\n",
    "#         res = res.reshape(target.shape)\n",
    "        return res\n",
    "    \n",
    "    \n",
    "class Interpolate(torch.nn.Module):\n",
    "    def __init__(self, size, mode):\n",
    "        super(Interpolate, self).__init__()\n",
    "        self.interp = torch.nn.functional.interpolate\n",
    "        self.size = size\n",
    "        self.mode = mode\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.interp(x, size=self.size, mode=self.mode, align_corners=False)\n",
    "        return x\n",
    "    \n",
    "class Reshape(torch.nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "    \n",
    "class Decenter_pooled(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super(Decenter_pooled, self).__init__()\n",
    "        self.shape = shape\n",
    "        self.translation = torch.nn.Sequential(\n",
    "#             torch.nn.BatchNorm2d(channels_out),\n",
    "#             torch.nn.AdaptiveAvgPool2d(1),\n",
    "            Interpolate(size=1, mode='bilinear'),\n",
    "            Reshape(shape[0], shape[1]*2),\n",
    "            torch.nn.Linear(shape[1]*2, shape[1]*shape[-1]*shape[-1]),\n",
    "#             Reshape(shape[0], shape[1] ,1 ,1),\n",
    "        )\n",
    "\n",
    "#         self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        x = torch.cat((source, target), 1)\n",
    "        res = self.translation(x)\n",
    "        res = res.view(self.shape[0], self.shape[1], self.shape[2], self.shape[3])\n",
    "        return res\n",
    "    \n",
    "    \n",
    "class Decenter_conv(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super(Decenter_conv, self).__init__()\n",
    "        self.shape = shape\n",
    "        channels_in = shape[1]*3\n",
    "        channels_out = shape[1]\n",
    "        self.translation = torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm2d(channels_in),\n",
    "            torch.nn.Conv2d(channels_in, channels_out, 3, stride=1, padding=1)\n",
    "#             torch.nn.ConvTranspose2d(channels_in, channels_out, 3, stride=1, padding=1)\n",
    "#             torch.nn.Linear(shape[0]*2, shape[0]*4),\n",
    "#             torch.nn.Dropout(p=0.5),\n",
    "#             torch.nn.Linear(shape[0]*2, shape[0]),\n",
    "#             torch.nn.AdaptiveAvgPool2d((shape[-2],shape[-1])),\n",
    "#             torch.nn.Conv2d(channels_out, channels_out, 3, stride=1, padding=1)\n",
    "\n",
    "        )\n",
    "        self.translation2 = torch.nn.Sequential(\n",
    "            torch.nn.AdaptiveMaxPool2d((shape[-2],shape[-1])),\n",
    "        )\n",
    "\n",
    "#         self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, source1, source2, target):\n",
    "        x = torch.cat((source1, source2, target), 1)\n",
    "#         x = x.reshape(-1, x.shape[0])\n",
    "#         x = torch.cat((torch.flatten(source), torch.flatten(target)), 0)\n",
    "#         x = torch.add(torch.flatten(source).to(\"cpu\"), torch.flatten(target).to(\"cpu\"))\n",
    "        res = self.translation(x)\n",
    "#         res = res.reshape(self.shape)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the local training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hooks are used to investigate the effect of gradiant decent on weights. Not necessary for simply reproducing paper results. \n",
    "grad_dict: dict = {}\n",
    "def fc_hook(layer_name, grad_input, grad_output): \n",
    "    if layer_name not in grad_dict:\n",
    "        grad_dict[layer_name] = {}\n",
    "        grad_dict[layer_name][\"grad_input\"] = []\n",
    "        grad_dict[layer_name][\"grad_output\"] = []\n",
    "        grad_dict[layer_name][\"labels\"] = []\n",
    "        \n",
    "#     print(grad_input)\n",
    "#     print(grad_output)\n",
    "    grad_dict[layer_name][\"grad_input\"].append(grad_input[0].cpu().numpy())\n",
    "    grad_dict[layer_name][\"grad_output\"].append(grad_output[0].cpu().numpy())\n",
    "    \n",
    "# def reserve_step(source, target):\n",
    "    \n",
    "\n",
    "matlst = []\n",
    "fclst = []\n",
    "\n",
    "## Option are used for simulating remote agents using pairwise knowledge transfer \n",
    "options = {0: ['trainA', 'validA','reservedAB'], \n",
    "           1: ['trainB','validB','reservedBA'],\n",
    "           2: ['trainC','validC','reservedCA','validC']}\n",
    "\n",
    "def train_model(dataloders, model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    writer = SummaryWriter('runs/') \n",
    "\n",
    "    since = time.time()\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    best_model_wts = 0.0\n",
    "    best_acc = 0.0\n",
    "    dataset_sizes = {'trainA': len(dataloders['trainA'].sampler),\n",
    "                     'trainB': len(dataloders['trainB'].sampler),\n",
    "                     'trainC': len(dataloders['trainC'].sampler),\n",
    "                     'ABtoC': len(dataloders['ABtoC'].sampler),\n",
    "                     'validA': len(dataloders['validA'].sampler),\n",
    "                     'validB': len(dataloders['validB'].sampler),\n",
    "                     'validC': len(dataloders['validC'].sampler)}\n",
    "\n",
    "    i = 0\n",
    "    ivc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['trainA', 'validA','trainB','validB','trainC','validC','ABtoC','validC']:  ## this sequense simualtes a half mesh configuation\n",
    "#         choice = np.random.choice(range(3), replace=False)\n",
    "#         for phase in options[choice]:\n",
    "            if phase not in ['validA','validB','validC']:\n",
    "                model[phase].train(True)\n",
    "            else:\n",
    "                model['trainA'].train(False)\n",
    "                model['trainB'].train(False)\n",
    "                model['trainC'].train(False)\n",
    "            \n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            ## if its a transfer phase, swap layers using the pipline models\n",
    "            if phase in ['ABtoC']:\n",
    "                if phase == 'ABtoC':\n",
    "                    sd = model[phase].state_dict()\n",
    "                    for key, value in mdlzAC.items():\n",
    "                        shape = model['trainC'].state_dict()[key].shape\n",
    "                        mdl = value[1](shape).to(device)\n",
    "                        checkpoint = torch.load(value[0])\n",
    "                        mdl.load_state_dict(checkpoint['model_state_dict'])\n",
    "                        mdl.eval()\n",
    "                        sd[key] = mdl(copy.deepcopy(model['trainA'].state_dict()[key]),\n",
    "                                      copy.deepcopy(model['trainB'].state_dict()[key]),\n",
    "                                      copy.deepcopy(model['trainC'].state_dict()[key]))\n",
    "#                         torch.save({'model_state_dict': mdl.state_dict()}, value[0])\n",
    "                        \n",
    "#                         if key == 'conv1.weight':\n",
    "#                             matlst.append(sd[key])\n",
    "#                         elif key == 'fc.weight':\n",
    "#                             fclst.append(sd[key])\n",
    "                    model[phase].load_state_dict(sd)            \n",
    "                    \n",
    "            for inputs, labels in dataloders[phase]:\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer[phase].zero_grad()\n",
    "\n",
    "                outputs = model[phase](inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                \n",
    "                ## if its a transfer phase, compute remote loss term\n",
    "                if phase in ['ABtoC']:\n",
    "                    loss_a = criterion['trainC'](outputs, labels)\n",
    "#                     batch_size = labels.shape[0]\n",
    "#                     # Dummy input that HAS to be 2D for the scatter (you can use view(-1,1) if needed)\n",
    "#                     y = labels.reshape(-1,1)\n",
    "#                     # One hot encoding buffer that you create out of the loop and just keep reusing\n",
    "#                     y_onehot = torch.FloatTensor(batch_size, 10).to(device)\n",
    "\n",
    "#                     # In your for loop\n",
    "#                     y_onehot.zero_()\n",
    "#                     y_onehot.scatter_(1, y, 1)\n",
    "\n",
    "                    if phase == 'ABtoC':\n",
    "                        outputs2 = model['trainA'](inputs)\n",
    "                        outputs3 = model['trainB'](inputs)\n",
    "    \n",
    "                    sm = torch.nn.Softmax(dim=1)\n",
    "                    outputs = sm(outputs)\n",
    "                    outputs2 = sm(outputs2)\n",
    "                    outputs3 = sm(outputs3)\n",
    "                    loss_b = criterion[phase](outputs, outputs2)\n",
    "                    loss_c = criterion[phase](outputs, outputs3)\n",
    "                    loss = (loss_a + (loss_b + loss_c)/2)/2\n",
    "                    \n",
    "                ## if its not a transfer phase, compute local loss term\n",
    "                else:\n",
    "                    loss = criterion[phase](outputs, labels)\n",
    "\n",
    "                ## if its not a validation phase, optimize our models\n",
    "                if phase not in ['validA','validB','validC']:\n",
    "                    loss.backward()\n",
    "                    optimizer[phase].step()\n",
    "                    \n",
    "                    if phase == 'ABtoC':\n",
    "#                         loss_b.backward(retain_graph=False)\n",
    "                        for key, value in mdlzAC.items():\n",
    "                            shape = model['trainC'].state_dict()[key].shape\n",
    "                            mdl = value[1](shape).to(device)\n",
    "                            opti = torch.optim.AdamW(mdl.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "                            checkpoint = torch.load(value[0])\n",
    "                            mdl.load_state_dict(checkpoint['model_state_dict'])\n",
    "                            mdl.train(True)\n",
    "                            opti.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#                             opti.zero_grad()\n",
    "                            opti.step()\n",
    "                            torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                                        'optimizer_state_dict': opti.state_dict(),\n",
    "                                        'factor': checkpoint['factor'],\n",
    "                                        'patience': checkpoint['patience'],\n",
    "                                        'scheduler_state_dict': checkpoint['scheduler_state_dict']},\n",
    "                                        value[0])\n",
    "                            \n",
    "                    \n",
    "                    ## Back prop hook\n",
    "#                     grad_dict[\"fc\"][\"labels\"].append(labels.cpu().numpy())\n",
    "\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            ## update scheduler for each model\n",
    "            if phase in ['validA','validB','validC']:\n",
    "                scheduler[phase].step(running_loss)\n",
    "                \n",
    "            elif phase == 'ABtoC':\n",
    "                for key, value in mdlzAC.items():\n",
    "                    checkpoint = torch.load(value[0])\n",
    "                    sched = lr_scheduler.ReduceLROnPlateau(optimizerC, 'min', factor=checkpoint['factor'], patience=checkpoint['patience'])\n",
    "                    sched.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "                    sched.step(running_loss)\n",
    "                    torch.save({'model_state_dict': checkpoint['model_state_dict'],\n",
    "                                'optimizer_state_dict': checkpoint['optimizer_state_dict'],\n",
    "                                'factor': checkpoint['factor'],\n",
    "                                'patience': checkpoint['patience'],\n",
    "                                'scheduler_state_dict': sched.state_dict()},\n",
    "                                value[0])\n",
    "                \n",
    "            ## report results\n",
    "            if phase not in ['validA','validB','validC']:\n",
    "                train_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                train_epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            else:\n",
    "                valid_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                valid_epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "                print('Epoch [{}/{}] phase: {} train loss: {:.4f} acc: {:.4f} ' \n",
    "                      'valid loss: {:.4f} acc: {:.4f}'.format(\n",
    "                        epoch, num_epochs - 1,\n",
    "                        phase,\n",
    "                        train_epoch_loss, train_epoch_acc, \n",
    "                        valid_epoch_loss, valid_epoch_acc))\n",
    "                print() \n",
    "                logger.info('Epoch [{}/{}] phase: {} train loss: {:.4f} acc: {:.4f} ' \n",
    "                      'valid loss: {:.4f} acc: {:.4f}'.format(\n",
    "                        epoch, num_epochs - 1,\n",
    "                        phase,\n",
    "                        train_epoch_loss, train_epoch_acc, \n",
    "                        valid_epoch_loss, valid_epoch_acc))\n",
    "                \n",
    "                ## Writing to tensorboard\n",
    "#                 if phase == 'validC':\n",
    "#                     ivc += 1\n",
    "#                     if ivc == 2:\n",
    "#                         writer.add_histogram('distribution centers/our_full_mesh', outputs, i)\n",
    "\n",
    "#                         writer.add_scalar('train/loss_our_full_mesh', train_epoch_loss, epoch)\n",
    "#                         writer.add_scalar('train/accuracy_our_full_mesh', train_epoch_acc, epoch)\n",
    "\n",
    "#                         writer.add_scalar('valid/loss_our_full_mesh', valid_epoch_loss, epoch)\n",
    "#                         writer.add_scalar('valid/accuracy_our_full_mesh', valid_epoch_acc, epoch)\n",
    "#                         ivc = 0\n",
    "\n",
    "                \n",
    "            if phase in ['validA','validB','validC'] and valid_epoch_acc > best_acc:\n",
    "                best_acc = valid_epoch_acc\n",
    "                best_model_wts = model[phase].state_dict()\n",
    "\n",
    "            i+=1\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    logger.info('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    writer.close()\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Define models for network of learners, optimizers, and loss terms\n",
    "\n",
    "resnetA = models.resnet18(pretrained=False)\n",
    "resnetB = models.resnet18(pretrained=False)\n",
    "resnetC = models.resnet18(pretrained=False)\n",
    "# freeze all model parameters\n",
    "# for param in resnet.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# new final layer with 2 classes\n",
    "num_ftrsA = resnetA.fc.in_features\n",
    "resnetA.fc = torch.nn.Linear(num_ftrsA, 2)\n",
    "\n",
    "num_ftrsB = resnetB.fc.in_features\n",
    "resnetB.fc = torch.nn.Linear(num_ftrsB, 2)\n",
    "\n",
    "num_ftrsC = resnetC.fc.in_features\n",
    "resnetC.fc = torch.nn.Linear(num_ftrsC, 2)\n",
    "\n",
    "def fc_backward_hook(module, grad_input, grad_output):  # module is Linear in this case. Ignored.\n",
    "        fc_hook(\"fc\", grad_input, grad_output)\n",
    "resnetA.fc_hook_handle = resnetA.fc.register_backward_hook(fc_backward_hook)\n",
    "resnetB.fc_hook_handle = resnetB.fc.register_backward_hook(fc_backward_hook)\n",
    "resnetC.fc_hook_handle = resnetC.fc.register_backward_hook(fc_backward_hook)\n",
    "\n",
    "\n",
    "def roc_auc_score_micro(y_pred_proba, y_true):\n",
    "    y_pred_proba = y_pred_proba.detach().cpu()\n",
    "    y_true = y_true.detach().cpu()\n",
    "    return metrics.roc_auc_score(\n",
    "        label_binarize(y_true, classes=list(range(y_pred_proba.shape[1]))).ravel(),\n",
    "        y_pred_proba.flatten())\n",
    "\n",
    "\n",
    "resnetA = resnetA.to(device)\n",
    "resnetB = resnetB.to(device)\n",
    "resnetC = resnetC.to(device)\n",
    "\n",
    "criterionA = torch.nn.CrossEntropyLoss()\n",
    "# criterionB = torch.nn.CrossEntropyLoss()\n",
    "# criterionA = torch.nn.KLDivLoss()\n",
    "criterionB = torch.nn.KLDivLoss(reduction = 'batchmean')\n",
    "# criterionB = torch.nn.KLDivLoss(reduction = 'mean')\n",
    "# criterionB = torch.nn.MSELoss()\n",
    "optimizerA = torch.optim.SGD(resnetA.parameters(), lr=0.0001, momentum=0.9)\n",
    "optimizerB = torch.optim.SGD(resnetB.parameters(), lr=0.0001, momentum=0.9)\n",
    "optimizerC = torch.optim.SGD(resnetC.parameters(), lr=0.0001, momentum=0.9)\n",
    "# optimizerA = torch.optim.AdamW(resnetA.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "# optimizerB = torch.optim.AdamW(resnetB.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "# optimizerC = torch.optim.AdamW(resnetC.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "# exp_lr_schedulerA = lr_scheduler.StepLR(optimizerA, step_size=5, gamma=0.01)\n",
    "# exp_lr_schedulerB = lr_scheduler.StepLR(optimizerB, step_size=5, gamma=0.01)\n",
    "# exp_lr_schedulerC = lr_scheduler.StepLR(optimizerC, step_size=5, gamma=0.2)\n",
    "exp_lr_schedulerA = lr_scheduler.ReduceLROnPlateau(optimizerA, 'min', factor=0.90, patience=500)\n",
    "exp_lr_schedulerB = lr_scheduler.ReduceLROnPlateau(optimizerB, 'min', factor=0.90, patience=500)\n",
    "exp_lr_schedulerC = lr_scheduler.ReduceLROnPlateau(optimizerC, 'min', factor=0.90, patience=500)\n",
    "\n",
    "\n",
    "def hwout(Hin, padding, dilation, kernel_size, stride):\n",
    "    return (Hin + 2 * padding - dilation * (kernel_size-1) - 1)/stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for finding largest layer\n",
    "\n",
    "max_layer = 0\n",
    "max_neurons = 0\n",
    "for prm in resnetC.named_parameters():\n",
    "    num_ftr = np.prod(prm[1].shape)\n",
    "    if num_ftr > max_neurons:\n",
    "         max_neurons = num_ftr\n",
    "         max_layer = prm[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1.weight',\n",
       " 'bn1.weight',\n",
       " 'bn1.bias',\n",
       " 'layer1.0.conv1.weight',\n",
       " 'layer1.0.bn1.weight',\n",
       " 'layer1.0.bn1.bias',\n",
       " 'layer1.0.conv2.weight',\n",
       " 'layer1.0.bn2.weight',\n",
       " 'layer1.0.bn2.bias',\n",
       " 'layer1.1.conv1.weight',\n",
       " 'layer1.1.bn1.weight',\n",
       " 'layer1.1.bn1.bias',\n",
       " 'layer1.1.conv2.weight',\n",
       " 'layer1.1.bn2.weight',\n",
       " 'layer1.1.bn2.bias',\n",
       " 'layer2.0.conv1.weight',\n",
       " 'layer2.0.bn1.weight',\n",
       " 'layer2.0.bn1.bias',\n",
       " 'layer2.0.conv2.weight',\n",
       " 'layer2.0.bn2.weight',\n",
       " 'layer2.0.bn2.bias',\n",
       " 'layer2.0.downsample.0.weight',\n",
       " 'layer2.0.downsample.1.weight',\n",
       " 'layer2.0.downsample.1.bias',\n",
       " 'layer2.1.conv1.weight',\n",
       " 'layer2.1.bn1.weight',\n",
       " 'layer2.1.bn1.bias',\n",
       " 'layer2.1.conv2.weight',\n",
       " 'layer2.1.bn2.weight',\n",
       " 'layer2.1.bn2.bias',\n",
       " 'layer3.0.conv1.weight',\n",
       " 'layer3.0.bn1.weight',\n",
       " 'layer3.0.bn1.bias',\n",
       " 'layer3.0.conv2.weight',\n",
       " 'layer3.0.bn2.weight',\n",
       " 'layer3.0.bn2.bias',\n",
       " 'layer3.0.downsample.0.weight',\n",
       " 'layer3.0.downsample.1.weight',\n",
       " 'layer3.0.downsample.1.bias',\n",
       " 'layer3.1.conv1.weight',\n",
       " 'layer3.1.bn1.weight',\n",
       " 'layer3.1.bn1.bias',\n",
       " 'layer3.1.conv2.weight',\n",
       " 'layer3.1.bn2.weight',\n",
       " 'layer3.1.bn2.bias',\n",
       " 'layer4.0.conv1.weight',\n",
       " 'layer4.0.bn1.weight',\n",
       " 'layer4.0.bn1.bias',\n",
       " 'layer4.0.conv2.weight',\n",
       " 'layer4.0.bn2.weight',\n",
       " 'layer4.0.bn2.bias',\n",
       " 'layer4.0.downsample.0.weight',\n",
       " 'layer4.0.downsample.1.weight',\n",
       " 'layer4.0.downsample.1.bias',\n",
       " 'layer4.1.conv1.weight',\n",
       " 'layer4.1.bn1.weight',\n",
       " 'layer4.1.bn1.bias',\n",
       " 'layer4.1.conv2.weight',\n",
       " 'layer4.1.bn2.weight',\n",
       " 'layer4.1.bn2.bias',\n",
       " 'fc.weight',\n",
       " 'fc.bias']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in resnetC.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "### Define our transfer pipeline and attach models, and parameters. Model chains are saved to disk for memory efficient execution.\n",
    "mdlzAC = dict()\n",
    "mdlzAB = dict()\n",
    "mdlzBA = dict()\n",
    "params = []\n",
    "model_dir = './multi_model_chain'\n",
    "conv_layers = ['layer4.1.conv1.weight', 'layer4.0.conv1.weight']\n",
    "bn_layers = ['fc.weight']\n",
    "\n",
    "for prm in resnetC.named_parameters():\n",
    "# for prm in temp_list:\n",
    "#     if 'conv' in prm[0] or 'fc' in prm[0] or 'bn' in prm[0] or 'downsample' in prm[0]:\n",
    "    if prm[0] in bn_layers+conv_layers:\n",
    "        try:\n",
    "            if prm[1].dim() > 2:\n",
    "#                 if prm[0] not in conv_layers:\n",
    "#                     continue\n",
    "                mdl = Decenter_conv(prm[1].shape).to(device)\n",
    "                optimizer = torch.optim.AdamW(mdl.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "                exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5)\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.1,\n",
    "                            'patience': 5,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'A')\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.1,\n",
    "                            'patience': 5,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'B')\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.1,\n",
    "                            'patience': 5,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'C')\n",
    "                mdlzAC[prm[0]] = (model_dir + '/' + prm[0]+'A', Decenter_conv)\n",
    "                mdlzAB[prm[0]] = (model_dir + '/' + prm[0]+'B', Decenter_conv)\n",
    "                mdlzBA[prm[0]] = (model_dir + '/' + prm[0]+'C', Decenter_conv)\n",
    "#                 params += mdl.parameters()\n",
    "#                 pass\n",
    "            else:\n",
    "#                 if prm[0] not in bn_layers:\n",
    "#                     continue\n",
    "                mdl = Decenter(prm[1].shape).to(device)\n",
    "                optimizer = torch.optim.AdamW(mdl.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "                exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=1)\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.5,\n",
    "                            'patience': 1,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'A')\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.5,\n",
    "                            'patience': 1,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'B')\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.5,\n",
    "                            'patience': 1,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'C')\n",
    "                mdlzAC[prm[0]] = (model_dir + '/' + prm[0]+'A', Decenter)\n",
    "                mdlzAB[prm[0]] = (model_dir + '/' + prm[0]+'B', Decenter)\n",
    "                mdlzBA[prm[0]] = (model_dir + '/' + prm[0]+'C', Decenter)\n",
    "#                 params += mdl.parameters()\n",
    "            \n",
    "            del mdl\n",
    "            torch.cuda.empty_cache()\n",
    "        except Exception as e:\n",
    "            print(\"Problem with: \" + prm[0] + \" Size: \" + str(num_ftr))\n",
    "            print(\"Error: \" + str(e))\n",
    "            traceback.print_exc()\n",
    "            print()\n",
    "            pass\n",
    "        \n",
    "# params += list(resnetC.parameters())\n",
    "\n",
    "# optimizerRB = torch.optim.SGD(params, lr=0.01, momentum=0.9)\n",
    "optimizerRC = torch.optim.AdamW(resnetC.parameters(), lr=0.001, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer4.0.conv1.weight': ('./multi_model_chain/layer4.0.conv1.weightA',\n",
       "  __main__.Decenter_conv),\n",
       " 'layer4.1.conv1.weight': ('./multi_model_chain/layer4.1.conv1.weightA',\n",
       "  __main__.Decenter_conv),\n",
       " 'fc.weight': ('./multi_model_chain/fc.weightA', __main__.Decenter)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdlzAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define phases and associated pareameters\n",
    "dloaders = {'trainA':train_loader1, 'trainB':train_loader2,'trainC':train_loader3,\n",
    "            'validA':test_loader, 'validB':test_loader,'validC':test_loader,\n",
    "            'ABtoC':train_loader3}\n",
    "model = {'trainA':resnetA, 'trainB':resnetB,'trainC':resnetC,\n",
    "         'validA':resnetA, 'validB':resnetB,'validC':resnetC,\n",
    "         'ABtoC':resnetC}\n",
    "optimizer = {'trainA':optimizerA, 'trainB':optimizerB,'trainC':optimizerC,\n",
    "             'validA':optimizerA, 'validB':optimizerB,'validC':optimizerC,\n",
    "             'ABtoC':optimizerB}\n",
    "criterion = {'trainA':criterionA, 'trainB':criterionA,'trainC':criterionA,\n",
    "             'validA':criterionA, 'validB':criterionA,'validC':criterionA,\n",
    "             'ABtoC':criterionB}\n",
    "exp_lr_scheduler = {'trainA':exp_lr_schedulerA, 'trainB':exp_lr_schedulerB, 'trainC':exp_lr_schedulerC,\n",
    "             'validA':exp_lr_schedulerA, 'validB':exp_lr_schedulerB, 'validC':exp_lr_schedulerC,\n",
    "             'ABtoC':exp_lr_schedulerC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/9] phase: validA train loss: 0.0355 acc: 0.6762 valid loss: 0.0355 acc: 0.7101\n",
      "\n",
      "Epoch [0/9] phase: validB train loss: 0.0382 acc: 0.7067 valid loss: 0.0444 acc: 0.4566\n",
      "\n",
      "Epoch [0/9] phase: validC train loss: 0.0398 acc: 0.6585 valid loss: 0.0575 acc: 0.2969\n",
      "\n",
      "Epoch [0/9] phase: validC train loss: -0.0146 acc: 0.3661 valid loss: 0.0417 acc: 0.6835\n",
      "\n",
      "Epoch [1/9] phase: validA train loss: 0.0304 acc: 0.7717 valid loss: 0.0277 acc: 0.7815\n",
      "\n",
      "Epoch [1/9] phase: validB train loss: 0.0323 acc: 0.7726 valid loss: 0.0315 acc: 0.7843\n",
      "\n",
      "Epoch [1/9] phase: validC train loss: 0.0376 acc: 0.6624 valid loss: 0.0388 acc: 0.7269\n",
      "\n",
      "Epoch [1/9] phase: validC train loss: -0.0159 acc: 0.7451 valid loss: 0.0364 acc: 0.8782\n",
      "\n",
      "Epoch [2/9] phase: validA train loss: 0.0274 acc: 0.8327 valid loss: 0.0251 acc: 0.8291\n",
      "\n",
      "Epoch [2/9] phase: validB train loss: 0.0302 acc: 0.7884 valid loss: 0.0270 acc: 0.8263\n",
      "\n",
      "Epoch [2/9] phase: validC train loss: 0.0308 acc: 0.7953 valid loss: 0.0302 acc: 0.8739\n",
      "\n",
      "Epoch [2/9] phase: validC train loss: -0.0180 acc: 0.7293 valid loss: 0.0294 acc: 0.8838\n",
      "\n",
      "Epoch [3/9] phase: validA train loss: 0.0250 acc: 0.8563 valid loss: 0.0222 acc: 0.8697\n",
      "\n",
      "Epoch [3/9] phase: validB train loss: 0.0292 acc: 0.7943 valid loss: 0.0253 acc: 0.8403\n",
      "\n",
      "Epoch [3/9] phase: validC train loss: 0.0288 acc: 0.8081 valid loss: 0.0285 acc: 0.8501\n",
      "\n",
      "Epoch [3/9] phase: validC train loss: -0.0200 acc: 0.7539 valid loss: 0.0266 acc: 0.8627\n",
      "\n",
      "Epoch [4/9] phase: validA train loss: 0.0241 acc: 0.8583 valid loss: 0.0217 acc: 0.8571\n",
      "\n",
      "Epoch [4/9] phase: validB train loss: 0.0283 acc: 0.8002 valid loss: 0.0241 acc: 0.8445\n",
      "\n",
      "Epoch [4/9] phase: validC train loss: 0.0280 acc: 0.8120 valid loss: 0.0418 acc: 0.6639\n",
      "\n",
      "Epoch [4/9] phase: validC train loss: -0.0200 acc: 0.7520 valid loss: 0.0249 acc: 0.8585\n",
      "\n",
      "Epoch [5/9] phase: validA train loss: 0.0222 acc: 0.8652 valid loss: 0.0200 acc: 0.8697\n",
      "\n",
      "Epoch [5/9] phase: validB train loss: 0.0270 acc: 0.8031 valid loss: 0.0238 acc: 0.8557\n",
      "\n",
      "Epoch [5/9] phase: validC train loss: 0.0261 acc: 0.8130 valid loss: 0.0306 acc: 0.8361\n",
      "\n",
      "Epoch [5/9] phase: validC train loss: -0.0211 acc: 0.7795 valid loss: 0.0231 acc: 0.8697\n",
      "\n",
      "Epoch [6/9] phase: validA train loss: 0.0219 acc: 0.8583 valid loss: 0.0238 acc: 0.8347\n",
      "\n",
      "Epoch [6/9] phase: validB train loss: 0.0269 acc: 0.8199 valid loss: 0.0250 acc: 0.8445\n",
      "\n",
      "Epoch [6/9] phase: validC train loss: 0.0242 acc: 0.8386 valid loss: 0.0526 acc: 0.6303\n",
      "\n",
      "Epoch [6/9] phase: validC train loss: -0.0213 acc: 0.7874 valid loss: 0.0205 acc: 0.8852\n",
      "\n",
      "Epoch [7/9] phase: validA train loss: 0.0203 acc: 0.8760 valid loss: 0.0181 acc: 0.8894\n",
      "\n",
      "Epoch [7/9] phase: validB train loss: 0.0248 acc: 0.8268 valid loss: 0.0212 acc: 0.8838\n",
      "\n",
      "Epoch [7/9] phase: validC train loss: 0.0232 acc: 0.8474 valid loss: 0.0209 acc: 0.9160\n",
      "\n",
      "Epoch [7/9] phase: validC train loss: -0.0226 acc: 0.8199 valid loss: 0.0189 acc: 0.9020\n",
      "\n",
      "Epoch [8/9] phase: validA train loss: 0.0191 acc: 0.8799 valid loss: 0.0185 acc: 0.8950\n",
      "\n",
      "Epoch [8/9] phase: validB train loss: 0.0259 acc: 0.8219 valid loss: 0.0196 acc: 0.8725\n",
      "\n",
      "Epoch [8/9] phase: validC train loss: 0.0216 acc: 0.8543 valid loss: 0.0396 acc: 0.7493\n",
      "\n",
      "Epoch [8/9] phase: validC train loss: -0.0228 acc: 0.8258 valid loss: 0.0179 acc: 0.9104\n",
      "\n",
      "Epoch [9/9] phase: validA train loss: 0.0184 acc: 0.8848 valid loss: 0.0173 acc: 0.8796\n",
      "\n",
      "Epoch [9/9] phase: validB train loss: 0.0242 acc: 0.8219 valid loss: 0.0195 acc: 0.8754\n",
      "\n",
      "Epoch [9/9] phase: validC train loss: 0.0197 acc: 0.8760 valid loss: 0.0213 acc: 0.8922\n",
      "\n",
      "Epoch [9/9] phase: validC train loss: -0.0236 acc: 0.8356 valid loss: 0.0173 acc: 0.9062\n",
      "\n",
      "Best val Acc: 0.915966\n",
      "Training time:  44.696035 minutes\n"
     ]
    }
   ],
   "source": [
    "### Run decentralized pairwised knowledge transfer\n",
    "\n",
    "logging.info(\"#### bn acti conv and fc - unlimited bn - adam learning rate 0.001 - scheduler 20 - opt adamw ####\")\n",
    "\n",
    "start_time = time.time()\n",
    "model = train_model(dloaders, model, criterion, optimizer, exp_lr_scheduler, num_epochs=10)\n",
    "print('Training time: {:10f} minutes'.format((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ground - Generate confusion matrices of TP,FP,FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = torch.zeros(2, 2)\n",
    "for inputs, labels in dloaders['validC']:\n",
    "    inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    "\n",
    "    outputs = model['validC'](inputs)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    \n",
    "    for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[491.,  11.],\n",
      "        [ 56., 156.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = torch.zeros(2, 2)\n",
    "for inputs, labels in dloaders['validC']:\n",
    "    inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    "\n",
    "    outputs = model['validC'](inputs)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    \n",
    "    for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[483.,  19.],\n",
      "        [ 27., 185.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with knowledge transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = torch.zeros(10, 10)\n",
    "for inputs, labels in dloaders['validC']:\n",
    "    inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    "\n",
    "    outputs = model['validC'](inputs)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    \n",
    "    for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[705.,   4.,  45.,   4.,  15.,   1.,  17.,  18., 107.,  84.],\n",
      "        [ 16., 693.,   3.,   0.,   0.,   4.,  12.,   3.,  46., 223.],\n",
      "        [ 70.,   0., 589.,  25.,  86.,  40.,  90.,  52.,  24.,  24.],\n",
      "        [ 21.,   1.,  53., 459.,  53., 139., 124.,  83.,  25.,  42.],\n",
      "        [ 23.,   1.,  57.,  32., 678.,  22.,  70.,  94.,  20.,   3.],\n",
      "        [  9.,   2.,  42., 146.,  27., 599.,  46.,  99.,   9.,  21.],\n",
      "        [  3.,   2.,  16.,   7.,   6.,   6., 946.,   4.,   4.,   6.],\n",
      "        [  4.,   0.,   4.,  13.,  28.,  13.,   9., 916.,   1.,  12.],\n",
      "        [ 21.,   4.,   3.,   1.,   1.,   0.,   6.,   2., 952.,  10.],\n",
      "        [  8.,  21.,   1.,   3.,   0.,   1.,   3.,   3.,  21., 939.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
