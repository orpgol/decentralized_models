{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import random\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from scipy.stats import entropy, ks_2samp\n",
    "from scipy.special import kl_div\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard\n",
    "\n",
    "import traceback\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logname = 'logs/decentralized_multi_agent'\n",
    "logging.basicConfig(filename=logname,\n",
    "                            filemode='a',\n",
    "                            format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                            datefmt='%H:%M:%S',\n",
    "                            level=logging.DEBUG)\n",
    "\n",
    "logging.info(\"Running Decentralized Learning test\")\n",
    "\n",
    "logger = logging.getLogger('Decentralized_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Transformations\n",
    "RC   = transforms.RandomCrop(32, padding=4)\n",
    "RHF  = transforms.RandomHorizontalFlip()\n",
    "RVF  = transforms.RandomVerticalFlip()\n",
    "NRM  = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "TT   = transforms.ToTensor()\n",
    "TPIL = transforms.ToPILImage()\n",
    "\n",
    "# Transforms object for trainset with augmentation\n",
    "transform_with_aug = transforms.Compose([TPIL, RC, RHF, TT, NRM])\n",
    "# Transforms object for testset with NO augmentation\n",
    "transform_no_aug   = transforms.Compose([TT, NRM])\n",
    "\n",
    "# Downloading/Louding CIFAR10 data\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data/cifar10', train=True,\n",
    "                                        download=True, transform=transform_with_aug)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data/cifar10', train=False,\n",
    "                                       download=True, transform=transform_no_aug)\n",
    "\n",
    "classDict = {'plane':0, 'car':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}\n",
    "\n",
    "# Separating trainset/testset data/label\n",
    "x_train  = trainset.data\n",
    "x_test   = testset.data\n",
    "y_train  = trainset.targets\n",
    "y_test   = testset.targets\n",
    "\n",
    "# Define a function to separate CIFAR classes by class index\n",
    "\n",
    "def get_class_i(x, y, i):\n",
    "    \"\"\"\n",
    "    x: trainset.train_data or testset.test_data\n",
    "    y: trainset.train_labels or testset.test_labels\n",
    "    i: class label, a number between 0 to 9\n",
    "    return: x_i\n",
    "    \"\"\"\n",
    "    # Convert to a numpy array\n",
    "    y = np.array(y)\n",
    "    # Locate position of labels that equal to i\n",
    "    pos_i = np.argwhere(y == i)\n",
    "    # Convert the result into a 1-D list\n",
    "    pos_i = list(pos_i[:,0])\n",
    "    # Collect all data that match the desired label\n",
    "    x_i = [x[j] for j in pos_i]\n",
    "    \n",
    "    return x_i\n",
    "\n",
    "class DatasetMaker(Dataset):\n",
    "    def __init__(self, datasets, transformFunc = transform_no_aug):\n",
    "        \"\"\"\n",
    "        datasets: a list of get_class_i outputs, i.e. a list of list of images for selected classes\n",
    "        \"\"\"\n",
    "        self.datasets = datasets\n",
    "        self.lengths  = [len(d) for d in self.datasets]\n",
    "        self.transformFunc = transformFunc\n",
    "    def __getitem__(self, i):\n",
    "        class_label, index_wrt_class = self.index_of_which_bin(self.lengths, i)\n",
    "        img = self.datasets[class_label][index_wrt_class]\n",
    "        img = self.transformFunc(img)\n",
    "        return img, class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.lengths)\n",
    "    \n",
    "    def index_of_which_bin(self, bin_sizes, absolute_index, verbose=False):\n",
    "        \"\"\"\n",
    "        Given the absolute index, returns which bin it falls in and which element of that bin it corresponds to.\n",
    "        \"\"\"\n",
    "        # Which class/bin does i fall into?\n",
    "        accum = np.add.accumulate(bin_sizes)\n",
    "        if verbose:\n",
    "            print(\"accum =\", accum)\n",
    "        bin_index  = len(np.argwhere(accum <= absolute_index))\n",
    "        if verbose:\n",
    "            print(\"class_label =\", bin_index)\n",
    "        # Which element of the fallent class/bin does i correspond to?\n",
    "        index_wrt_class = absolute_index - np.insert(accum, 0, 0)[bin_index]\n",
    "        if verbose:\n",
    "            print(\"index_wrt_class =\", index_wrt_class)\n",
    "\n",
    "        return bin_index, index_wrt_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are saving a fraction\n",
    "frac = int(len(x_train) * 0.05)\n",
    "x_reserve = x_train[:frac]\n",
    "y_reserve = y_train[:frac]\n",
    "x_train = x_train[frac:]\n",
    "y_train = y_train[frac:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Usage ================== #\n",
    "\n",
    "# \n",
    "trainset1 = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_train, y_train, classDict['plane']), \n",
    "         get_class_i(x_train, y_train, classDict['car']), \n",
    "         get_class_i(x_train, y_train, classDict['bird']),\n",
    "        [],[],[],[],[],[],[]],\n",
    "        transform_with_aug\n",
    "    )\n",
    "trainset2 = \\\n",
    "    DatasetMaker(\n",
    "        [[],[],[],\n",
    "         get_class_i(x_train, y_train, classDict['cat']), \n",
    "         get_class_i(x_train, y_train, classDict['deer']), \n",
    "         get_class_i(x_train, y_train, classDict['dog']), \n",
    "         [],[],[],[]],\n",
    "        transform_with_aug\n",
    "    )\n",
    "trainset3 = \\\n",
    "    DatasetMaker(\n",
    "        [[],[],[],[],[],[],\n",
    "         get_class_i(x_train, y_train, classDict['frog']), \n",
    "         get_class_i(x_train, y_train, classDict['horse']), \n",
    "         get_class_i(x_train, y_train, classDict['ship']), \n",
    "         get_class_i(x_train, y_train, classDict['truck'])],\n",
    "        transform_with_aug\n",
    "    )\n",
    "trainset4 = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_train, y_train, classDict['plane']), \n",
    "         get_class_i(x_train, y_train, classDict['car']), \n",
    "         get_class_i(x_train, y_train, classDict['bird']), \n",
    "         get_class_i(x_train, y_train, classDict['cat']), \n",
    "         get_class_i(x_train, y_train, classDict['deer']),\n",
    "         get_class_i(x_train, y_train, classDict['dog']), \n",
    "         get_class_i(x_train, y_train, classDict['frog']), \n",
    "         get_class_i(x_train, y_train, classDict['horse']), \n",
    "         get_class_i(x_train, y_train, classDict['ship']), \n",
    "         get_class_i(x_train, y_train, classDict['truck'])],\n",
    "        transform_with_aug\n",
    "    )\n",
    "reserved = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_reserve, y_reserve, classDict['plane']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['car']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['bird']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['cat']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['deer']),\n",
    "         get_class_i(x_reserve, y_reserve, classDict['dog']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['frog']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['horse']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['ship']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['truck'])],\n",
    "        transform_with_aug\n",
    "    )\n",
    "testset  = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_test, y_test, classDict['plane']), \n",
    "         get_class_i(x_test, y_test, classDict['car']), \n",
    "         get_class_i(x_test, y_test, classDict['bird']), \n",
    "         get_class_i(x_test, y_test, classDict['cat']), \n",
    "         get_class_i(x_test, y_test, classDict['deer']),\n",
    "         get_class_i(x_test, y_test, classDict['dog']), \n",
    "         get_class_i(x_test, y_test, classDict['frog']), \n",
    "         get_class_i(x_test, y_test, classDict['horse']), \n",
    "         get_class_i(x_test, y_test, classDict['ship']), \n",
    "         get_class_i(x_test, y_test, classDict['truck'])],\n",
    "        transform_no_aug\n",
    "    )\n",
    "\n",
    "superset = torch.utils.data.ConcatDataset([trainset3,reserved])\n",
    "\n",
    "kwargs = {'num_workers': 2, 'pin_memory': False}\n",
    "\n",
    "# Create datasetLoaders from trainset and testset\n",
    "trainsetLoader1   = DataLoader(trainset1, batch_size=64, shuffle=True , **kwargs)\n",
    "trainsetLoader2   = DataLoader(trainset2, batch_size=64, shuffle=True , **kwargs)\n",
    "trainsetLoader3   = DataLoader(trainset3, batch_size=64, shuffle=True , **kwargs)\n",
    "trainsetLoader4   = DataLoader(trainset4, batch_size=64, shuffle=True , **kwargs)\n",
    "reservedLoader    = DataLoader(superset, batch_size=64, shuffle=True , **kwargs)\n",
    "testsetLoader    = DataLoader(testset , batch_size=64, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.3    # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = next(iter(reservedLoader))\n",
    "imshow(torchvision.utils.make_grid(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "# device2 = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decentralized model using reserved data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a knowledge transfer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_init(m):\n",
    "    if isinstance(m, (torch.nn.Linear, torch.nn.Conv2d)):\n",
    "        torch.nn.init.sparse_(m.weight, sparsity=0.33)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "    elif isinstance(m, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d)):\n",
    "        m.weight.data.fill_(1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "class Decenter(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super(Decenter, self).__init__()\n",
    "        if len(shape) == 1:\n",
    "            shape = shape[0]\n",
    "            self.dim = 0\n",
    "        elif len(shape) == 2:\n",
    "            shape = shape[1]\n",
    "            self.dim = 1\n",
    "        self.translation = torch.nn.Sequential(\n",
    "#             torch.nn.Tanh(),\n",
    "            torch.nn.Linear(shape*2, shape)\n",
    "        )\n",
    "\n",
    "        self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        x = torch.cat((source, target), self.dim)\n",
    "#         x = torch.cat((torch.flatten(source), torch.flatten(target)), 0)\n",
    "#         x = torch.add(torch.flatten(source).to(\"cpu\"), torch.flatten(target).to(\"cpu\"))\n",
    "        res = self.translation(x)\n",
    "#         res = res.reshape(target.shape)\n",
    "        return res\n",
    "    \n",
    "    \n",
    "class Interpolate(torch.nn.Module):\n",
    "    def __init__(self, size, mode):\n",
    "        super(Interpolate, self).__init__()\n",
    "        self.interp = torch.nn.functional.interpolate\n",
    "        self.size = size\n",
    "        self.mode = mode\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.interp(x, size=self.size, mode=self.mode, align_corners=False)\n",
    "        return x\n",
    "    \n",
    "class Reshape(torch.nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "    \n",
    "class Decenter_pooled(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super(Decenter_pooled, self).__init__()\n",
    "        self.shape = shape\n",
    "        self.translation = torch.nn.Sequential(\n",
    "#             torch.nn.BatchNorm2d(channels_out),\n",
    "            torch.nn.AdaptiveAvgPool2d(1),\n",
    "#             Interpolate(size=1, mode='bilinear'),\n",
    "            Reshape(shape[0], shape[1]*2),\n",
    "            torch.nn.Linear(shape[1]*2, shape[1]*shape[-1]*shape[-1]),\n",
    "#             Reshape(shape[0], shape[1] ,1 ,1),\n",
    "        )\n",
    "\n",
    "        self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        x = torch.cat((source, target), 1)\n",
    "        res = self.translation(x)\n",
    "        res = res.view(self.shape[0], self.shape[1], self.shape[2], self.shape[3])\n",
    "        return res\n",
    "    \n",
    "    \n",
    "class Decenter_conv(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super(Decenter_conv, self).__init__()\n",
    "        channels_in = shape[1]*2\n",
    "        channels_out = shape[1]\n",
    "        self.translation = torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm2d(channels_in),\n",
    "            torch.nn.Conv2d(channels_in, channels_out, 3, stride=1, padding=1)\n",
    "#             torch.nn.ConvTranspose2d(channels_in, channels_out, 3, stride=1, padding=1)\n",
    "\n",
    "        )\n",
    "\n",
    "#         self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        x = torch.cat((source, target), 1)\n",
    "#         x = torch.cat((torch.flatten(source), torch.flatten(target)), 0)\n",
    "#         x = torch.add(torch.flatten(source).to(\"cpu\"), torch.flatten(target).to(\"cpu\"))\n",
    "        res = self.translation(x)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_dict: dict = {}\n",
    "def fc_hook(layer_name, grad_input, grad_output): \n",
    "    if layer_name not in grad_dict:\n",
    "        grad_dict[layer_name] = {}\n",
    "        grad_dict[layer_name][\"grad_input\"] = []\n",
    "        grad_dict[layer_name][\"grad_output\"] = []\n",
    "        grad_dict[layer_name][\"labels\"] = []\n",
    "        \n",
    "#     print(grad_input)\n",
    "#     print(grad_output)\n",
    "    grad_dict[layer_name][\"grad_input\"].append(grad_input[0].cpu().numpy())\n",
    "    grad_dict[layer_name][\"grad_output\"].append(grad_output[0].cpu().numpy())\n",
    "    \n",
    "# def reserve_step(source, target):\n",
    "    \n",
    "\n",
    "matlst = []\n",
    "fclst = []\n",
    "\n",
    "def train_model(dataloders, model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    writer = SummaryWriter('runs/') \n",
    "\n",
    "    since = time.time()\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    best_model_wts = 0.0\n",
    "    best_acc = 0.0\n",
    "    dataset_sizes = {'trainA': len(dataloders['trainA'].sampler),\n",
    "                     'trainB': len(dataloders['trainB'].sampler),\n",
    "                     'trainC': len(dataloders['trainC'].sampler),\n",
    "                     'reservedA': len(dataloders['reservedA'].sampler),\n",
    "                     'reservedB': len(dataloders['reservedB'].sampler),\n",
    "                     'reservedCA': len(dataloders['reservedCA'].sampler),\n",
    "                     'reservedCB': len(dataloders['reservedCB'].sampler),\n",
    "                     'validA': len(dataloders['validA'].sampler),\n",
    "                     'validB': len(dataloders['validB'].sampler),\n",
    "                     'validC': len(dataloders['validC'].sampler)}\n",
    "\n",
    "    i = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['trainA', 'validA', 'trainB', 'validB', 'trainC', 'validC', 'reservedCA', 'validC', 'reservedCB', 'validC']:\n",
    "            if phase not in ['validA','validB','validC']:\n",
    "                scheduler[phase].step()\n",
    "                scheduler[phase].step()\n",
    "                model[phase].train(True)\n",
    "            else:\n",
    "                model['trainA'].train(False)\n",
    "                model['trainB'].train(False)\n",
    "                model['trainC'].train(False)\n",
    "            \n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            if phase in ['reservedCA','reservedCB']:\n",
    "                if phase == 'reservedCA':\n",
    "                    sd = model[phase].state_dict()\n",
    "                    for key, value in mdlzAC.items():\n",
    "                        shape = model['trainC'].state_dict()[key].shape\n",
    "                        mdl = value[1](shape).to(device)\n",
    "                        checkpoint = torch.load(value[0])\n",
    "                        mdl.load_state_dict(checkpoint['model_state_dict'])\n",
    "                        mdl.eval()\n",
    "                        sd[key] = mdl(copy.deepcopy(model['trainA'].state_dict()[key]), copy.deepcopy(model['trainC'].state_dict()[key]))\n",
    "#                         torch.save({'model_state_dict': mdl.state_dict()}, value[0])\n",
    "                        \n",
    "                        if key == 'conv1.weight':\n",
    "                            matlst.append(sd[key])\n",
    "                        elif key == 'fc.weight':\n",
    "                            fclst.append(sd[key])\n",
    "                        \n",
    "                    model[phase].load_state_dict(sd)\n",
    "                elif phase == 'reservedCB':\n",
    "                    sd = model[phase].state_dict()\n",
    "                    for key, value in mdlzBC.items():\n",
    "                        shape = model['trainC'].state_dict()[key].shape\n",
    "                        mdl = value[1](shape).to(device)\n",
    "                        checkpoint = torch.load(value[0])\n",
    "                        mdl.load_state_dict(checkpoint['model_state_dict'])\n",
    "                        \n",
    "                        sd[key] = mdl(copy.deepcopy(model['trainB'].state_dict()[key]), copy.deepcopy(model['trainC'].state_dict()[key]))\n",
    "#                         torch.save({'model_state_dict': mdl.state_dict()}, value[0])\n",
    "                        \n",
    "                        if key == 'conv1.weight':\n",
    "                            matlst.append(sd[key])\n",
    "                        elif key == 'fc.weight':\n",
    "                            fclst.append(sd[key])\n",
    "                        \n",
    "                    model[phase].load_state_dict(sd)\n",
    "                    \n",
    "                    \n",
    "            for inputs, labels in dataloders[phase]:\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer[phase].zero_grad()\n",
    "\n",
    "                outputs = model[phase](inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                \n",
    "                if phase in ['reservedCA','reservedCB']:\n",
    "                    loss_a = criterion['trainC'](outputs, labels)\n",
    "#                     batch_size = labels.shape[0]\n",
    "#                     # Dummy input that HAS to be 2D for the scatter (you can use view(-1,1) if needed)\n",
    "#                     y = labels.reshape(-1,1)\n",
    "#                     # One hot encoding buffer that you create out of the loop and just keep reusing\n",
    "#                     y_onehot = torch.FloatTensor(batch_size, 10).to(device)\n",
    "\n",
    "#                     # In your for loop\n",
    "#                     y_onehot.zero_()\n",
    "#                     y_onehot.scatter_(1, y, 1)\n",
    "\n",
    "                    if phase == 'reservedCA':\n",
    "                        outputs2 = model['trainA'](inputs)\n",
    "                    elif phase == 'reservedCB':\n",
    "                        outputs2 = model['trainB'](inputs)\n",
    "    \n",
    "                    sm = torch.nn.Softmax(dim=1)\n",
    "                    outputs = sm(outputs)\n",
    "                    outputs2 = sm(outputs2)\n",
    "                    loss_b = criterion[phase](outputs, outputs2)\n",
    "                    loss = (loss_a + loss_b) / 2\n",
    "                else:\n",
    "                    loss = criterion[phase](outputs, labels)\n",
    "\n",
    "                if phase not in ['validA','validB','validC']:\n",
    "                    loss.backward()\n",
    "                    optimizer[phase].step()\n",
    "                    \n",
    "                    if phase == 'reservedCA':\n",
    "#                         loss_b.backward(retain_graph=False)\n",
    "                        for key, value in mdlzAC.items():\n",
    "                            shape = model['trainC'].state_dict()[key].shape\n",
    "                            mdl = value[1](shape).to(device)\n",
    "                            opti = torch.optim.AdamW(mdl.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "                            checkpoint = torch.load(value[0])\n",
    "                            mdl.load_state_dict(checkpoint['model_state_dict'])\n",
    "                            mdl.eval()\n",
    "                            opti.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#                             opti.zero_grad()\n",
    "                            opti.step()\n",
    "                            torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                                        'optimizer_state_dict': opti.state_dict()},\n",
    "                                       value[0])\n",
    "        \n",
    "                    elif phase == 'reservedCB':\n",
    "#                         loss_b.backward(retain_graph=False)\n",
    "                        for key, value in mdlzBC.items():\n",
    "                            shape = model['trainC'].state_dict()[key].shape\n",
    "                            mdl = value[1](shape).to(device)\n",
    "                            opti = torch.optim.AdamW(mdl.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "                            checkpoint = torch.load(value[0])\n",
    "                            mdl.load_state_dict(checkpoint['model_state_dict'])\n",
    "                            mdl.eval()\n",
    "                            opti.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#                             opti.zero_grad()\n",
    "                            opti.step()\n",
    "                            torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                                        'optimizer_state_dict': opti.state_dict()},\n",
    "                                       value[0])\n",
    "                    \n",
    "                    ## Tensorboard\n",
    "#                     writer.add_histogram('distribution centers/resnet2', model.fc.weight.cpu().detach().numpy(), i)\n",
    "                    i+=1\n",
    "                    ## Back prop hook\n",
    "#                     grad_dict[\"fc\"][\"labels\"].append(labels.cpu().numpy())\n",
    "\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                \n",
    "            if phase not in ['validA','validB','validC']:\n",
    "                train_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                train_epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            else:\n",
    "                valid_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                valid_epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "                print('Epoch [{}/{}] phase: {} train loss: {:.4f} acc: {:.4f} ' \n",
    "                      'valid loss: {:.4f} acc: {:.4f}'.format(\n",
    "                        epoch, num_epochs - 1,\n",
    "                        phase,\n",
    "                        train_epoch_loss, train_epoch_acc, \n",
    "                        valid_epoch_loss, valid_epoch_acc))\n",
    "                print() \n",
    "                logger.info('Epoch [{}/{}] phase: {} train loss: {:.4f} acc: {:.4f} ' \n",
    "                      'valid loss: {:.4f} acc: {:.4f}'.format(\n",
    "                        epoch, num_epochs - 1,\n",
    "                        phase,\n",
    "                        train_epoch_loss, train_epoch_acc, \n",
    "                        valid_epoch_loss, valid_epoch_acc))\n",
    "                \n",
    "            if phase in ['validA','validB','validC'] and valid_epoch_acc > best_acc:\n",
    "                best_acc = valid_epoch_acc\n",
    "                best_model_wts = model[phase].state_dict()\n",
    "\n",
    "                \n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    logger.info('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    writer.close()\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnetA = models.resnet18(pretrained=False)\n",
    "resnetB = models.resnet18(pretrained=False)\n",
    "resnetC = models.resnet18(pretrained=False)\n",
    "# freeze all model parameters\n",
    "# for param in resnet.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# new final layer with 16 classes\n",
    "num_ftrsA = resnetA.fc.in_features\n",
    "resnetA.fc = torch.nn.Linear(num_ftrsA, 10)\n",
    "\n",
    "num_ftrsB = resnetB.fc.in_features\n",
    "resnetB.fc = torch.nn.Linear(num_ftrsB, 10)\n",
    "\n",
    "num_ftrsC = resnetC.fc.in_features\n",
    "resnetC.fc = torch.nn.Linear(num_ftrsC, 10)\n",
    "\n",
    "def fc_backward_hook(module, grad_input, grad_output):  # module is Linear in this case. Ignored.\n",
    "        fc_hook(\"fc\", grad_input, grad_output)\n",
    "resnetA.fc_hook_handle = resnetA.fc.register_backward_hook(fc_backward_hook)\n",
    "resnetB.fc_hook_handle = resnetB.fc.register_backward_hook(fc_backward_hook)\n",
    "resnetC.fc_hook_handle = resnetC.fc.register_backward_hook(fc_backward_hook)\n",
    "\n",
    "\n",
    "def roc_auc_score_micro(y_pred_proba, y_true):\n",
    "    y_pred_proba = y_pred_proba.detach().cpu()\n",
    "    y_true = y_true.detach().cpu()\n",
    "    return metrics.roc_auc_score(\n",
    "        label_binarize(y_true, classes=list(range(y_pred_proba.shape[1]))).ravel(),\n",
    "        y_pred_proba.flatten())\n",
    "\n",
    "\n",
    "resnetA = resnetA.to(device)\n",
    "resnetB = resnetB.to(device)\n",
    "resnetC = resnetC.to(device)\n",
    "\n",
    "criterionA = torch.nn.CrossEntropyLoss()\n",
    "# criterionB = torch.nn.CrossEntropyLoss()\n",
    "# criterionA = torch.nn.KLDivLoss()\n",
    "criterionB = torch.nn.KLDivLoss(reduction = 'batchmean')\n",
    "# criterionB = torch.nn.KLDivLoss(reduction = 'mean')\n",
    "# criterionB = torch.nn.MSELoss()\n",
    "# optimizerA = torch.optim.SGD(resnetA.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizerB = torch.optim.SGD(resnetB.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizerA = torch.optim.AdamW(resnetA.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "optimizerB = torch.optim.AdamW(resnetB.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "optimizerC = torch.optim.AdamW(resnetC.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "exp_lr_schedulerA = lr_scheduler.StepLR(optimizerA, step_size=20, gamma=0.1)\n",
    "exp_lr_schedulerB = lr_scheduler.StepLR(optimizerB, step_size=20, gamma=0.1)\n",
    "exp_lr_schedulerC = lr_scheduler.StepLR(optimizerC, step_size=20, gamma=0.1)\n",
    "\n",
    "\n",
    "def hwout(Hin, padding, dilation, kernel_size, stride):\n",
    "    return (Hin + 2 * padding - dilation * (kernel_size-1) - 1)/stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_layer = 0\n",
    "max_neurons = 0\n",
    "for prm in resnetC.named_parameters():\n",
    "    num_ftr = np.prod(prm[1].shape)\n",
    "    if num_ftr > max_neurons:\n",
    "         max_neurons = num_ftr\n",
    "         max_layer = prm[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1.weight',\n",
       " 'bn1.weight',\n",
       " 'bn1.bias',\n",
       " 'layer1.0.conv1.weight',\n",
       " 'layer1.0.bn1.weight',\n",
       " 'layer1.0.bn1.bias',\n",
       " 'layer1.0.conv2.weight',\n",
       " 'layer1.0.bn2.weight',\n",
       " 'layer1.0.bn2.bias',\n",
       " 'layer1.1.conv1.weight',\n",
       " 'layer1.1.bn1.weight',\n",
       " 'layer1.1.bn1.bias',\n",
       " 'layer1.1.conv2.weight',\n",
       " 'layer1.1.bn2.weight',\n",
       " 'layer1.1.bn2.bias',\n",
       " 'layer2.0.conv1.weight',\n",
       " 'layer2.0.bn1.weight',\n",
       " 'layer2.0.bn1.bias',\n",
       " 'layer2.0.conv2.weight',\n",
       " 'layer2.0.bn2.weight',\n",
       " 'layer2.0.bn2.bias',\n",
       " 'layer2.0.downsample.0.weight',\n",
       " 'layer2.0.downsample.1.weight',\n",
       " 'layer2.0.downsample.1.bias',\n",
       " 'layer2.1.conv1.weight',\n",
       " 'layer2.1.bn1.weight',\n",
       " 'layer2.1.bn1.bias',\n",
       " 'layer2.1.conv2.weight',\n",
       " 'layer2.1.bn2.weight',\n",
       " 'layer2.1.bn2.bias',\n",
       " 'layer3.0.conv1.weight',\n",
       " 'layer3.0.bn1.weight',\n",
       " 'layer3.0.bn1.bias',\n",
       " 'layer3.0.conv2.weight',\n",
       " 'layer3.0.bn2.weight',\n",
       " 'layer3.0.bn2.bias',\n",
       " 'layer3.0.downsample.0.weight',\n",
       " 'layer3.0.downsample.1.weight',\n",
       " 'layer3.0.downsample.1.bias',\n",
       " 'layer3.1.conv1.weight',\n",
       " 'layer3.1.bn1.weight',\n",
       " 'layer3.1.bn1.bias',\n",
       " 'layer3.1.conv2.weight',\n",
       " 'layer3.1.bn2.weight',\n",
       " 'layer3.1.bn2.bias',\n",
       " 'layer4.0.conv1.weight',\n",
       " 'layer4.0.bn1.weight',\n",
       " 'layer4.0.bn1.bias',\n",
       " 'layer4.0.conv2.weight',\n",
       " 'layer4.0.bn2.weight',\n",
       " 'layer4.0.bn2.bias',\n",
       " 'layer4.0.downsample.0.weight',\n",
       " 'layer4.0.downsample.1.weight',\n",
       " 'layer4.0.downsample.1.bias',\n",
       " 'layer4.1.conv1.weight',\n",
       " 'layer4.1.bn1.weight',\n",
       " 'layer4.1.bn1.bias',\n",
       " 'layer4.1.conv2.weight',\n",
       " 'layer4.1.bn2.weight',\n",
       " 'layer4.1.bn2.bias',\n",
       " 'fc.weight',\n",
       " 'fc.bias']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in resnetC.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "mdlzAC = dict()\n",
    "mdlzBC = dict()\n",
    "params = []\n",
    "model_dir = './multi_model_chain'\n",
    "conv_layers = ['layer4.1.conv2.weight', 'layer4.1.conv1.weight', 'layer4.0.conv2.weight']\n",
    "bn_layers = ['layer4.1.bn2.bias', 'layer4.1.bn2.weight',\n",
    "             'layer4.1.bn1.bias', 'layer4.1.bn1.weight',\n",
    "             'layer4.0.bn2.bias', 'layer4.0.bn2.weight',\n",
    "             'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias',\n",
    "             'fc.weight', 'fc.bias']\n",
    "\n",
    "for prm in resnetC.named_parameters():\n",
    "# for prm in temp_list:\n",
    "    if 'conv' in prm[0] or 'fc' in prm[0] or 'bn' in prm[0] or 'downsample' in prm[0]:\n",
    "        try:\n",
    "            if prm[1].dim() > 2:\n",
    "                if prm[0] not in conv_layers:\n",
    "                    continue\n",
    "                mdl = Decenter_conv(prm[1].shape).to(device)\n",
    "                optimizer = torch.optim.AdamW(mdl.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'A')\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'B')\n",
    "                mdlzAC[prm[0]] = (model_dir + '/' + prm[0]+'A', Decenter_conv)\n",
    "                mdlzBC[prm[0]] = (model_dir + '/' + prm[0]+'B', Decenter_conv)\n",
    "#                 params += mdl.parameters()\n",
    "#                 pass\n",
    "            else:\n",
    "#                 if prm[0] not in bn_layers:\n",
    "#                     continue\n",
    "                mdl = Decenter(prm[1].shape).to(device)\n",
    "                optimizer = torch.optim.AdamW(mdl.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'A')\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'B')\n",
    "                mdlzAC[prm[0]] = (model_dir + '/' + prm[0]+'A', Decenter)\n",
    "                mdlzBC[prm[0]] = (model_dir + '/' + prm[0]+'B', Decenter)\n",
    "#                 params += mdl.parameters()\n",
    "            \n",
    "            del mdl\n",
    "            torch.cuda.empty_cache()\n",
    "        except Exception as e:\n",
    "            print(\"Problem with: \" + prm[0] + \" Size: \" + str(num_ftr))\n",
    "            print(\"Error: \" + str(e))\n",
    "            traceback.print_exc()\n",
    "            print()\n",
    "            pass\n",
    "        \n",
    "# params += list(resnetC.parameters())\n",
    "\n",
    "# optimizerRB = torch.optim.SGD(params, lr=0.01, momentum=0.9)\n",
    "optimizerRC = torch.optim.AdamW(resnetC.parameters(), lr=0.001, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bn1.weight': ('./multi_model_chain/bn1.weightB', __main__.Decenter),\n",
       " 'bn1.bias': ('./multi_model_chain/bn1.biasB', __main__.Decenter),\n",
       " 'layer1.0.bn1.weight': ('./multi_model_chain/layer1.0.bn1.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer1.0.bn1.bias': ('./multi_model_chain/layer1.0.bn1.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer1.0.bn2.weight': ('./multi_model_chain/layer1.0.bn2.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer1.0.bn2.bias': ('./multi_model_chain/layer1.0.bn2.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer1.1.bn1.weight': ('./multi_model_chain/layer1.1.bn1.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer1.1.bn1.bias': ('./multi_model_chain/layer1.1.bn1.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer1.1.bn2.weight': ('./multi_model_chain/layer1.1.bn2.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer1.1.bn2.bias': ('./multi_model_chain/layer1.1.bn2.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer2.0.bn1.weight': ('./multi_model_chain/layer2.0.bn1.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer2.0.bn1.bias': ('./multi_model_chain/layer2.0.bn1.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer2.0.bn2.weight': ('./multi_model_chain/layer2.0.bn2.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer2.0.bn2.bias': ('./multi_model_chain/layer2.0.bn2.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer2.0.downsample.1.weight': ('./multi_model_chain/layer2.0.downsample.1.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer2.0.downsample.1.bias': ('./multi_model_chain/layer2.0.downsample.1.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer2.1.bn1.weight': ('./multi_model_chain/layer2.1.bn1.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer2.1.bn1.bias': ('./multi_model_chain/layer2.1.bn1.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer2.1.bn2.weight': ('./multi_model_chain/layer2.1.bn2.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer2.1.bn2.bias': ('./multi_model_chain/layer2.1.bn2.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer3.0.bn1.weight': ('./multi_model_chain/layer3.0.bn1.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer3.0.bn1.bias': ('./multi_model_chain/layer3.0.bn1.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer3.0.bn2.weight': ('./multi_model_chain/layer3.0.bn2.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer3.0.bn2.bias': ('./multi_model_chain/layer3.0.bn2.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer3.0.downsample.1.weight': ('./multi_model_chain/layer3.0.downsample.1.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer3.0.downsample.1.bias': ('./multi_model_chain/layer3.0.downsample.1.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer3.1.bn1.weight': ('./multi_model_chain/layer3.1.bn1.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer3.1.bn1.bias': ('./multi_model_chain/layer3.1.bn1.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer3.1.bn2.weight': ('./multi_model_chain/layer3.1.bn2.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer3.1.bn2.bias': ('./multi_model_chain/layer3.1.bn2.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer4.0.bn1.weight': ('./multi_model_chain/layer4.0.bn1.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer4.0.bn1.bias': ('./multi_model_chain/layer4.0.bn1.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer4.0.conv2.weight': ('./multi_model_chain/layer4.0.conv2.weightB',\n",
       "  __main__.Decenter_conv),\n",
       " 'layer4.0.bn2.weight': ('./multi_model_chain/layer4.0.bn2.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer4.0.bn2.bias': ('./multi_model_chain/layer4.0.bn2.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer4.0.downsample.1.weight': ('./multi_model_chain/layer4.0.downsample.1.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer4.0.downsample.1.bias': ('./multi_model_chain/layer4.0.downsample.1.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer4.1.conv1.weight': ('./multi_model_chain/layer4.1.conv1.weightB',\n",
       "  __main__.Decenter_conv),\n",
       " 'layer4.1.bn1.weight': ('./multi_model_chain/layer4.1.bn1.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer4.1.bn1.bias': ('./multi_model_chain/layer4.1.bn1.biasB',\n",
       "  __main__.Decenter),\n",
       " 'layer4.1.conv2.weight': ('./multi_model_chain/layer4.1.conv2.weightB',\n",
       "  __main__.Decenter_conv),\n",
       " 'layer4.1.bn2.weight': ('./multi_model_chain/layer4.1.bn2.weightB',\n",
       "  __main__.Decenter),\n",
       " 'layer4.1.bn2.bias': ('./multi_model_chain/layer4.1.bn2.biasB',\n",
       "  __main__.Decenter),\n",
       " 'fc.weight': ('./multi_model_chain/fc.weightB', __main__.Decenter),\n",
       " 'fc.bias': ('./multi_model_chain/fc.biasB', __main__.Decenter)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdlzBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define phases \n",
    "dloaders = {'trainA':trainsetLoader1, 'trainB':trainsetLoader2, 'trainC':reservedLoader,\n",
    "            'validA':testsetLoader, 'validB':testsetLoader, 'validC':testsetLoader,\n",
    "            'reservedA':reservedLoader, 'reservedB':reservedLoader, 'reservedCA':reservedLoader, 'reservedCB':reservedLoader}\n",
    "model = {'trainA':resnetA, 'trainB':resnetB, 'trainC':resnetC,\n",
    "         'validA':resnetA, 'validB':resnetB, 'validC':resnetC,\n",
    "         'reservedA':resnetA, 'reservedB':resnetB, 'reservedCA':resnetC, 'reservedCB':resnetC}\n",
    "optimizer = {'trainA':optimizerA, 'trainB':optimizerB, 'trainC':optimizerC,\n",
    "             'validA':optimizerA, 'validB':optimizerB, 'validC':optimizerC,\n",
    "             'reservedA':optimizerA, 'reservedB':optimizerB, 'reservedCA':optimizerRC, 'reservedCB':optimizerRC}\n",
    "criterion = {'trainA':criterionA, 'trainB':criterionA, 'trainC':criterionA,\n",
    "             'validA':criterionA, 'validB':criterionA, 'validC':criterionA,\n",
    "             'reservedA':criterionB, 'reservedB':criterionB, 'reservedCA':criterionB, 'reservedCB':criterionB}\n",
    "exp_lr_scheduler = {'trainA':exp_lr_schedulerA, 'trainB':exp_lr_schedulerB, 'trainC':exp_lr_schedulerC,\n",
    "             'validA':exp_lr_schedulerA, 'validB':exp_lr_schedulerB, 'validC':exp_lr_schedulerC,\n",
    "             'reservedA':exp_lr_schedulerA, 'reservedB':exp_lr_schedulerB, 'reservedCA':exp_lr_schedulerC, 'reservedCB':exp_lr_schedulerC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ogoldstein/anaconda3/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/199] phase: validA train loss: 0.0107 acc: 0.7201 valid loss: 0.1264 acc: 0.2393\n",
      "\n",
      "Epoch [0/199] phase: validB train loss: 0.0152 acc: 0.5359 valid loss: 0.1070 acc: 0.1766\n",
      "\n",
      "Epoch [0/199] phase: validC train loss: 0.0153 acc: 0.6876 valid loss: 0.0419 acc: 0.3074\n",
      "\n",
      "Epoch [0/199] phase: validC train loss: 0.0020 acc: 0.7091 valid loss: 0.0362 acc: 0.3339\n",
      "\n",
      "Epoch [0/199] phase: validC train loss: -0.0010 acc: 0.7680 valid loss: 0.0373 acc: 0.3383\n",
      "\n",
      "Epoch [1/199] phase: validA train loss: 0.0074 acc: 0.8156 valid loss: 0.1322 acc: 0.2575\n",
      "\n",
      "Epoch [1/199] phase: validB train loss: 0.0132 acc: 0.6034 valid loss: 0.1188 acc: 0.1897\n",
      "\n",
      "Epoch [1/199] phase: validC train loss: 0.0098 acc: 0.8120 valid loss: 0.0347 acc: 0.3428\n",
      "\n",
      "Epoch [1/199] phase: validC train loss: 0.0011 acc: 0.8078 valid loss: 0.0337 acc: 0.3603\n",
      "\n",
      "Epoch [1/199] phase: validC train loss: -0.0014 acc: 0.8223 valid loss: 0.0312 acc: 0.3690\n",
      "\n",
      "Epoch [2/199] phase: validA train loss: 0.0065 acc: 0.8349 valid loss: 0.1303 acc: 0.2573\n",
      "\n",
      "Epoch [2/199] phase: validB train loss: 0.0123 acc: 0.6446 valid loss: 0.1208 acc: 0.1949\n",
      "\n",
      "Epoch [2/199] phase: validC train loss: 0.0084 acc: 0.8404 valid loss: 0.0329 acc: 0.3670\n",
      "\n",
      "Epoch [2/199] phase: validC train loss: 0.0003 acc: 0.8363 valid loss: 0.0297 acc: 0.4146\n",
      "\n",
      "Epoch [2/199] phase: validC train loss: -0.0017 acc: 0.8405 valid loss: 0.0291 acc: 0.3873\n",
      "\n",
      "Epoch [3/199] phase: validA train loss: 0.0058 acc: 0.8566 valid loss: 0.1334 acc: 0.2593\n",
      "\n",
      "Epoch [3/199] phase: validB train loss: 0.0115 acc: 0.6702 valid loss: 0.1145 acc: 0.2058\n",
      "\n",
      "Epoch [3/199] phase: validC train loss: 0.0070 acc: 0.8676 valid loss: 0.0283 acc: 0.4103\n",
      "\n",
      "Epoch [3/199] phase: validC train loss: 0.0001 acc: 0.8457 valid loss: 0.0282 acc: 0.4339\n",
      "\n",
      "Epoch [3/199] phase: validC train loss: -0.0020 acc: 0.8506 valid loss: 0.0271 acc: 0.4152\n",
      "\n",
      "Epoch [4/199] phase: validA train loss: 0.0052 acc: 0.8680 valid loss: 0.1613 acc: 0.2602\n",
      "\n",
      "Epoch [4/199] phase: validB train loss: 0.0108 acc: 0.6972 valid loss: 0.1330 acc: 0.2084\n",
      "\n",
      "Epoch [4/199] phase: validC train loss: 0.0064 acc: 0.8759 valid loss: 0.0261 acc: 0.4350\n",
      "\n",
      "Epoch [4/199] phase: validC train loss: 0.0008 acc: 0.8526 valid loss: 0.0279 acc: 0.4570\n",
      "\n",
      "Epoch [4/199] phase: validC train loss: -0.0018 acc: 0.8553 valid loss: 0.0269 acc: 0.4571\n",
      "\n",
      "Epoch [5/199] phase: validA train loss: 0.0049 acc: 0.8811 valid loss: 0.1388 acc: 0.2678\n",
      "\n",
      "Epoch [5/199] phase: validB train loss: 0.0102 acc: 0.7145 valid loss: 0.1175 acc: 0.2176\n",
      "\n",
      "Epoch [5/199] phase: validC train loss: 0.0060 acc: 0.8834 valid loss: 0.0256 acc: 0.4623\n",
      "\n",
      "Epoch [5/199] phase: validC train loss: 0.0002 acc: 0.8570 valid loss: 0.0248 acc: 0.4702\n",
      "\n",
      "Epoch [5/199] phase: validC train loss: -0.0027 acc: 0.8627 valid loss: 0.0245 acc: 0.4725\n",
      "\n",
      "Epoch [6/199] phase: validA train loss: 0.0046 acc: 0.8853 valid loss: 0.1397 acc: 0.2683\n",
      "\n",
      "Epoch [6/199] phase: validB train loss: 0.0099 acc: 0.7265 valid loss: 0.1285 acc: 0.2206\n",
      "\n",
      "Epoch [6/199] phase: validC train loss: 0.0056 acc: 0.8912 valid loss: 0.0246 acc: 0.4845\n",
      "\n",
      "Epoch [6/199] phase: validC train loss: -0.0001 acc: 0.8643 valid loss: 0.0259 acc: 0.4787\n",
      "\n",
      "Epoch [6/199] phase: validC train loss: -0.0018 acc: 0.8663 valid loss: 0.0295 acc: 0.4329\n",
      "\n",
      "Epoch [7/199] phase: validA train loss: 0.0043 acc: 0.8952 valid loss: 0.1437 acc: 0.2715\n",
      "\n",
      "Epoch [7/199] phase: validB train loss: 0.0095 acc: 0.7399 valid loss: 0.1262 acc: 0.2258\n",
      "\n",
      "Epoch [7/199] phase: validC train loss: 0.0060 acc: 0.8809 valid loss: 0.0258 acc: 0.4724\n",
      "\n",
      "Epoch [7/199] phase: validC train loss: -0.0002 acc: 0.8687 valid loss: 0.0231 acc: 0.4987\n",
      "\n",
      "Epoch [7/199] phase: validC train loss: -0.0024 acc: 0.8728 valid loss: 0.0244 acc: 0.5205\n",
      "\n",
      "Epoch [8/199] phase: validA train loss: 0.0040 acc: 0.9025 valid loss: 0.1454 acc: 0.2727\n",
      "\n",
      "Epoch [8/199] phase: validB train loss: 0.0093 acc: 0.7442 valid loss: 0.1312 acc: 0.2271\n",
      "\n",
      "Epoch [8/199] phase: validC train loss: 0.0057 acc: 0.8861 valid loss: 0.0228 acc: 0.5224\n",
      "\n",
      "Epoch [8/199] phase: validC train loss: -0.0002 acc: 0.8716 valid loss: 0.0247 acc: 0.5063\n",
      "\n",
      "Epoch [8/199] phase: validC train loss: -0.0021 acc: 0.8764 valid loss: 0.0223 acc: 0.5498\n",
      "\n",
      "Epoch [9/199] phase: validA train loss: 0.0032 acc: 0.9228 valid loss: 0.1561 acc: 0.2773\n",
      "\n",
      "Epoch [9/199] phase: validB train loss: 0.0080 acc: 0.7810 valid loss: 0.1320 acc: 0.2348\n",
      "\n",
      "Epoch [9/199] phase: validC train loss: 0.0055 acc: 0.8909 valid loss: 0.0212 acc: 0.5562\n",
      "\n",
      "Epoch [9/199] phase: validC train loss: 0.0001 acc: 0.8759 valid loss: 0.0247 acc: 0.5265\n",
      "\n",
      "Epoch [9/199] phase: validC train loss: -0.0023 acc: 0.8832 valid loss: 0.0228 acc: 0.5347\n",
      "\n",
      "Epoch [10/199] phase: validA train loss: 0.0029 acc: 0.9301 valid loss: 0.1535 acc: 0.2788\n",
      "\n",
      "Epoch [10/199] phase: validB train loss: 0.0077 acc: 0.7968 valid loss: 0.1358 acc: 0.2365\n",
      "\n",
      "Epoch [10/199] phase: validC train loss: 0.0054 acc: 0.8918 valid loss: 0.0217 acc: 0.5500\n",
      "\n",
      "Epoch [10/199] phase: validC train loss: 0.0001 acc: 0.8781 valid loss: 0.0222 acc: 0.5401\n",
      "\n",
      "Epoch [10/199] phase: validC train loss: -0.0022 acc: 0.8863 valid loss: 0.0248 acc: 0.5116\n",
      "\n",
      "Epoch [11/199] phase: validA train loss: 0.0027 acc: 0.9362 valid loss: 0.1603 acc: 0.2791\n",
      "\n",
      "Epoch [11/199] phase: validB train loss: 0.0075 acc: 0.7999 valid loss: 0.1383 acc: 0.2361\n",
      "\n",
      "Epoch [11/199] phase: validC train loss: 0.0052 acc: 0.8972 valid loss: 0.0248 acc: 0.5116\n",
      "\n",
      "Epoch [11/199] phase: validC train loss: 0.0001 acc: 0.8827 valid loss: 0.0231 acc: 0.5183\n",
      "\n",
      "Epoch [11/199] phase: validC train loss: -0.0023 acc: 0.8889 valid loss: 0.0229 acc: 0.5350\n",
      "\n",
      "Epoch [12/199] phase: validA train loss: 0.0027 acc: 0.9353 valid loss: 0.1567 acc: 0.2783\n",
      "\n",
      "Epoch [12/199] phase: validB train loss: 0.0073 acc: 0.8024 valid loss: 0.1360 acc: 0.2374\n",
      "\n",
      "Epoch [12/199] phase: validC train loss: 0.0049 acc: 0.9015 valid loss: 0.0225 acc: 0.5398\n",
      "\n",
      "Epoch [12/199] phase: validC train loss: -0.0000 acc: 0.8860 valid loss: 0.0220 acc: 0.5589\n",
      "\n",
      "Epoch [12/199] phase: validC train loss: -0.0022 acc: 0.8893 valid loss: 0.0224 acc: 0.5430\n",
      "\n",
      "Epoch [13/199] phase: validA train loss: 0.0025 acc: 0.9380 valid loss: 0.1583 acc: 0.2789\n",
      "\n",
      "Epoch [13/199] phase: validB train loss: 0.0071 acc: 0.8106 valid loss: 0.1369 acc: 0.2393\n",
      "\n",
      "Epoch [13/199] phase: validC train loss: 0.0048 acc: 0.9017 valid loss: 0.0236 acc: 0.5313\n",
      "\n",
      "Epoch [13/199] phase: validC train loss: 0.0001 acc: 0.8896 valid loss: 0.0223 acc: 0.5684\n",
      "\n",
      "Epoch [13/199] phase: validC train loss: -0.0023 acc: 0.8962 valid loss: 0.0219 acc: 0.5663\n",
      "\n",
      "Epoch [14/199] phase: validA train loss: 0.0025 acc: 0.9401 valid loss: 0.1625 acc: 0.2782\n",
      "\n",
      "Epoch [14/199] phase: validB train loss: 0.0072 acc: 0.8097 valid loss: 0.1412 acc: 0.2396\n",
      "\n",
      "Epoch [14/199] phase: validC train loss: 0.0048 acc: 0.9036 valid loss: 0.0210 acc: 0.5836\n",
      "\n",
      "Epoch [14/199] phase: validC train loss: 0.0001 acc: 0.8914 valid loss: 0.0213 acc: 0.5735\n",
      "\n",
      "Epoch [14/199] phase: validC train loss: -0.0024 acc: 0.8964 valid loss: 0.0216 acc: 0.5735\n",
      "\n",
      "Epoch [15/199] phase: validA train loss: 0.0024 acc: 0.9397 valid loss: 0.1652 acc: 0.2801\n",
      "\n",
      "Epoch [15/199] phase: validB train loss: 0.0070 acc: 0.8129 valid loss: 0.1454 acc: 0.2425\n",
      "\n",
      "Epoch [15/199] phase: validC train loss: 0.0044 acc: 0.9136 valid loss: 0.0207 acc: 0.5780\n",
      "\n",
      "Epoch [15/199] phase: validC train loss: -0.0001 acc: 0.8928 valid loss: 0.0204 acc: 0.5826\n",
      "\n",
      "Epoch [15/199] phase: validC train loss: -0.0023 acc: 0.8994 valid loss: 0.0230 acc: 0.5536\n",
      "\n",
      "Epoch [16/199] phase: validA train loss: 0.0023 acc: 0.9444 valid loss: 0.1647 acc: 0.2787\n",
      "\n",
      "Epoch [16/199] phase: validB train loss: 0.0068 acc: 0.8189 valid loss: 0.1428 acc: 0.2410\n",
      "\n",
      "Epoch [16/199] phase: validC train loss: 0.0047 acc: 0.9045 valid loss: 0.0235 acc: 0.5538\n",
      "\n",
      "Epoch [16/199] phase: validC train loss: -0.0001 acc: 0.8952 valid loss: 0.0228 acc: 0.5813\n",
      "\n",
      "Epoch [16/199] phase: validC train loss: -0.0024 acc: 0.9035 valid loss: 0.0234 acc: 0.5576\n",
      "\n",
      "Epoch [17/199] phase: validA train loss: 0.0023 acc: 0.9434 valid loss: 0.1629 acc: 0.2778\n",
      "\n",
      "Epoch [17/199] phase: validB train loss: 0.0067 acc: 0.8242 valid loss: 0.1432 acc: 0.2426\n",
      "\n",
      "Epoch [17/199] phase: validC train loss: 0.0044 acc: 0.9106 valid loss: 0.0225 acc: 0.5676\n",
      "\n",
      "Epoch [17/199] phase: validC train loss: -0.0001 acc: 0.8988 valid loss: 0.0196 acc: 0.5926\n",
      "\n",
      "Epoch [17/199] phase: validC train loss: -0.0024 acc: 0.9030 valid loss: 0.0211 acc: 0.5935\n",
      "\n",
      "Epoch [18/199] phase: validA train loss: 0.0022 acc: 0.9488 valid loss: 0.1660 acc: 0.2787\n",
      "\n",
      "Epoch [18/199] phase: validB train loss: 0.0066 acc: 0.8254 valid loss: 0.1519 acc: 0.2433\n",
      "\n",
      "Epoch [18/199] phase: validC train loss: 0.0042 acc: 0.9122 valid loss: 0.0220 acc: 0.5708\n",
      "\n",
      "Epoch [18/199] phase: validC train loss: -0.0001 acc: 0.9027 valid loss: 0.0199 acc: 0.5942\n",
      "\n",
      "Epoch [18/199] phase: validC train loss: -0.0024 acc: 0.9098 valid loss: 0.0235 acc: 0.5723\n",
      "\n",
      "Epoch [19/199] phase: validA train loss: 0.0021 acc: 0.9503 valid loss: 0.1683 acc: 0.2792\n",
      "\n",
      "Epoch [19/199] phase: validB train loss: 0.0063 acc: 0.8322 valid loss: 0.1477 acc: 0.2423\n",
      "\n",
      "Epoch [19/199] phase: validC train loss: 0.0045 acc: 0.9103 valid loss: 0.0225 acc: 0.5841\n",
      "\n",
      "Epoch [19/199] phase: validC train loss: -0.0001 acc: 0.9018 valid loss: 0.0211 acc: 0.5949\n",
      "\n",
      "Epoch [19/199] phase: validC train loss: -0.0023 acc: 0.9070 valid loss: 0.0194 acc: 0.6122\n",
      "\n",
      "Epoch [20/199] phase: validA train loss: 0.0019 acc: 0.9550 valid loss: 0.1704 acc: 0.2792\n",
      "\n",
      "Epoch [20/199] phase: validB train loss: 0.0063 acc: 0.8349 valid loss: 0.1459 acc: 0.2427\n",
      "\n",
      "Epoch [20/199] phase: validC train loss: 0.0039 acc: 0.9213 valid loss: 0.0201 acc: 0.6078\n",
      "\n",
      "Epoch [20/199] phase: validC train loss: -0.0002 acc: 0.9082 valid loss: 0.0237 acc: 0.5670\n",
      "\n",
      "Epoch [20/199] phase: validC train loss: -0.0024 acc: 0.9105 valid loss: 0.0223 acc: 0.5682\n",
      "\n",
      "Epoch [21/199] phase: validA train loss: 0.0019 acc: 0.9547 valid loss: 0.1687 acc: 0.2792\n",
      "\n",
      "Epoch [21/199] phase: validB train loss: 0.0062 acc: 0.8399 valid loss: 0.1522 acc: 0.2427\n",
      "\n",
      "Epoch [21/199] phase: validC train loss: 0.0041 acc: 0.9155 valid loss: 0.0206 acc: 0.5895\n",
      "\n",
      "Epoch [21/199] phase: validC train loss: -0.0002 acc: 0.9098 valid loss: 0.0211 acc: 0.5937\n",
      "\n",
      "Epoch [21/199] phase: validC train loss: -0.0024 acc: 0.9145 valid loss: 0.0209 acc: 0.6002\n",
      "\n",
      "Epoch [22/199] phase: validA train loss: 0.0019 acc: 0.9540 valid loss: 0.1702 acc: 0.2791\n",
      "\n",
      "Epoch [22/199] phase: validB train loss: 0.0063 acc: 0.8336 valid loss: 0.1472 acc: 0.2432\n",
      "\n",
      "Epoch [22/199] phase: validC train loss: 0.0041 acc: 0.9157 valid loss: 0.0192 acc: 0.6230\n",
      "\n",
      "Epoch [22/199] phase: validC train loss: -0.0002 acc: 0.9077 valid loss: 0.0185 acc: 0.6322\n",
      "\n",
      "Epoch [22/199] phase: validC train loss: -0.0023 acc: 0.9124 valid loss: 0.0221 acc: 0.5811\n",
      "\n",
      "Epoch [23/199] phase: validA train loss: 0.0019 acc: 0.9542 valid loss: 0.1667 acc: 0.2789\n",
      "\n",
      "Epoch [23/199] phase: validB train loss: 0.0062 acc: 0.8361 valid loss: 0.1495 acc: 0.2428\n",
      "\n",
      "Epoch [23/199] phase: validC train loss: 0.0040 acc: 0.9174 valid loss: 0.0217 acc: 0.5856\n",
      "\n",
      "Epoch [23/199] phase: validC train loss: -0.0002 acc: 0.9130 valid loss: 0.0209 acc: 0.5965\n",
      "\n",
      "Epoch [23/199] phase: validC train loss: -0.0024 acc: 0.9177 valid loss: 0.0224 acc: 0.5780\n",
      "\n",
      "Epoch [24/199] phase: validA train loss: 0.0019 acc: 0.9540 valid loss: 0.1665 acc: 0.2788\n",
      "\n",
      "Epoch [24/199] phase: validB train loss: 0.0062 acc: 0.8360 valid loss: 0.1505 acc: 0.2423\n",
      "\n",
      "Epoch [24/199] phase: validC train loss: 0.0035 acc: 0.9282 valid loss: 0.0212 acc: 0.5970\n",
      "\n",
      "Epoch [24/199] phase: validC train loss: -0.0003 acc: 0.9141 valid loss: 0.0203 acc: 0.6205\n",
      "\n",
      "Epoch [24/199] phase: validC train loss: -0.0024 acc: 0.9186 valid loss: 0.0208 acc: 0.6157\n",
      "\n",
      "Epoch [25/199] phase: validA train loss: 0.0019 acc: 0.9533 valid loss: 0.1695 acc: 0.2787\n",
      "\n",
      "Epoch [25/199] phase: validB train loss: 0.0061 acc: 0.8377 valid loss: 0.1501 acc: 0.2425\n",
      "\n",
      "Epoch [25/199] phase: validC train loss: 0.0039 acc: 0.9169 valid loss: 0.0197 acc: 0.6317\n",
      "\n",
      "Epoch [25/199] phase: validC train loss: -0.0003 acc: 0.9143 valid loss: 0.0210 acc: 0.6105\n",
      "\n",
      "Epoch [25/199] phase: validC train loss: -0.0025 acc: 0.9191 valid loss: 0.0200 acc: 0.6338\n",
      "\n",
      "Epoch [26/199] phase: validA train loss: 0.0020 acc: 0.9537 valid loss: 0.1750 acc: 0.2790\n",
      "\n",
      "Epoch [26/199] phase: validB train loss: 0.0062 acc: 0.8359 valid loss: 0.1483 acc: 0.2426\n",
      "\n",
      "Epoch [26/199] phase: validC train loss: 0.0034 acc: 0.9287 valid loss: 0.0200 acc: 0.6358\n",
      "\n",
      "Epoch [26/199] phase: validC train loss: -0.0004 acc: 0.9167 valid loss: 0.0199 acc: 0.6192\n",
      "\n",
      "Epoch [26/199] phase: validC train loss: -0.0027 acc: 0.9232 valid loss: 0.0220 acc: 0.6109\n",
      "\n",
      "Epoch [27/199] phase: validA train loss: 0.0019 acc: 0.9556 valid loss: 0.1722 acc: 0.2781\n",
      "\n",
      "Epoch [27/199] phase: validB train loss: 0.0062 acc: 0.8379 valid loss: 0.1472 acc: 0.2433\n",
      "\n",
      "Epoch [27/199] phase: validC train loss: 0.0033 acc: 0.9332 valid loss: 0.0216 acc: 0.6152\n",
      "\n",
      "Epoch [27/199] phase: validC train loss: -0.0004 acc: 0.9184 valid loss: 0.0211 acc: 0.6170\n",
      "\n",
      "Epoch [27/199] phase: validC train loss: -0.0027 acc: 0.9249 valid loss: 0.0236 acc: 0.5954\n",
      "\n",
      "Epoch [28/199] phase: validA train loss: 0.0019 acc: 0.9552 valid loss: 0.1770 acc: 0.2795\n",
      "\n",
      "Epoch [28/199] phase: validB train loss: 0.0061 acc: 0.8370 valid loss: 0.1503 acc: 0.2426\n",
      "\n",
      "Epoch [28/199] phase: validC train loss: 0.0031 acc: 0.9375 valid loss: 0.0208 acc: 0.6173\n",
      "\n",
      "Epoch [28/199] phase: validC train loss: -0.0004 acc: 0.9218 valid loss: 0.0211 acc: 0.6165\n",
      "\n",
      "Epoch [28/199] phase: validC train loss: -0.0026 acc: 0.9243 valid loss: 0.0210 acc: 0.6181\n",
      "\n",
      "Epoch [29/199] phase: validA train loss: 0.0019 acc: 0.9542 valid loss: 0.1733 acc: 0.2791\n",
      "\n",
      "Epoch [29/199] phase: validB train loss: 0.0060 acc: 0.8439 valid loss: 0.1499 acc: 0.2427\n",
      "\n",
      "Epoch [29/199] phase: validC train loss: 0.0032 acc: 0.9347 valid loss: 0.0187 acc: 0.6445\n",
      "\n",
      "Epoch [29/199] phase: validC train loss: -0.0005 acc: 0.9214 valid loss: 0.0204 acc: 0.6200\n",
      "\n",
      "Epoch [29/199] phase: validC train loss: -0.0026 acc: 0.9229 valid loss: 0.0248 acc: 0.5750\n",
      "\n",
      "Epoch [30/199] phase: validA train loss: 0.0018 acc: 0.9542 valid loss: 0.1757 acc: 0.2791\n",
      "\n",
      "Epoch [30/199] phase: validB train loss: 0.0061 acc: 0.8439 valid loss: 0.1520 acc: 0.2422\n",
      "\n",
      "Epoch [30/199] phase: validC train loss: 0.0032 acc: 0.9330 valid loss: 0.0219 acc: 0.6026\n",
      "\n",
      "Epoch [30/199] phase: validC train loss: -0.0005 acc: 0.9239 valid loss: 0.0251 acc: 0.5719\n",
      "\n",
      "Epoch [30/199] phase: validC train loss: -0.0027 acc: 0.9260 valid loss: 0.0224 acc: 0.6096\n",
      "\n",
      "Epoch [31/199] phase: validA train loss: 0.0019 acc: 0.9549 valid loss: 0.1737 acc: 0.2794\n",
      "\n",
      "Epoch [31/199] phase: validB train loss: 0.0060 acc: 0.8428 valid loss: 0.1505 acc: 0.2425\n",
      "\n",
      "Epoch [31/199] phase: validC train loss: 0.0030 acc: 0.9383 valid loss: 0.0212 acc: 0.6225\n",
      "\n",
      "Epoch [31/199] phase: validC train loss: -0.0005 acc: 0.9247 valid loss: 0.0221 acc: 0.6252\n",
      "\n",
      "Epoch [31/199] phase: validC train loss: -0.0028 acc: 0.9293 valid loss: 0.0208 acc: 0.6318\n",
      "\n",
      "Epoch [32/199] phase: validA train loss: 0.0019 acc: 0.9552 valid loss: 0.1798 acc: 0.2797\n",
      "\n",
      "Epoch [32/199] phase: validB train loss: 0.0061 acc: 0.8386 valid loss: 0.1492 acc: 0.2429\n",
      "\n",
      "Epoch [32/199] phase: validC train loss: 0.0031 acc: 0.9372 valid loss: 0.0215 acc: 0.6232\n",
      "\n",
      "Epoch [32/199] phase: validC train loss: -0.0005 acc: 0.9289 valid loss: 0.0202 acc: 0.6448\n",
      "\n",
      "Epoch [32/199] phase: validC train loss: -0.0028 acc: 0.9320 valid loss: 0.0226 acc: 0.6054\n",
      "\n",
      "Epoch [33/199] phase: validA train loss: 0.0018 acc: 0.9563 valid loss: 0.1717 acc: 0.2792\n",
      "\n",
      "Epoch [33/199] phase: validB train loss: 0.0060 acc: 0.8423 valid loss: 0.1504 acc: 0.2426\n",
      "\n",
      "Epoch [33/199] phase: validC train loss: 0.0030 acc: 0.9395 valid loss: 0.0227 acc: 0.6057\n",
      "\n",
      "Epoch [33/199] phase: validC train loss: -0.0006 acc: 0.9273 valid loss: 0.0187 acc: 0.6580\n",
      "\n",
      "Epoch [33/199] phase: validC train loss: -0.0028 acc: 0.9316 valid loss: 0.0222 acc: 0.6175\n",
      "\n",
      "Epoch [34/199] phase: validA train loss: 0.0018 acc: 0.9568 valid loss: 0.1722 acc: 0.2795\n",
      "\n",
      "Epoch [34/199] phase: validB train loss: 0.0060 acc: 0.8410 valid loss: 0.1501 acc: 0.2432\n",
      "\n",
      "Epoch [34/199] phase: validC train loss: 0.0031 acc: 0.9345 valid loss: 0.0218 acc: 0.6231\n",
      "\n",
      "Epoch [34/199] phase: validC train loss: -0.0007 acc: 0.9311 valid loss: 0.0185 acc: 0.6514\n",
      "\n",
      "Epoch [34/199] phase: validC train loss: -0.0028 acc: 0.9323 valid loss: 0.0193 acc: 0.6546\n",
      "\n",
      "Epoch [35/199] phase: validA train loss: 0.0018 acc: 0.9566 valid loss: 0.1743 acc: 0.2791\n",
      "\n",
      "Epoch [35/199] phase: validB train loss: 0.0061 acc: 0.8353 valid loss: 0.1491 acc: 0.2426\n",
      "\n",
      "Epoch [35/199] phase: validC train loss: 0.0030 acc: 0.9374 valid loss: 0.0206 acc: 0.6425\n",
      "\n",
      "Epoch [35/199] phase: validC train loss: -0.0007 acc: 0.9300 valid loss: 0.0199 acc: 0.6244\n",
      "\n",
      "Epoch [35/199] phase: validC train loss: -0.0029 acc: 0.9338 valid loss: 0.0228 acc: 0.6159\n",
      "\n",
      "Epoch [36/199] phase: validA train loss: 0.0018 acc: 0.9573 valid loss: 0.1761 acc: 0.2790\n",
      "\n",
      "Epoch [36/199] phase: validB train loss: 0.0060 acc: 0.8424 valid loss: 0.1520 acc: 0.2426\n",
      "\n",
      "Epoch [36/199] phase: validC train loss: 0.0028 acc: 0.9417 valid loss: 0.0211 acc: 0.6316\n",
      "\n",
      "Epoch [36/199] phase: validC train loss: -0.0007 acc: 0.9328 valid loss: 0.0224 acc: 0.6259\n",
      "\n",
      "Epoch [36/199] phase: validC train loss: -0.0030 acc: 0.9364 valid loss: 0.0258 acc: 0.5977\n",
      "\n",
      "Epoch [37/199] phase: validA train loss: 0.0019 acc: 0.9569 valid loss: 0.1719 acc: 0.2788\n",
      "\n",
      "Epoch [37/199] phase: validB train loss: 0.0060 acc: 0.8411 valid loss: 0.1490 acc: 0.2424\n",
      "\n",
      "Epoch [37/199] phase: validC train loss: 0.0027 acc: 0.9444 valid loss: 0.0227 acc: 0.6259\n",
      "\n",
      "Epoch [37/199] phase: validC train loss: -0.0007 acc: 0.9330 valid loss: 0.0199 acc: 0.6408\n",
      "\n",
      "Epoch [37/199] phase: validC train loss: -0.0029 acc: 0.9378 valid loss: 0.0209 acc: 0.6424\n",
      "\n",
      "Epoch [38/199] phase: validA train loss: 0.0018 acc: 0.9562 valid loss: 0.1726 acc: 0.2796\n",
      "\n",
      "Epoch [38/199] phase: validB train loss: 0.0061 acc: 0.8383 valid loss: 0.1510 acc: 0.2429\n",
      "\n",
      "Epoch [38/199] phase: validC train loss: 0.0027 acc: 0.9435 valid loss: 0.0204 acc: 0.6455\n",
      "\n",
      "Epoch [38/199] phase: validC train loss: -0.0007 acc: 0.9340 valid loss: 0.0221 acc: 0.6106\n",
      "\n",
      "Epoch [38/199] phase: validC train loss: -0.0030 acc: 0.9390 valid loss: 0.0242 acc: 0.6143\n",
      "\n",
      "Epoch [39/199] phase: validA train loss: 0.0019 acc: 0.9552 valid loss: 0.1766 acc: 0.2790\n",
      "\n",
      "Epoch [39/199] phase: validB train loss: 0.0060 acc: 0.8393 valid loss: 0.1524 acc: 0.2433\n",
      "\n",
      "Epoch [39/199] phase: validC train loss: 0.0027 acc: 0.9444 valid loss: 0.0208 acc: 0.6380\n",
      "\n",
      "Epoch [39/199] phase: validC train loss: -0.0007 acc: 0.9351 valid loss: 0.0224 acc: 0.6245\n",
      "\n",
      "Epoch [39/199] phase: validC train loss: -0.0028 acc: 0.9383 valid loss: 0.0224 acc: 0.6316\n",
      "\n",
      "Epoch [40/199] phase: validA train loss: 0.0018 acc: 0.9542 valid loss: 0.1704 acc: 0.2791\n",
      "\n",
      "Epoch [40/199] phase: validB train loss: 0.0061 acc: 0.8403 valid loss: 0.1523 acc: 0.2428\n",
      "\n",
      "Epoch [40/199] phase: validC train loss: 0.0029 acc: 0.9405 valid loss: 0.0198 acc: 0.6604\n",
      "\n",
      "Epoch [40/199] phase: validC train loss: -0.0009 acc: 0.9377 valid loss: 0.0210 acc: 0.6330\n",
      "\n",
      "Epoch [40/199] phase: validC train loss: -0.0029 acc: 0.9361 valid loss: 0.0212 acc: 0.6382\n",
      "\n",
      "Epoch [41/199] phase: validA train loss: 0.0018 acc: 0.9573 valid loss: 0.1719 acc: 0.2790\n",
      "\n",
      "Epoch [41/199] phase: validB train loss: 0.0061 acc: 0.8391 valid loss: 0.1516 acc: 0.2425\n",
      "\n",
      "Epoch [41/199] phase: validC train loss: 0.0024 acc: 0.9487 valid loss: 0.0206 acc: 0.6478\n",
      "\n",
      "Epoch [41/199] phase: validC train loss: -0.0008 acc: 0.9372 valid loss: 0.0226 acc: 0.6281\n",
      "\n",
      "Epoch [41/199] phase: validC train loss: -0.0030 acc: 0.9409 valid loss: 0.0241 acc: 0.6083\n",
      "\n",
      "Epoch [42/199] phase: validA train loss: 0.0018 acc: 0.9563 valid loss: 0.1762 acc: 0.2792\n",
      "\n",
      "Epoch [42/199] phase: validB train loss: 0.0062 acc: 0.8370 valid loss: 0.1519 acc: 0.2425\n",
      "\n",
      "Epoch [42/199] phase: validC train loss: 0.0027 acc: 0.9451 valid loss: 0.0216 acc: 0.6315\n",
      "\n",
      "Epoch [42/199] phase: validC train loss: -0.0008 acc: 0.9377 valid loss: 0.0230 acc: 0.6221\n",
      "\n",
      "Epoch [42/199] phase: validC train loss: -0.0031 acc: 0.9421 valid loss: 0.0206 acc: 0.6555\n",
      "\n",
      "Epoch [43/199] phase: validA train loss: 0.0018 acc: 0.9565 valid loss: 0.1725 acc: 0.2789\n",
      "\n",
      "Epoch [43/199] phase: validB train loss: 0.0061 acc: 0.8400 valid loss: 0.1503 acc: 0.2429\n",
      "\n",
      "Epoch [43/199] phase: validC train loss: 0.0023 acc: 0.9510 valid loss: 0.0204 acc: 0.6554\n",
      "\n",
      "Epoch [43/199] phase: validC train loss: -0.0010 acc: 0.9423 valid loss: 0.0219 acc: 0.6365\n",
      "\n",
      "Epoch [43/199] phase: validC train loss: -0.0031 acc: 0.9424 valid loss: 0.0222 acc: 0.6362\n",
      "\n",
      "Epoch [44/199] phase: validA train loss: 0.0019 acc: 0.9548 valid loss: 0.1733 acc: 0.2795\n",
      "\n",
      "Epoch [44/199] phase: validB train loss: 0.0061 acc: 0.8388 valid loss: 0.1473 acc: 0.2423\n",
      "\n",
      "Epoch [44/199] phase: validC train loss: 0.0024 acc: 0.9480 valid loss: 0.0208 acc: 0.6508\n",
      "\n",
      "Epoch [44/199] phase: validC train loss: -0.0009 acc: 0.9407 valid loss: 0.0213 acc: 0.6320\n",
      "\n",
      "Epoch [44/199] phase: validC train loss: -0.0031 acc: 0.9444 valid loss: 0.0237 acc: 0.6321\n",
      "\n",
      "Epoch [45/199] phase: validA train loss: 0.0019 acc: 0.9542 valid loss: 0.1714 acc: 0.2786\n",
      "\n",
      "Epoch [45/199] phase: validB train loss: 0.0061 acc: 0.8404 valid loss: 0.1553 acc: 0.2427\n",
      "\n",
      "Epoch [45/199] phase: validC train loss: 0.0024 acc: 0.9500 valid loss: 0.0224 acc: 0.6468\n",
      "\n",
      "Epoch [45/199] phase: validC train loss: -0.0010 acc: 0.9415 valid loss: 0.0206 acc: 0.6502\n",
      "\n",
      "Epoch [45/199] phase: validC train loss: -0.0031 acc: 0.9464 valid loss: 0.0199 acc: 0.6664\n",
      "\n",
      "Epoch [46/199] phase: validA train loss: 0.0018 acc: 0.9546 valid loss: 0.1740 acc: 0.2793\n",
      "\n",
      "Epoch [46/199] phase: validB train loss: 0.0061 acc: 0.8379 valid loss: 0.1528 acc: 0.2424\n",
      "\n",
      "Epoch [46/199] phase: validC train loss: 0.0026 acc: 0.9444 valid loss: 0.0200 acc: 0.6644\n",
      "\n",
      "Epoch [46/199] phase: validC train loss: -0.0010 acc: 0.9436 valid loss: 0.0241 acc: 0.6234\n",
      "\n",
      "Epoch [46/199] phase: validC train loss: -0.0031 acc: 0.9440 valid loss: 0.0223 acc: 0.6364\n",
      "\n",
      "Epoch [47/199] phase: validA train loss: 0.0018 acc: 0.9566 valid loss: 0.1697 acc: 0.2791\n",
      "\n",
      "Epoch [47/199] phase: validB train loss: 0.0061 acc: 0.8418 valid loss: 0.1485 acc: 0.2428\n",
      "\n",
      "Epoch [47/199] phase: validC train loss: 0.0024 acc: 0.9498 valid loss: 0.0205 acc: 0.6604\n",
      "\n",
      "Epoch [47/199] phase: validC train loss: -0.0010 acc: 0.9430 valid loss: 0.0238 acc: 0.6148\n",
      "\n",
      "Epoch [47/199] phase: validC train loss: -0.0031 acc: 0.9470 valid loss: 0.0231 acc: 0.6304\n",
      "\n",
      "Epoch [48/199] phase: validA train loss: 0.0018 acc: 0.9563 valid loss: 0.1706 acc: 0.2790\n",
      "\n",
      "Epoch [48/199] phase: validB train loss: 0.0061 acc: 0.8357 valid loss: 0.1522 acc: 0.2432\n",
      "\n",
      "Epoch [48/199] phase: validC train loss: 0.0022 acc: 0.9565 valid loss: 0.0216 acc: 0.6459\n",
      "\n",
      "Epoch [48/199] phase: validC train loss: -0.0010 acc: 0.9425 valid loss: 0.0203 acc: 0.6561\n",
      "\n",
      "Epoch [48/199] phase: validC train loss: -0.0032 acc: 0.9474 valid loss: 0.0219 acc: 0.6350\n",
      "\n",
      "Epoch [49/199] phase: validA train loss: 0.0019 acc: 0.9548 valid loss: 0.1740 acc: 0.2789\n",
      "\n",
      "Epoch [49/199] phase: validB train loss: 0.0060 acc: 0.8416 valid loss: 0.1489 acc: 0.2419\n",
      "\n",
      "Epoch [49/199] phase: validC train loss: 0.0023 acc: 0.9536 valid loss: 0.0223 acc: 0.6338\n",
      "\n",
      "Epoch [49/199] phase: validC train loss: -0.0010 acc: 0.9451 valid loss: 0.0238 acc: 0.6240\n",
      "\n",
      "Epoch [49/199] phase: validC train loss: -0.0032 acc: 0.9497 valid loss: 0.0236 acc: 0.6259\n",
      "\n",
      "Epoch [50/199] phase: validA train loss: 0.0018 acc: 0.9572 valid loss: 0.1722 acc: 0.2791\n",
      "\n",
      "Epoch [50/199] phase: validB train loss: 0.0061 acc: 0.8390 valid loss: 0.1517 acc: 0.2422\n",
      "\n",
      "Epoch [50/199] phase: validC train loss: 0.0023 acc: 0.9519 valid loss: 0.0231 acc: 0.6312\n",
      "\n",
      "Epoch [50/199] phase: validC train loss: -0.0010 acc: 0.9444 valid loss: 0.0277 acc: 0.5973\n",
      "\n",
      "Epoch [50/199] phase: validC train loss: -0.0033 acc: 0.9500 valid loss: 0.0209 acc: 0.6700\n",
      "\n",
      "Epoch [51/199] phase: validA train loss: 0.0019 acc: 0.9576 valid loss: 0.1774 acc: 0.2792\n",
      "\n",
      "Epoch [51/199] phase: validB train loss: 0.0060 acc: 0.8422 valid loss: 0.1483 acc: 0.2427\n",
      "\n",
      "Epoch [51/199] phase: validC train loss: 0.0022 acc: 0.9518 valid loss: 0.0209 acc: 0.6669\n",
      "\n",
      "Epoch [51/199] phase: validC train loss: -0.0010 acc: 0.9491 valid loss: 0.0223 acc: 0.6417\n",
      "\n",
      "Epoch [51/199] phase: validC train loss: -0.0033 acc: 0.9466 valid loss: 0.0220 acc: 0.6510\n",
      "\n",
      "Epoch [52/199] phase: validA train loss: 0.0018 acc: 0.9584 valid loss: 0.1765 acc: 0.2794\n",
      "\n",
      "Epoch [52/199] phase: validB train loss: 0.0060 acc: 0.8401 valid loss: 0.1520 acc: 0.2427\n",
      "\n",
      "Epoch [52/199] phase: validC train loss: 0.0021 acc: 0.9558 valid loss: 0.0219 acc: 0.6438\n",
      "\n",
      "Epoch [52/199] phase: validC train loss: -0.0010 acc: 0.9452 valid loss: 0.0238 acc: 0.6144\n",
      "\n",
      "Epoch [52/199] phase: validC train loss: -0.0034 acc: 0.9524 valid loss: 0.0250 acc: 0.6187\n",
      "\n",
      "Epoch [53/199] phase: validA train loss: 0.0018 acc: 0.9577 valid loss: 0.1733 acc: 0.2792\n",
      "\n",
      "Epoch [53/199] phase: validB train loss: 0.0060 acc: 0.8398 valid loss: 0.1506 acc: 0.2429\n",
      "\n",
      "Epoch [53/199] phase: validC train loss: 0.0022 acc: 0.9544 valid loss: 0.0236 acc: 0.6302\n",
      "\n",
      "Epoch [53/199] phase: validC train loss: -0.0010 acc: 0.9476 valid loss: 0.0235 acc: 0.6440\n",
      "\n",
      "Epoch [53/199] phase: validC train loss: -0.0033 acc: 0.9498 valid loss: 0.0247 acc: 0.6317\n",
      "\n",
      "Epoch [54/199] phase: validA train loss: 0.0019 acc: 0.9561 valid loss: 0.1742 acc: 0.2791\n",
      "\n",
      "Epoch [54/199] phase: validB train loss: 0.0061 acc: 0.8392 valid loss: 0.1509 acc: 0.2426\n",
      "\n",
      "Epoch [54/199] phase: validC train loss: 0.0022 acc: 0.9532 valid loss: 0.0239 acc: 0.6373\n",
      "\n",
      "Epoch [54/199] phase: validC train loss: -0.0011 acc: 0.9465 valid loss: 0.0216 acc: 0.6437\n",
      "\n",
      "Epoch [54/199] phase: validC train loss: -0.0033 acc: 0.9487 valid loss: 0.0208 acc: 0.6537\n",
      "\n",
      "Epoch [55/199] phase: validA train loss: 0.0018 acc: 0.9554 valid loss: 0.1832 acc: 0.2796\n",
      "\n",
      "Epoch [55/199] phase: validB train loss: 0.0061 acc: 0.8402 valid loss: 0.1519 acc: 0.2431\n",
      "\n",
      "Epoch [55/199] phase: validC train loss: 0.0020 acc: 0.9590 valid loss: 0.0216 acc: 0.6476\n",
      "\n",
      "Epoch [55/199] phase: validC train loss: -0.0011 acc: 0.9508 valid loss: 0.0199 acc: 0.6667\n",
      "\n",
      "Epoch [55/199] phase: validC train loss: -0.0034 acc: 0.9494 valid loss: 0.0257 acc: 0.6059\n",
      "\n",
      "Epoch [56/199] phase: validA train loss: 0.0018 acc: 0.9558 valid loss: 0.1744 acc: 0.2792\n",
      "\n",
      "Epoch [56/199] phase: validB train loss: 0.0061 acc: 0.8407 valid loss: 0.1491 acc: 0.2423\n",
      "\n",
      "Epoch [56/199] phase: validC train loss: 0.0022 acc: 0.9530 valid loss: 0.0228 acc: 0.6318\n",
      "\n",
      "Epoch [56/199] phase: validC train loss: -0.0012 acc: 0.9504 valid loss: 0.0195 acc: 0.6791\n",
      "\n",
      "Epoch [56/199] phase: validC train loss: -0.0034 acc: 0.9524 valid loss: 0.0232 acc: 0.6462\n",
      "\n",
      "Epoch [57/199] phase: validA train loss: 0.0018 acc: 0.9576 valid loss: 0.1723 acc: 0.2785\n",
      "\n",
      "Epoch [57/199] phase: validB train loss: 0.0061 acc: 0.8375 valid loss: 0.1508 acc: 0.2428\n",
      "\n",
      "Epoch [57/199] phase: validC train loss: 0.0020 acc: 0.9572 valid loss: 0.0230 acc: 0.6472\n",
      "\n",
      "Epoch [57/199] phase: validC train loss: -0.0011 acc: 0.9510 valid loss: 0.0229 acc: 0.6376\n",
      "\n",
      "Epoch [57/199] phase: validC train loss: -0.0033 acc: 0.9515 valid loss: 0.0230 acc: 0.6399\n",
      "\n",
      "Epoch [58/199] phase: validA train loss: 0.0018 acc: 0.9587 valid loss: 0.1781 acc: 0.2793\n",
      "\n",
      "Epoch [58/199] phase: validB train loss: 0.0062 acc: 0.8390 valid loss: 0.1514 acc: 0.2427\n",
      "\n",
      "Epoch [58/199] phase: validC train loss: 0.0018 acc: 0.9627 valid loss: 0.0231 acc: 0.6374\n",
      "\n",
      "Epoch [58/199] phase: validC train loss: -0.0012 acc: 0.9539 valid loss: 0.0243 acc: 0.6279\n",
      "\n",
      "Epoch [58/199] phase: validC train loss: -0.0033 acc: 0.9531 valid loss: 0.0210 acc: 0.6653\n",
      "\n",
      "Epoch [59/199] phase: validA train loss: 0.0018 acc: 0.9586 valid loss: 0.1705 acc: 0.2789\n",
      "\n",
      "Epoch [59/199] phase: validB train loss: 0.0061 acc: 0.8376 valid loss: 0.1465 acc: 0.2423\n",
      "\n",
      "Epoch [59/199] phase: validC train loss: 0.0018 acc: 0.9637 valid loss: 0.0227 acc: 0.6503\n",
      "\n",
      "Epoch [59/199] phase: validC train loss: -0.0012 acc: 0.9515 valid loss: 0.0248 acc: 0.6144\n",
      "\n",
      "Epoch [59/199] phase: validC train loss: -0.0034 acc: 0.9547 valid loss: 0.0236 acc: 0.6325\n",
      "\n",
      "Epoch [60/199] phase: validA train loss: 0.0019 acc: 0.9555 valid loss: 0.1758 acc: 0.2790\n",
      "\n",
      "Epoch [60/199] phase: validB train loss: 0.0061 acc: 0.8394 valid loss: 0.1465 acc: 0.2424\n",
      "\n",
      "Epoch [60/199] phase: validC train loss: 0.0018 acc: 0.9620 valid loss: 0.0230 acc: 0.6372\n",
      "\n",
      "Epoch [60/199] phase: validC train loss: -0.0011 acc: 0.9525 valid loss: 0.0186 acc: 0.6866\n",
      "\n",
      "Epoch [60/199] phase: validC train loss: -0.0034 acc: 0.9548 valid loss: 0.0272 acc: 0.6000\n",
      "\n",
      "Epoch [61/199] phase: validA train loss: 0.0018 acc: 0.9560 valid loss: 0.1736 acc: 0.2792\n",
      "\n",
      "Epoch [61/199] phase: validB train loss: 0.0061 acc: 0.8385 valid loss: 0.1565 acc: 0.2423\n",
      "\n",
      "Epoch [61/199] phase: validC train loss: 0.0018 acc: 0.9629 valid loss: 0.0257 acc: 0.6153\n",
      "\n",
      "Epoch [61/199] phase: validC train loss: -0.0013 acc: 0.9546 valid loss: 0.0213 acc: 0.6531\n",
      "\n",
      "Epoch [61/199] phase: validC train loss: -0.0034 acc: 0.9556 valid loss: 0.0215 acc: 0.6652\n",
      "\n",
      "Epoch [62/199] phase: validA train loss: 0.0018 acc: 0.9552 valid loss: 0.1780 acc: 0.2790\n",
      "\n",
      "Epoch [62/199] phase: validB train loss: 0.0061 acc: 0.8409 valid loss: 0.1484 acc: 0.2427\n",
      "\n",
      "Epoch [62/199] phase: validC train loss: 0.0019 acc: 0.9599 valid loss: 0.0211 acc: 0.6679\n",
      "\n",
      "Epoch [62/199] phase: validC train loss: -0.0012 acc: 0.9545 valid loss: 0.0224 acc: 0.6440\n",
      "\n",
      "Epoch [62/199] phase: validC train loss: -0.0035 acc: 0.9583 valid loss: 0.0222 acc: 0.6508\n",
      "\n",
      "Epoch [63/199] phase: validA train loss: 0.0018 acc: 0.9554 valid loss: 0.1777 acc: 0.2790\n",
      "\n",
      "Epoch [63/199] phase: validB train loss: 0.0060 acc: 0.8408 valid loss: 0.1513 acc: 0.2428\n",
      "\n",
      "Epoch [63/199] phase: validC train loss: 0.0021 acc: 0.9575 valid loss: 0.0237 acc: 0.6419\n",
      "\n",
      "Epoch [63/199] phase: validC train loss: -0.0012 acc: 0.9544 valid loss: 0.0212 acc: 0.6547\n",
      "\n",
      "Epoch [63/199] phase: validC train loss: -0.0035 acc: 0.9577 valid loss: 0.0244 acc: 0.6502\n",
      "\n",
      "Epoch [64/199] phase: validA train loss: 0.0018 acc: 0.9556 valid loss: 0.1766 acc: 0.2794\n",
      "\n",
      "Epoch [64/199] phase: validB train loss: 0.0060 acc: 0.8436 valid loss: 0.1510 acc: 0.2426\n",
      "\n",
      "Epoch [64/199] phase: validC train loss: 0.0019 acc: 0.9605 valid loss: 0.0225 acc: 0.6641\n",
      "\n",
      "Epoch [64/199] phase: validC train loss: -0.0013 acc: 0.9561 valid loss: 0.0230 acc: 0.6492\n",
      "\n",
      "Epoch [64/199] phase: validC train loss: -0.0035 acc: 0.9580 valid loss: 0.0250 acc: 0.6225\n",
      "\n",
      "Epoch [65/199] phase: validA train loss: 0.0018 acc: 0.9544 valid loss: 0.1737 acc: 0.2787\n",
      "\n",
      "Epoch [65/199] phase: validB train loss: 0.0060 acc: 0.8416 valid loss: 0.1520 acc: 0.2429\n",
      "\n",
      "Epoch [65/199] phase: validC train loss: 0.0019 acc: 0.9600 valid loss: 0.0251 acc: 0.6238\n",
      "\n",
      "Epoch [65/199] phase: validC train loss: -0.0012 acc: 0.9559 valid loss: 0.0219 acc: 0.6437\n",
      "\n",
      "Epoch [65/199] phase: validC train loss: -0.0035 acc: 0.9598 valid loss: 0.0245 acc: 0.6358\n",
      "\n",
      "Epoch [66/199] phase: validA train loss: 0.0018 acc: 0.9571 valid loss: 0.1738 acc: 0.2790\n",
      "\n",
      "Epoch [66/199] phase: validB train loss: 0.0060 acc: 0.8464 valid loss: 0.1533 acc: 0.2429\n",
      "\n",
      "Epoch [66/199] phase: validC train loss: 0.0015 acc: 0.9691 valid loss: 0.0237 acc: 0.6430\n",
      "\n",
      "Epoch [66/199] phase: validC train loss: -0.0013 acc: 0.9559 valid loss: 0.0225 acc: 0.6528\n",
      "\n",
      "Epoch [66/199] phase: validC train loss: -0.0034 acc: 0.9576 valid loss: 0.0237 acc: 0.6339\n",
      "\n",
      "Epoch [67/199] phase: validA train loss: 0.0019 acc: 0.9555 valid loss: 0.1725 acc: 0.2793\n",
      "\n",
      "Epoch [67/199] phase: validB train loss: 0.0060 acc: 0.8407 valid loss: 0.1503 acc: 0.2426\n",
      "\n",
      "Epoch [67/199] phase: validC train loss: 0.0016 acc: 0.9672 valid loss: 0.0227 acc: 0.6454\n",
      "\n",
      "Epoch [67/199] phase: validC train loss: -0.0013 acc: 0.9575 valid loss: 0.0246 acc: 0.6308\n",
      "\n",
      "Epoch [67/199] phase: validC train loss: -0.0035 acc: 0.9612 valid loss: 0.0260 acc: 0.6302\n",
      "\n",
      "Epoch [68/199] phase: validA train loss: 0.0018 acc: 0.9573 valid loss: 0.1731 acc: 0.2788\n",
      "\n",
      "Epoch [68/199] phase: validB train loss: 0.0061 acc: 0.8383 valid loss: 0.1519 acc: 0.2427\n",
      "\n",
      "Epoch [68/199] phase: validC train loss: 0.0017 acc: 0.9645 valid loss: 0.0251 acc: 0.6389\n",
      "\n",
      "Epoch [68/199] phase: validC train loss: -0.0014 acc: 0.9574 valid loss: 0.0237 acc: 0.6326\n",
      "\n",
      "Epoch [68/199] phase: validC train loss: -0.0036 acc: 0.9609 valid loss: 0.0234 acc: 0.6493\n",
      "\n",
      "Epoch [69/199] phase: validA train loss: 0.0019 acc: 0.9542 valid loss: 0.1717 acc: 0.2791\n",
      "\n",
      "Epoch [69/199] phase: validB train loss: 0.0060 acc: 0.8411 valid loss: 0.1563 acc: 0.2425\n",
      "\n",
      "Epoch [69/199] phase: validC train loss: 0.0016 acc: 0.9665 valid loss: 0.0249 acc: 0.6361\n",
      "\n",
      "Epoch [69/199] phase: validC train loss: -0.0014 acc: 0.9584 valid loss: 0.0246 acc: 0.6307\n",
      "\n",
      "Epoch [69/199] phase: validC train loss: -0.0035 acc: 0.9614 valid loss: 0.0272 acc: 0.6181\n",
      "\n",
      "Epoch [70/199] phase: validA train loss: 0.0018 acc: 0.9547 valid loss: 0.1765 acc: 0.2797\n",
      "\n",
      "Epoch [70/199] phase: validB train loss: 0.0060 acc: 0.8449 valid loss: 0.1511 acc: 0.2424\n",
      "\n",
      "Epoch [70/199] phase: validC train loss: 0.0016 acc: 0.9665 valid loss: 0.0250 acc: 0.6422\n",
      "\n",
      "Epoch [70/199] phase: validC train loss: -0.0013 acc: 0.9580 valid loss: 0.0264 acc: 0.6220\n",
      "\n",
      "Epoch [70/199] phase: validC train loss: -0.0035 acc: 0.9603 valid loss: 0.0257 acc: 0.6271\n",
      "\n",
      "Epoch [71/199] phase: validA train loss: 0.0019 acc: 0.9540 valid loss: 0.1736 acc: 0.2794\n",
      "\n",
      "Epoch [71/199] phase: validB train loss: 0.0062 acc: 0.8371 valid loss: 0.1512 acc: 0.2431\n",
      "\n",
      "Epoch [71/199] phase: validC train loss: 0.0016 acc: 0.9649 valid loss: 0.0251 acc: 0.6303\n",
      "\n",
      "Epoch [71/199] phase: validC train loss: -0.0013 acc: 0.9585 valid loss: 0.0243 acc: 0.6414\n",
      "\n",
      "Epoch [71/199] phase: validC train loss: -0.0035 acc: 0.9614 valid loss: 0.0265 acc: 0.6178\n",
      "\n",
      "Epoch [72/199] phase: validA train loss: 0.0018 acc: 0.9564 valid loss: 0.1700 acc: 0.2788\n",
      "\n",
      "Epoch [72/199] phase: validB train loss: 0.0060 acc: 0.8430 valid loss: 0.1522 acc: 0.2424\n",
      "\n",
      "Epoch [72/199] phase: validC train loss: 0.0020 acc: 0.9586 valid loss: 0.0268 acc: 0.6088\n",
      "\n",
      "Epoch [72/199] phase: validC train loss: -0.0013 acc: 0.9572 valid loss: 0.0237 acc: 0.6394\n",
      "\n",
      "Epoch [72/199] phase: validC train loss: -0.0035 acc: 0.9593 valid loss: 0.0263 acc: 0.6292\n",
      "\n",
      "Epoch [73/199] phase: validA train loss: 0.0018 acc: 0.9567 valid loss: 0.1747 acc: 0.2791\n",
      "\n",
      "Epoch [73/199] phase: validB train loss: 0.0060 acc: 0.8411 valid loss: 0.1500 acc: 0.2428\n",
      "\n",
      "Epoch [73/199] phase: validC train loss: 0.0017 acc: 0.9642 valid loss: 0.0253 acc: 0.6362\n",
      "\n",
      "Epoch [73/199] phase: validC train loss: -0.0013 acc: 0.9594 valid loss: 0.0248 acc: 0.6295\n",
      "\n",
      "Epoch [73/199] phase: validC train loss: -0.0036 acc: 0.9614 valid loss: 0.0252 acc: 0.6451\n",
      "\n",
      "Epoch [74/199] phase: validA train loss: 0.0018 acc: 0.9567 valid loss: 0.1761 acc: 0.2793\n",
      "\n",
      "Epoch [74/199] phase: validB train loss: 0.0060 acc: 0.8406 valid loss: 0.1535 acc: 0.2427\n",
      "\n",
      "Epoch [74/199] phase: validC train loss: 0.0014 acc: 0.9719 valid loss: 0.0241 acc: 0.6524\n",
      "\n",
      "Epoch [74/199] phase: validC train loss: -0.0013 acc: 0.9588 valid loss: 0.0233 acc: 0.6441\n",
      "\n",
      "Epoch [74/199] phase: validC train loss: -0.0036 acc: 0.9631 valid loss: 0.0262 acc: 0.6190\n",
      "\n",
      "Epoch [75/199] phase: validA train loss: 0.0019 acc: 0.9544 valid loss: 0.1764 acc: 0.2795\n",
      "\n",
      "Epoch [75/199] phase: validB train loss: 0.0061 acc: 0.8399 valid loss: 0.1504 acc: 0.2420\n",
      "\n",
      "Epoch [75/199] phase: validC train loss: 0.0017 acc: 0.9650 valid loss: 0.0246 acc: 0.6368\n",
      "\n",
      "Epoch [75/199] phase: validC train loss: -0.0014 acc: 0.9622 valid loss: 0.0239 acc: 0.6427\n",
      "\n",
      "Epoch [75/199] phase: validC train loss: -0.0035 acc: 0.9597 valid loss: 0.0242 acc: 0.6421\n",
      "\n",
      "Epoch [76/199] phase: validA train loss: 0.0019 acc: 0.9568 valid loss: 0.1689 acc: 0.2787\n",
      "\n",
      "Epoch [76/199] phase: validB train loss: 0.0061 acc: 0.8404 valid loss: 0.1449 acc: 0.2427\n",
      "\n",
      "Epoch [76/199] phase: validC train loss: 0.0015 acc: 0.9676 valid loss: 0.0234 acc: 0.6441\n",
      "\n",
      "Epoch [76/199] phase: validC train loss: -0.0014 acc: 0.9613 valid loss: 0.0243 acc: 0.6405\n",
      "\n",
      "Epoch [76/199] phase: validC train loss: -0.0036 acc: 0.9607 valid loss: 0.0218 acc: 0.6671\n",
      "\n",
      "Epoch [77/199] phase: validA train loss: 0.0018 acc: 0.9562 valid loss: 0.1767 acc: 0.2789\n",
      "\n",
      "Epoch [77/199] phase: validB train loss: 0.0060 acc: 0.8426 valid loss: 0.1522 acc: 0.2423\n",
      "\n",
      "Epoch [77/199] phase: validC train loss: 0.0014 acc: 0.9703 valid loss: 0.0227 acc: 0.6582\n",
      "\n",
      "Epoch [77/199] phase: validC train loss: -0.0014 acc: 0.9618 valid loss: 0.0233 acc: 0.6467\n",
      "\n",
      "Epoch [77/199] phase: validC train loss: -0.0036 acc: 0.9646 valid loss: 0.0313 acc: 0.5897\n",
      "\n",
      "Epoch [78/199] phase: validA train loss: 0.0018 acc: 0.9561 valid loss: 0.1737 acc: 0.2792\n",
      "\n",
      "Epoch [78/199] phase: validB train loss: 0.0060 acc: 0.8424 valid loss: 0.1523 acc: 0.2428\n",
      "\n",
      "Epoch [78/199] phase: validC train loss: 0.0016 acc: 0.9658 valid loss: 0.0295 acc: 0.6053\n",
      "\n",
      "Epoch [78/199] phase: validC train loss: -0.0015 acc: 0.9619 valid loss: 0.0238 acc: 0.6369\n",
      "\n",
      "Epoch [78/199] phase: validC train loss: -0.0036 acc: 0.9628 valid loss: 0.0283 acc: 0.6201\n",
      "\n",
      "Epoch [79/199] phase: validA train loss: 0.0018 acc: 0.9569 valid loss: 0.1748 acc: 0.2795\n",
      "\n",
      "Epoch [79/199] phase: validB train loss: 0.0060 acc: 0.8411 valid loss: 0.1522 acc: 0.2421\n",
      "\n",
      "Epoch [79/199] phase: validC train loss: 0.0014 acc: 0.9706 valid loss: 0.0259 acc: 0.6304\n",
      "\n",
      "Epoch [79/199] phase: validC train loss: -0.0014 acc: 0.9632 valid loss: 0.0251 acc: 0.6469\n",
      "\n",
      "Epoch [79/199] phase: validC train loss: -0.0036 acc: 0.9644 valid loss: 0.0259 acc: 0.6293\n",
      "\n",
      "Epoch [80/199] phase: validA train loss: 0.0018 acc: 0.9575 valid loss: 0.1687 acc: 0.2793\n",
      "\n",
      "Epoch [80/199] phase: validB train loss: 0.0062 acc: 0.8386 valid loss: 0.1508 acc: 0.2424\n",
      "\n",
      "Epoch [80/199] phase: validC train loss: 0.0015 acc: 0.9695 valid loss: 0.0258 acc: 0.6258\n",
      "\n",
      "Epoch [80/199] phase: validC train loss: -0.0015 acc: 0.9633 valid loss: 0.0231 acc: 0.6582\n",
      "\n",
      "Epoch [80/199] phase: validC train loss: -0.0037 acc: 0.9637 valid loss: 0.0240 acc: 0.6509\n",
      "\n",
      "Epoch [81/199] phase: validA train loss: 0.0018 acc: 0.9566 valid loss: 0.1732 acc: 0.2794\n",
      "\n",
      "Epoch [81/199] phase: validB train loss: 0.0061 acc: 0.8402 valid loss: 0.1526 acc: 0.2431\n",
      "\n",
      "Epoch [81/199] phase: validC train loss: 0.0014 acc: 0.9713 valid loss: 0.0244 acc: 0.6512\n",
      "\n",
      "Epoch [81/199] phase: validC train loss: -0.0014 acc: 0.9608 valid loss: 0.0232 acc: 0.6529\n",
      "\n",
      "Epoch [81/199] phase: validC train loss: -0.0037 acc: 0.9664 valid loss: 0.0261 acc: 0.6309\n",
      "\n",
      "Epoch [82/199] phase: validA train loss: 0.0019 acc: 0.9554 valid loss: 0.1743 acc: 0.2791\n",
      "\n",
      "Epoch [82/199] phase: validB train loss: 0.0060 acc: 0.8407 valid loss: 0.1527 acc: 0.2434\n",
      "\n",
      "Epoch [82/199] phase: validC train loss: 0.0015 acc: 0.9678 valid loss: 0.0264 acc: 0.6274\n",
      "\n",
      "Epoch [82/199] phase: validC train loss: -0.0014 acc: 0.9627 valid loss: 0.0223 acc: 0.6518\n",
      "\n",
      "Epoch [82/199] phase: validC train loss: -0.0036 acc: 0.9670 valid loss: 0.0252 acc: 0.6449\n",
      "\n",
      "Epoch [83/199] phase: validA train loss: 0.0018 acc: 0.9567 valid loss: 0.1737 acc: 0.2798\n",
      "\n",
      "Epoch [83/199] phase: validB train loss: 0.0060 acc: 0.8436 valid loss: 0.1509 acc: 0.2427\n",
      "\n",
      "Epoch [83/199] phase: validC train loss: 0.0012 acc: 0.9736 valid loss: 0.0255 acc: 0.6447\n",
      "\n",
      "Epoch [83/199] phase: validC train loss: -0.0015 acc: 0.9627 valid loss: 0.0246 acc: 0.6370\n",
      "\n",
      "Epoch [83/199] phase: validC train loss: -0.0037 acc: 0.9656 valid loss: 0.0268 acc: 0.6276\n",
      "\n",
      "Epoch [84/199] phase: validA train loss: 0.0019 acc: 0.9554 valid loss: 0.1700 acc: 0.2794\n",
      "\n",
      "Epoch [84/199] phase: validB train loss: 0.0060 acc: 0.8423 valid loss: 0.1509 acc: 0.2427\n",
      "\n",
      "Epoch [84/199] phase: validC train loss: 0.0014 acc: 0.9704 valid loss: 0.0247 acc: 0.6479\n",
      "\n",
      "Epoch [84/199] phase: validC train loss: -0.0014 acc: 0.9623 valid loss: 0.0241 acc: 0.6469\n",
      "\n",
      "Epoch [84/199] phase: validC train loss: -0.0036 acc: 0.9656 valid loss: 0.0260 acc: 0.6406\n",
      "\n",
      "Epoch [85/199] phase: validA train loss: 0.0018 acc: 0.9567 valid loss: 0.1726 acc: 0.2790\n",
      "\n",
      "Epoch [85/199] phase: validB train loss: 0.0061 acc: 0.8392 valid loss: 0.1476 acc: 0.2430\n",
      "\n",
      "Epoch [85/199] phase: validC train loss: 0.0014 acc: 0.9728 valid loss: 0.0268 acc: 0.6337\n",
      "\n",
      "Epoch [85/199] phase: validC train loss: -0.0015 acc: 0.9667 valid loss: 0.0282 acc: 0.6105\n",
      "\n",
      "Epoch [85/199] phase: validC train loss: -0.0037 acc: 0.9637 valid loss: 0.0269 acc: 0.6218\n",
      "\n",
      "Epoch [86/199] phase: validA train loss: 0.0018 acc: 0.9560 valid loss: 0.1741 acc: 0.2795\n",
      "\n",
      "Epoch [86/199] phase: validB train loss: 0.0060 acc: 0.8427 valid loss: 0.1517 acc: 0.2431\n",
      "\n",
      "Epoch [86/199] phase: validC train loss: 0.0014 acc: 0.9723 valid loss: 0.0251 acc: 0.6371\n",
      "\n",
      "Epoch [86/199] phase: validC train loss: -0.0015 acc: 0.9631 valid loss: 0.0251 acc: 0.6391\n",
      "\n",
      "Epoch [86/199] phase: validC train loss: -0.0036 acc: 0.9654 valid loss: 0.0288 acc: 0.6149\n",
      "\n",
      "Epoch [87/199] phase: validA train loss: 0.0018 acc: 0.9561 valid loss: 0.1783 acc: 0.2790\n",
      "\n",
      "Epoch [87/199] phase: validB train loss: 0.0060 acc: 0.8371 valid loss: 0.1515 acc: 0.2431\n",
      "\n",
      "Epoch [87/199] phase: validC train loss: 0.0013 acc: 0.9732 valid loss: 0.0252 acc: 0.6423\n",
      "\n",
      "Epoch [87/199] phase: validC train loss: -0.0015 acc: 0.9666 valid loss: 0.0239 acc: 0.6578\n",
      "\n",
      "Epoch [87/199] phase: validC train loss: -0.0038 acc: 0.9697 valid loss: 0.0260 acc: 0.6454\n",
      "\n",
      "Epoch [88/199] phase: validA train loss: 0.0018 acc: 0.9563 valid loss: 0.1729 acc: 0.2792\n",
      "\n",
      "Epoch [88/199] phase: validB train loss: 0.0060 acc: 0.8405 valid loss: 0.1503 acc: 0.2431\n",
      "\n",
      "Epoch [88/199] phase: validC train loss: 0.0014 acc: 0.9722 valid loss: 0.0242 acc: 0.6573\n",
      "\n",
      "Epoch [88/199] phase: validC train loss: -0.0015 acc: 0.9651 valid loss: 0.0237 acc: 0.6515\n",
      "\n",
      "Epoch [88/199] phase: validC train loss: -0.0037 acc: 0.9665 valid loss: 0.0264 acc: 0.6289\n",
      "\n",
      "Epoch [89/199] phase: validA train loss: 0.0018 acc: 0.9580 valid loss: 0.1728 acc: 0.2790\n",
      "\n",
      "Epoch [89/199] phase: validB train loss: 0.0060 acc: 0.8414 valid loss: 0.1509 acc: 0.2421\n",
      "\n",
      "Epoch [89/199] phase: validC train loss: 0.0014 acc: 0.9716 valid loss: 0.0250 acc: 0.6414\n",
      "\n",
      "Epoch [89/199] phase: validC train loss: -0.0015 acc: 0.9658 valid loss: 0.0276 acc: 0.6206\n",
      "\n",
      "Epoch [89/199] phase: validC train loss: -0.0038 acc: 0.9678 valid loss: 0.0263 acc: 0.6291\n",
      "\n",
      "Epoch [90/199] phase: validA train loss: 0.0018 acc: 0.9550 valid loss: 0.1681 acc: 0.2787\n",
      "\n",
      "Epoch [90/199] phase: validB train loss: 0.0060 acc: 0.8403 valid loss: 0.1514 acc: 0.2422\n",
      "\n",
      "Epoch [90/199] phase: validC train loss: 0.0019 acc: 0.9606 valid loss: 0.0247 acc: 0.6434\n",
      "\n",
      "Epoch [90/199] phase: validC train loss: -0.0015 acc: 0.9641 valid loss: 0.0227 acc: 0.6493\n",
      "\n",
      "Epoch [90/199] phase: validC train loss: -0.0037 acc: 0.9684 valid loss: 0.0294 acc: 0.6152\n",
      "\n",
      "Epoch [91/199] phase: validA train loss: 0.0018 acc: 0.9562 valid loss: 0.1748 acc: 0.2791\n",
      "\n",
      "Epoch [91/199] phase: validB train loss: 0.0061 acc: 0.8381 valid loss: 0.1523 acc: 0.2430\n",
      "\n",
      "Epoch [91/199] phase: validC train loss: 0.0013 acc: 0.9716 valid loss: 0.0275 acc: 0.6312\n",
      "\n",
      "Epoch [91/199] phase: validC train loss: -0.0014 acc: 0.9635 valid loss: 0.0223 acc: 0.6678\n",
      "\n",
      "Epoch [91/199] phase: validC train loss: -0.0036 acc: 0.9677 valid loss: 0.0254 acc: 0.6458\n",
      "\n",
      "Epoch [92/199] phase: validA train loss: 0.0018 acc: 0.9559 valid loss: 0.1794 acc: 0.2795\n",
      "\n",
      "Epoch [92/199] phase: validB train loss: 0.0061 acc: 0.8381 valid loss: 0.1495 acc: 0.2428\n",
      "\n",
      "Epoch [92/199] phase: validC train loss: 0.0014 acc: 0.9729 valid loss: 0.0241 acc: 0.6590\n",
      "\n",
      "Epoch [92/199] phase: validC train loss: -0.0015 acc: 0.9658 valid loss: 0.0262 acc: 0.6294\n",
      "\n",
      "Epoch [92/199] phase: validC train loss: -0.0037 acc: 0.9695 valid loss: 0.0292 acc: 0.6090\n",
      "\n",
      "Epoch [93/199] phase: validA train loss: 0.0018 acc: 0.9573 valid loss: 0.1790 acc: 0.2790\n",
      "\n",
      "Epoch [93/199] phase: validB train loss: 0.0060 acc: 0.8397 valid loss: 0.1510 acc: 0.2430\n",
      "\n",
      "Epoch [93/199] phase: validC train loss: 0.0014 acc: 0.9710 valid loss: 0.0280 acc: 0.6212\n",
      "\n",
      "Epoch [93/199] phase: validC train loss: -0.0015 acc: 0.9686 valid loss: 0.0230 acc: 0.6614\n",
      "\n",
      "Epoch [93/199] phase: validC train loss: -0.0037 acc: 0.9679 valid loss: 0.0274 acc: 0.6351\n",
      "\n",
      "Epoch [94/199] phase: validA train loss: 0.0018 acc: 0.9578 valid loss: 0.1739 acc: 0.2794\n",
      "\n",
      "Epoch [94/199] phase: validB train loss: 0.0060 acc: 0.8427 valid loss: 0.1541 acc: 0.2431\n",
      "\n",
      "Epoch [94/199] phase: validC train loss: 0.0011 acc: 0.9778 valid loss: 0.0270 acc: 0.6360\n",
      "\n",
      "Epoch [94/199] phase: validC train loss: -0.0015 acc: 0.9673 valid loss: 0.0257 acc: 0.6374\n",
      "\n",
      "Epoch [94/199] phase: validC train loss: -0.0038 acc: 0.9692 valid loss: 0.0242 acc: 0.6533\n",
      "\n",
      "Epoch [95/199] phase: validA train loss: 0.0018 acc: 0.9575 valid loss: 0.1722 acc: 0.2784\n",
      "\n",
      "Epoch [95/199] phase: validB train loss: 0.0060 acc: 0.8384 valid loss: 0.1497 acc: 0.2425\n",
      "\n",
      "Epoch [95/199] phase: validC train loss: 0.0013 acc: 0.9745 valid loss: 0.0244 acc: 0.6474\n",
      "\n",
      "Epoch [95/199] phase: validC train loss: -0.0015 acc: 0.9671 valid loss: 0.0242 acc: 0.6459\n",
      "\n",
      "Epoch [95/199] phase: validC train loss: -0.0037 acc: 0.9664 valid loss: 0.0296 acc: 0.6151\n",
      "\n",
      "Epoch [96/199] phase: validA train loss: 0.0018 acc: 0.9573 valid loss: 0.1739 acc: 0.2791\n",
      "\n",
      "Epoch [96/199] phase: validB train loss: 0.0060 acc: 0.8404 valid loss: 0.1526 acc: 0.2429\n",
      "\n",
      "Epoch [96/199] phase: validC train loss: 0.0014 acc: 0.9705 valid loss: 0.0270 acc: 0.6353\n",
      "\n",
      "Epoch [96/199] phase: validC train loss: -0.0015 acc: 0.9646 valid loss: 0.0261 acc: 0.6301\n",
      "\n",
      "Epoch [96/199] phase: validC train loss: -0.0037 acc: 0.9677 valid loss: 0.0252 acc: 0.6551\n",
      "\n",
      "Epoch [97/199] phase: validA train loss: 0.0018 acc: 0.9565 valid loss: 0.1790 acc: 0.2793\n",
      "\n",
      "Epoch [97/199] phase: validB train loss: 0.0061 acc: 0.8375 valid loss: 0.1525 acc: 0.2423\n",
      "\n",
      "Epoch [97/199] phase: validC train loss: 0.0011 acc: 0.9778 valid loss: 0.0246 acc: 0.6570\n",
      "\n",
      "Epoch [97/199] phase: validC train loss: -0.0015 acc: 0.9699 valid loss: 0.0238 acc: 0.6585\n",
      "\n",
      "Epoch [97/199] phase: validC train loss: -0.0037 acc: 0.9715 valid loss: 0.0239 acc: 0.6627\n",
      "\n",
      "Epoch [98/199] phase: validA train loss: 0.0019 acc: 0.9567 valid loss: 0.1726 acc: 0.2790\n",
      "\n",
      "Epoch [98/199] phase: validB train loss: 0.0060 acc: 0.8414 valid loss: 0.1533 acc: 0.2423\n",
      "\n",
      "Epoch [98/199] phase: validC train loss: 0.0010 acc: 0.9789 valid loss: 0.0252 acc: 0.6494\n",
      "\n",
      "Epoch [98/199] phase: validC train loss: -0.0016 acc: 0.9696 valid loss: 0.0279 acc: 0.6274\n",
      "\n",
      "Epoch [98/199] phase: validC train loss: -0.0038 acc: 0.9691 valid loss: 0.0255 acc: 0.6443\n",
      "\n",
      "Epoch [99/199] phase: validA train loss: 0.0018 acc: 0.9554 valid loss: 0.1754 acc: 0.2791\n",
      "\n",
      "Epoch [99/199] phase: validB train loss: 0.0060 acc: 0.8416 valid loss: 0.1500 acc: 0.2428\n",
      "\n",
      "Epoch [99/199] phase: validC train loss: 0.0012 acc: 0.9747 valid loss: 0.0251 acc: 0.6462\n",
      "\n",
      "Epoch [99/199] phase: validC train loss: -0.0016 acc: 0.9705 valid loss: 0.0222 acc: 0.6645\n",
      "\n",
      "Epoch [99/199] phase: validC train loss: -0.0038 acc: 0.9720 valid loss: 0.0242 acc: 0.6649\n",
      "\n",
      "Epoch [100/199] phase: validA train loss: 0.0018 acc: 0.9556 valid loss: 0.1759 acc: 0.2791\n",
      "\n",
      "Epoch [100/199] phase: validB train loss: 0.0061 acc: 0.8385 valid loss: 0.1516 acc: 0.2432\n",
      "\n",
      "Epoch [100/199] phase: validC train loss: 0.0012 acc: 0.9738 valid loss: 0.0258 acc: 0.6502\n",
      "\n",
      "Epoch [100/199] phase: validC train loss: -0.0015 acc: 0.9668 valid loss: 0.0258 acc: 0.6361\n",
      "\n",
      "Epoch [100/199] phase: validC train loss: -0.0037 acc: 0.9689 valid loss: 0.0300 acc: 0.6137\n",
      "\n",
      "Epoch [101/199] phase: validA train loss: 0.0018 acc: 0.9570 valid loss: 0.1702 acc: 0.2795\n",
      "\n",
      "Epoch [101/199] phase: validB train loss: 0.0060 acc: 0.8364 valid loss: 0.1512 acc: 0.2429\n",
      "\n",
      "Epoch [101/199] phase: validC train loss: 0.0013 acc: 0.9729 valid loss: 0.0289 acc: 0.6175\n",
      "\n",
      "Epoch [101/199] phase: validC train loss: -0.0016 acc: 0.9683 valid loss: 0.0256 acc: 0.6422\n",
      "\n",
      "Epoch [101/199] phase: validC train loss: -0.0038 acc: 0.9693 valid loss: 0.0250 acc: 0.6559\n",
      "\n",
      "Epoch [102/199] phase: validA train loss: 0.0018 acc: 0.9559 valid loss: 0.1702 acc: 0.2792\n",
      "\n",
      "Epoch [102/199] phase: validB train loss: 0.0060 acc: 0.8411 valid loss: 0.1487 acc: 0.2424\n",
      "\n",
      "Epoch [102/199] phase: validC train loss: 0.0015 acc: 0.9690 valid loss: 0.0246 acc: 0.6613\n",
      "\n",
      "Epoch [102/199] phase: validC train loss: -0.0016 acc: 0.9701 valid loss: 0.0232 acc: 0.6554\n",
      "\n",
      "Epoch [102/199] phase: validC train loss: -0.0038 acc: 0.9704 valid loss: 0.0328 acc: 0.5882\n",
      "\n",
      "Epoch [103/199] phase: validA train loss: 0.0018 acc: 0.9538 valid loss: 0.1786 acc: 0.2794\n",
      "\n",
      "Epoch [103/199] phase: validB train loss: 0.0061 acc: 0.8404 valid loss: 0.1495 acc: 0.2423\n",
      "\n",
      "Epoch [103/199] phase: validC train loss: 0.0013 acc: 0.9742 valid loss: 0.0303 acc: 0.6030\n",
      "\n",
      "Epoch [103/199] phase: validC train loss: -0.0015 acc: 0.9679 valid loss: 0.0249 acc: 0.6450\n",
      "\n",
      "Epoch [103/199] phase: validC train loss: -0.0037 acc: 0.9711 valid loss: 0.0280 acc: 0.6329\n",
      "\n",
      "Epoch [104/199] phase: validA train loss: 0.0018 acc: 0.9582 valid loss: 0.1698 acc: 0.2796\n",
      "\n",
      "Epoch [104/199] phase: validB train loss: 0.0060 acc: 0.8404 valid loss: 0.1539 acc: 0.2431\n",
      "\n",
      "Epoch [104/199] phase: validC train loss: 0.0010 acc: 0.9793 valid loss: 0.0278 acc: 0.6330\n",
      "\n",
      "Epoch [104/199] phase: validC train loss: -0.0016 acc: 0.9678 valid loss: 0.0237 acc: 0.6590\n",
      "\n",
      "Epoch [104/199] phase: validC train loss: -0.0039 acc: 0.9693 valid loss: 0.0261 acc: 0.6493\n",
      "\n",
      "Epoch [105/199] phase: validA train loss: 0.0018 acc: 0.9560 valid loss: 0.1666 acc: 0.2790\n",
      "\n",
      "Epoch [105/199] phase: validB train loss: 0.0061 acc: 0.8387 valid loss: 0.1482 acc: 0.2432\n",
      "\n",
      "Epoch [105/199] phase: validC train loss: 0.0012 acc: 0.9747 valid loss: 0.0261 acc: 0.6452\n",
      "\n",
      "Epoch [105/199] phase: validC train loss: -0.0017 acc: 0.9704 valid loss: 0.0287 acc: 0.6222\n",
      "\n",
      "Epoch [105/199] phase: validC train loss: -0.0039 acc: 0.9720 valid loss: 0.0280 acc: 0.6359\n",
      "\n",
      "Epoch [106/199] phase: validA train loss: 0.0018 acc: 0.9566 valid loss: 0.1709 acc: 0.2787\n",
      "\n",
      "Epoch [106/199] phase: validB train loss: 0.0060 acc: 0.8421 valid loss: 0.1539 acc: 0.2425\n",
      "\n",
      "Epoch [106/199] phase: validC train loss: 0.0013 acc: 0.9719 valid loss: 0.0285 acc: 0.6264\n",
      "\n",
      "Epoch [106/199] phase: validC train loss: -0.0016 acc: 0.9680 valid loss: 0.0299 acc: 0.6047\n",
      "\n",
      "Epoch [106/199] phase: validC train loss: -0.0037 acc: 0.9712 valid loss: 0.0281 acc: 0.6333\n",
      "\n",
      "Epoch [107/199] phase: validA train loss: 0.0018 acc: 0.9561 valid loss: 0.1762 acc: 0.2793\n",
      "\n",
      "Epoch [107/199] phase: validB train loss: 0.0060 acc: 0.8432 valid loss: 0.1517 acc: 0.2425\n",
      "\n",
      "Epoch [107/199] phase: validC train loss: 0.0013 acc: 0.9745 valid loss: 0.0272 acc: 0.6425\n",
      "\n",
      "Epoch [107/199] phase: validC train loss: -0.0016 acc: 0.9710 valid loss: 0.0261 acc: 0.6499\n",
      "\n",
      "Epoch [107/199] phase: validC train loss: -0.0038 acc: 0.9702 valid loss: 0.0277 acc: 0.6125\n",
      "\n",
      "Epoch [108/199] phase: validA train loss: 0.0018 acc: 0.9554 valid loss: 0.1722 acc: 0.2791\n",
      "\n",
      "Epoch [108/199] phase: validB train loss: 0.0060 acc: 0.8418 valid loss: 0.1505 acc: 0.2432\n",
      "\n",
      "Epoch [108/199] phase: validC train loss: 0.0016 acc: 0.9658 valid loss: 0.0253 acc: 0.6399\n",
      "\n",
      "Epoch [108/199] phase: validC train loss: -0.0015 acc: 0.9691 valid loss: 0.0264 acc: 0.6125\n",
      "\n",
      "Epoch [108/199] phase: validC train loss: -0.0038 acc: 0.9716 valid loss: 0.0266 acc: 0.6403\n",
      "\n",
      "Epoch [109/199] phase: validA train loss: 0.0018 acc: 0.9594 valid loss: 0.1728 acc: 0.2796\n",
      "\n",
      "Epoch [109/199] phase: validB train loss: 0.0061 acc: 0.8376 valid loss: 0.1540 acc: 0.2425\n",
      "\n",
      "Epoch [109/199] phase: validC train loss: 0.0012 acc: 0.9745 valid loss: 0.0264 acc: 0.6440\n",
      "\n",
      "Epoch [109/199] phase: validC train loss: -0.0017 acc: 0.9730 valid loss: 0.0265 acc: 0.6343\n",
      "\n",
      "Epoch [109/199] phase: validC train loss: -0.0037 acc: 0.9709 valid loss: 0.0251 acc: 0.6595\n",
      "\n",
      "Epoch [110/199] phase: validA train loss: 0.0018 acc: 0.9563 valid loss: 0.1745 acc: 0.2789\n",
      "\n",
      "Epoch [110/199] phase: validB train loss: 0.0061 acc: 0.8382 valid loss: 0.1534 acc: 0.2429\n",
      "\n",
      "Epoch [110/199] phase: validC train loss: 0.0012 acc: 0.9752 valid loss: 0.0239 acc: 0.6659\n",
      "\n",
      "Epoch [110/199] phase: validC train loss: -0.0016 acc: 0.9710 valid loss: 0.0273 acc: 0.6250\n",
      "\n",
      "Epoch [110/199] phase: validC train loss: -0.0037 acc: 0.9701 valid loss: 0.0239 acc: 0.6567\n",
      "\n",
      "Epoch [111/199] phase: validA train loss: 0.0018 acc: 0.9566 valid loss: 0.1690 acc: 0.2788\n",
      "\n",
      "Epoch [111/199] phase: validB train loss: 0.0061 acc: 0.8386 valid loss: 0.1482 acc: 0.2423\n",
      "\n",
      "Epoch [111/199] phase: validC train loss: 0.0012 acc: 0.9746 valid loss: 0.0243 acc: 0.6568\n",
      "\n",
      "Epoch [111/199] phase: validC train loss: -0.0017 acc: 0.9720 valid loss: 0.0236 acc: 0.6632\n",
      "\n",
      "Epoch [111/199] phase: validC train loss: -0.0038 acc: 0.9718 valid loss: 0.0286 acc: 0.6174\n",
      "\n",
      "Epoch [112/199] phase: validA train loss: 0.0018 acc: 0.9573 valid loss: 0.1739 acc: 0.2792\n",
      "\n",
      "Epoch [112/199] phase: validB train loss: 0.0061 acc: 0.8424 valid loss: 0.1515 acc: 0.2423\n",
      "\n",
      "Epoch [112/199] phase: validC train loss: 0.0012 acc: 0.9753 valid loss: 0.0275 acc: 0.6298\n",
      "\n",
      "Epoch [112/199] phase: validC train loss: -0.0017 acc: 0.9719 valid loss: 0.0244 acc: 0.6494\n",
      "\n",
      "Epoch [112/199] phase: validC train loss: -0.0038 acc: 0.9739 valid loss: 0.0252 acc: 0.6610\n",
      "\n",
      "Epoch [113/199] phase: validA train loss: 0.0018 acc: 0.9590 valid loss: 0.1741 acc: 0.2790\n",
      "\n",
      "Epoch [113/199] phase: validB train loss: 0.0060 acc: 0.8431 valid loss: 0.1500 acc: 0.2424\n",
      "\n",
      "Epoch [113/199] phase: validC train loss: 0.0012 acc: 0.9750 valid loss: 0.0262 acc: 0.6554\n",
      "\n",
      "Epoch [113/199] phase: validC train loss: -0.0016 acc: 0.9702 valid loss: 0.0265 acc: 0.6305\n",
      "\n",
      "Epoch [113/199] phase: validC train loss: -0.0038 acc: 0.9744 valid loss: 0.0268 acc: 0.6496\n",
      "\n",
      "Epoch [114/199] phase: validA train loss: 0.0019 acc: 0.9558 valid loss: 0.1779 acc: 0.2790\n",
      "\n",
      "Epoch [114/199] phase: validB train loss: 0.0061 acc: 0.8399 valid loss: 0.1494 acc: 0.2430\n",
      "\n",
      "Epoch [114/199] phase: validC train loss: 0.0012 acc: 0.9742 valid loss: 0.0254 acc: 0.6634\n",
      "\n",
      "Epoch [114/199] phase: validC train loss: -0.0016 acc: 0.9703 valid loss: 0.0229 acc: 0.6677\n",
      "\n",
      "Epoch [114/199] phase: validC train loss: -0.0039 acc: 0.9727 valid loss: 0.0274 acc: 0.6434\n",
      "\n",
      "Epoch [115/199] phase: validA train loss: 0.0017 acc: 0.9569 valid loss: 0.1719 acc: 0.2790\n",
      "\n",
      "Epoch [115/199] phase: validB train loss: 0.0061 acc: 0.8378 valid loss: 0.1499 acc: 0.2431\n",
      "\n",
      "Epoch [115/199] phase: validC train loss: 0.0012 acc: 0.9763 valid loss: 0.0286 acc: 0.6331\n",
      "\n",
      "Epoch [115/199] phase: validC train loss: -0.0017 acc: 0.9704 valid loss: 0.0260 acc: 0.6379\n",
      "\n",
      "Epoch [115/199] phase: validC train loss: -0.0038 acc: 0.9728 valid loss: 0.0237 acc: 0.6730\n",
      "\n",
      "Epoch [116/199] phase: validA train loss: 0.0018 acc: 0.9566 valid loss: 0.1726 acc: 0.2795\n",
      "\n",
      "Epoch [116/199] phase: validB train loss: 0.0061 acc: 0.8395 valid loss: 0.1510 acc: 0.2432\n",
      "\n",
      "Epoch [116/199] phase: validC train loss: 0.0011 acc: 0.9773 valid loss: 0.0250 acc: 0.6584\n",
      "\n",
      "Epoch [116/199] phase: validC train loss: -0.0017 acc: 0.9716 valid loss: 0.0253 acc: 0.6623\n",
      "\n",
      "Epoch [116/199] phase: validC train loss: -0.0038 acc: 0.9713 valid loss: 0.0247 acc: 0.6617\n",
      "\n",
      "Epoch [117/199] phase: validA train loss: 0.0018 acc: 0.9570 valid loss: 0.1745 acc: 0.2790\n",
      "\n",
      "Epoch [117/199] phase: validB train loss: 0.0060 acc: 0.8391 valid loss: 0.1535 acc: 0.2431\n",
      "\n",
      "Epoch [117/199] phase: validC train loss: 0.0009 acc: 0.9813 valid loss: 0.0247 acc: 0.6588\n",
      "\n",
      "Epoch [117/199] phase: validC train loss: -0.0017 acc: 0.9713 valid loss: 0.0279 acc: 0.6292\n",
      "\n",
      "Epoch [117/199] phase: validC train loss: -0.0039 acc: 0.9730 valid loss: 0.0258 acc: 0.6554\n",
      "\n",
      "Epoch [118/199] phase: validA train loss: 0.0019 acc: 0.9554 valid loss: 0.1748 acc: 0.2788\n",
      "\n",
      "Epoch [118/199] phase: validB train loss: 0.0060 acc: 0.8432 valid loss: 0.1509 acc: 0.2426\n",
      "\n",
      "Epoch [118/199] phase: validC train loss: 0.0012 acc: 0.9755 valid loss: 0.0251 acc: 0.6576\n",
      "\n",
      "Epoch [118/199] phase: validC train loss: -0.0016 acc: 0.9701 valid loss: 0.0227 acc: 0.6664\n",
      "\n",
      "Epoch [118/199] phase: validC train loss: -0.0039 acc: 0.9740 valid loss: 0.0278 acc: 0.6395\n",
      "\n",
      "Epoch [119/199] phase: validA train loss: 0.0018 acc: 0.9553 valid loss: 0.1752 acc: 0.2791\n",
      "\n",
      "Epoch [119/199] phase: validB train loss: 0.0060 acc: 0.8417 valid loss: 0.1532 acc: 0.2427\n",
      "\n",
      "Epoch [119/199] phase: validC train loss: 0.0010 acc: 0.9786 valid loss: 0.0270 acc: 0.6438\n",
      "\n",
      "Epoch [119/199] phase: validC train loss: -0.0016 acc: 0.9715 valid loss: 0.0274 acc: 0.6458\n",
      "\n",
      "Epoch [119/199] phase: validC train loss: -0.0038 acc: 0.9744 valid loss: 0.0277 acc: 0.6323\n",
      "\n",
      "Epoch [120/199] phase: validA train loss: 0.0017 acc: 0.9579 valid loss: 0.1735 acc: 0.2791\n",
      "\n",
      "Epoch [120/199] phase: validB train loss: 0.0061 acc: 0.8392 valid loss: 0.1528 acc: 0.2426\n",
      "\n",
      "Epoch [120/199] phase: validC train loss: 0.0010 acc: 0.9795 valid loss: 0.0273 acc: 0.6332\n",
      "\n",
      "Epoch [120/199] phase: validC train loss: -0.0017 acc: 0.9721 valid loss: 0.0286 acc: 0.6283\n",
      "\n",
      "Epoch [120/199] phase: validC train loss: -0.0038 acc: 0.9732 valid loss: 0.0251 acc: 0.6502\n",
      "\n",
      "Epoch [121/199] phase: validA train loss: 0.0018 acc: 0.9566 valid loss: 0.1769 acc: 0.2789\n",
      "\n",
      "Epoch [121/199] phase: validB train loss: 0.0060 acc: 0.8429 valid loss: 0.1526 acc: 0.2425\n",
      "\n",
      "Epoch [121/199] phase: validC train loss: 0.0010 acc: 0.9797 valid loss: 0.0246 acc: 0.6541\n",
      "\n",
      "Epoch [121/199] phase: validC train loss: -0.0016 acc: 0.9709 valid loss: 0.0233 acc: 0.6650\n",
      "\n",
      "Epoch [121/199] phase: validC train loss: -0.0038 acc: 0.9716 valid loss: 0.0252 acc: 0.6490\n",
      "\n",
      "Epoch [122/199] phase: validA train loss: 0.0018 acc: 0.9563 valid loss: 0.1691 acc: 0.2788\n",
      "\n",
      "Epoch [122/199] phase: validB train loss: 0.0061 acc: 0.8396 valid loss: 0.1488 acc: 0.2428\n",
      "\n",
      "Epoch [122/199] phase: validC train loss: 0.0009 acc: 0.9819 valid loss: 0.0252 acc: 0.6455\n",
      "\n",
      "Epoch [122/199] phase: validC train loss: -0.0017 acc: 0.9699 valid loss: 0.0317 acc: 0.6048\n",
      "\n",
      "Epoch [122/199] phase: validC train loss: -0.0039 acc: 0.9747 valid loss: 0.0278 acc: 0.6324\n",
      "\n",
      "Epoch [123/199] phase: validA train loss: 0.0018 acc: 0.9548 valid loss: 0.1736 acc: 0.2791\n",
      "\n",
      "Epoch [123/199] phase: validB train loss: 0.0061 acc: 0.8430 valid loss: 0.1516 acc: 0.2427\n",
      "\n",
      "Epoch [123/199] phase: validC train loss: 0.0011 acc: 0.9780 valid loss: 0.0275 acc: 0.6348\n",
      "\n",
      "Epoch [123/199] phase: validC train loss: -0.0017 acc: 0.9751 valid loss: 0.0254 acc: 0.6441\n",
      "\n",
      "Epoch [123/199] phase: validC train loss: -0.0038 acc: 0.9724 valid loss: 0.0265 acc: 0.6568\n",
      "\n",
      "Epoch [124/199] phase: validA train loss: 0.0018 acc: 0.9570 valid loss: 0.1694 acc: 0.2789\n",
      "\n",
      "Epoch [124/199] phase: validB train loss: 0.0060 acc: 0.8390 valid loss: 0.1539 acc: 0.2427\n",
      "\n",
      "Epoch [124/199] phase: validC train loss: 0.0010 acc: 0.9791 valid loss: 0.0252 acc: 0.6600\n",
      "\n",
      "Epoch [124/199] phase: validC train loss: -0.0017 acc: 0.9707 valid loss: 0.0282 acc: 0.6245\n",
      "\n",
      "Epoch [124/199] phase: validC train loss: -0.0038 acc: 0.9747 valid loss: 0.0253 acc: 0.6534\n",
      "\n",
      "Epoch [125/199] phase: validA train loss: 0.0018 acc: 0.9557 valid loss: 0.1743 acc: 0.2789\n",
      "\n",
      "Epoch [125/199] phase: validB train loss: 0.0061 acc: 0.8388 valid loss: 0.1511 acc: 0.2422\n",
      "\n",
      "Epoch [125/199] phase: validC train loss: 0.0011 acc: 0.9779 valid loss: 0.0247 acc: 0.6586\n",
      "\n",
      "Epoch [125/199] phase: validC train loss: -0.0017 acc: 0.9730 valid loss: 0.0255 acc: 0.6374\n",
      "\n",
      "Epoch [125/199] phase: validC train loss: -0.0039 acc: 0.9763 valid loss: 0.0261 acc: 0.6463\n",
      "\n",
      "Epoch [126/199] phase: validA train loss: 0.0018 acc: 0.9559 valid loss: 0.1749 acc: 0.2799\n",
      "\n",
      "Epoch [126/199] phase: validB train loss: 0.0061 acc: 0.8396 valid loss: 0.1506 acc: 0.2427\n",
      "\n",
      "Epoch [126/199] phase: validC train loss: 0.0011 acc: 0.9770 valid loss: 0.0264 acc: 0.6492\n",
      "\n",
      "Epoch [126/199] phase: validC train loss: -0.0016 acc: 0.9718 valid loss: 0.0293 acc: 0.6169\n",
      "\n",
      "Epoch [126/199] phase: validC train loss: -0.0039 acc: 0.9754 valid loss: 0.0274 acc: 0.6481\n",
      "\n",
      "Epoch [127/199] phase: validA train loss: 0.0019 acc: 0.9549 valid loss: 0.1780 acc: 0.2790\n",
      "\n",
      "Epoch [127/199] phase: validB train loss: 0.0061 acc: 0.8388 valid loss: 0.1521 acc: 0.2428\n",
      "\n",
      "Epoch [127/199] phase: validC train loss: 0.0010 acc: 0.9788 valid loss: 0.0266 acc: 0.6492\n",
      "\n",
      "Epoch [127/199] phase: validC train loss: -0.0016 acc: 0.9718 valid loss: 0.0241 acc: 0.6611\n",
      "\n",
      "Epoch [127/199] phase: validC train loss: -0.0039 acc: 0.9747 valid loss: 0.0243 acc: 0.6670\n",
      "\n",
      "Epoch [128/199] phase: validA train loss: 0.0018 acc: 0.9563 valid loss: 0.1757 acc: 0.2790\n",
      "\n",
      "Epoch [128/199] phase: validB train loss: 0.0061 acc: 0.8385 valid loss: 0.1490 acc: 0.2424\n",
      "\n",
      "Epoch [128/199] phase: validC train loss: 0.0009 acc: 0.9815 valid loss: 0.0248 acc: 0.6600\n",
      "\n",
      "Epoch [128/199] phase: validC train loss: -0.0016 acc: 0.9710 valid loss: 0.0277 acc: 0.6301\n",
      "\n",
      "Epoch [128/199] phase: validC train loss: -0.0038 acc: 0.9725 valid loss: 0.0268 acc: 0.6544\n",
      "\n",
      "Epoch [129/199] phase: validA train loss: 0.0018 acc: 0.9559 valid loss: 0.1726 acc: 0.2797\n",
      "\n",
      "Epoch [129/199] phase: validB train loss: 0.0060 acc: 0.8405 valid loss: 0.1494 acc: 0.2424\n",
      "\n",
      "Epoch [129/199] phase: validC train loss: 0.0010 acc: 0.9799 valid loss: 0.0257 acc: 0.6623\n",
      "\n",
      "Epoch [129/199] phase: validC train loss: -0.0017 acc: 0.9745 valid loss: 0.0274 acc: 0.6353\n",
      "\n",
      "Epoch [129/199] phase: validC train loss: -0.0039 acc: 0.9754 valid loss: 0.0281 acc: 0.6427\n",
      "\n",
      "Epoch [130/199] phase: validA train loss: 0.0019 acc: 0.9549 valid loss: 0.1753 acc: 0.2796\n",
      "\n",
      "Epoch [130/199] phase: validB train loss: 0.0061 acc: 0.8358 valid loss: 0.1555 acc: 0.2425\n",
      "\n",
      "Epoch [130/199] phase: validC train loss: 0.0010 acc: 0.9801 valid loss: 0.0270 acc: 0.6516\n",
      "\n",
      "Epoch [130/199] phase: validC train loss: -0.0017 acc: 0.9740 valid loss: 0.0271 acc: 0.6379\n",
      "\n",
      "Epoch [130/199] phase: validC train loss: -0.0039 acc: 0.9744 valid loss: 0.0256 acc: 0.6626\n",
      "\n",
      "Epoch [131/199] phase: validA train loss: 0.0019 acc: 0.9545 valid loss: 0.1706 acc: 0.2793\n",
      "\n",
      "Epoch [131/199] phase: validB train loss: 0.0061 acc: 0.8356 valid loss: 0.1500 acc: 0.2427\n",
      "\n",
      "Epoch [131/199] phase: validC train loss: 0.0013 acc: 0.9745 valid loss: 0.0275 acc: 0.6436\n",
      "\n",
      "Epoch [131/199] phase: validC train loss: -0.0017 acc: 0.9721 valid loss: 0.0249 acc: 0.6580\n",
      "\n",
      "Epoch [131/199] phase: validC train loss: -0.0039 acc: 0.9761 valid loss: 0.0266 acc: 0.6532\n",
      "\n",
      "Epoch [132/199] phase: validA train loss: 0.0018 acc: 0.9575 valid loss: 0.1795 acc: 0.2790\n",
      "\n",
      "Epoch [132/199] phase: validB train loss: 0.0060 acc: 0.8455 valid loss: 0.1476 acc: 0.2423\n",
      "\n",
      "Epoch [132/199] phase: validC train loss: 0.0011 acc: 0.9773 valid loss: 0.0265 acc: 0.6595\n",
      "\n",
      "Epoch [132/199] phase: validC train loss: -0.0016 acc: 0.9730 valid loss: 0.0267 acc: 0.6407\n",
      "\n",
      "Epoch [132/199] phase: validC train loss: -0.0038 acc: 0.9732 valid loss: 0.0258 acc: 0.6481\n",
      "\n",
      "Epoch [133/199] phase: validA train loss: 0.0018 acc: 0.9562 valid loss: 0.1702 acc: 0.2793\n",
      "\n",
      "Epoch [133/199] phase: validB train loss: 0.0060 acc: 0.8422 valid loss: 0.1554 acc: 0.2423\n",
      "\n",
      "Epoch [133/199] phase: validC train loss: 0.0011 acc: 0.9770 valid loss: 0.0257 acc: 0.6479\n",
      "\n",
      "Epoch [133/199] phase: validC train loss: -0.0017 acc: 0.9739 valid loss: 0.0268 acc: 0.6379\n",
      "\n",
      "Epoch [133/199] phase: validC train loss: -0.0039 acc: 0.9752 valid loss: 0.0239 acc: 0.6679\n",
      "\n",
      "Epoch [134/199] phase: validA train loss: 0.0018 acc: 0.9564 valid loss: 0.1728 acc: 0.2789\n",
      "\n",
      "Epoch [134/199] phase: validB train loss: 0.0061 acc: 0.8387 valid loss: 0.1444 acc: 0.2430\n",
      "\n",
      "Epoch [134/199] phase: validC train loss: 0.0009 acc: 0.9806 valid loss: 0.0238 acc: 0.6676\n",
      "\n",
      "Epoch [134/199] phase: validC train loss: -0.0018 acc: 0.9771 valid loss: 0.0289 acc: 0.6285\n",
      "\n",
      "Epoch [134/199] phase: validC train loss: -0.0039 acc: 0.9755 valid loss: 0.0288 acc: 0.6324\n",
      "\n",
      "Epoch [135/199] phase: validA train loss: 0.0018 acc: 0.9567 valid loss: 0.1729 acc: 0.2793\n",
      "\n",
      "Epoch [135/199] phase: validB train loss: 0.0060 acc: 0.8394 valid loss: 0.1493 acc: 0.2426\n",
      "\n",
      "Epoch [135/199] phase: validC train loss: 0.0010 acc: 0.9783 valid loss: 0.0286 acc: 0.6345\n",
      "\n",
      "Epoch [135/199] phase: validC train loss: -0.0017 acc: 0.9749 valid loss: 0.0308 acc: 0.6225\n",
      "\n",
      "Epoch [135/199] phase: validC train loss: -0.0039 acc: 0.9753 valid loss: 0.0287 acc: 0.6370\n",
      "\n",
      "Epoch [136/199] phase: validA train loss: 0.0018 acc: 0.9559 valid loss: 0.1765 acc: 0.2789\n",
      "\n",
      "Epoch [136/199] phase: validB train loss: 0.0060 acc: 0.8366 valid loss: 0.1520 acc: 0.2427\n",
      "\n",
      "Epoch [136/199] phase: validC train loss: 0.0014 acc: 0.9713 valid loss: 0.0283 acc: 0.6385\n",
      "\n",
      "Epoch [136/199] phase: validC train loss: -0.0017 acc: 0.9738 valid loss: 0.0231 acc: 0.6680\n",
      "\n",
      "Epoch [136/199] phase: validC train loss: -0.0038 acc: 0.9751 valid loss: 0.0250 acc: 0.6561\n",
      "\n",
      "Epoch [137/199] phase: validA train loss: 0.0018 acc: 0.9556 valid loss: 0.1701 acc: 0.2794\n",
      "\n",
      "Epoch [137/199] phase: validB train loss: 0.0060 acc: 0.8413 valid loss: 0.1529 acc: 0.2427\n",
      "\n",
      "Epoch [137/199] phase: validC train loss: 0.0012 acc: 0.9762 valid loss: 0.0247 acc: 0.6589\n",
      "\n",
      "Epoch [137/199] phase: validC train loss: -0.0017 acc: 0.9723 valid loss: 0.0253 acc: 0.6545\n",
      "\n",
      "Epoch [137/199] phase: validC train loss: -0.0039 acc: 0.9755 valid loss: 0.0272 acc: 0.6426\n",
      "\n",
      "Epoch [138/199] phase: validA train loss: 0.0018 acc: 0.9552 valid loss: 0.1734 acc: 0.2786\n",
      "\n",
      "Epoch [138/199] phase: validB train loss: 0.0061 acc: 0.8388 valid loss: 0.1494 acc: 0.2426\n",
      "\n",
      "Epoch [138/199] phase: validC train loss: 0.0010 acc: 0.9798 valid loss: 0.0265 acc: 0.6458\n",
      "\n",
      "Epoch [138/199] phase: validC train loss: -0.0018 acc: 0.9736 valid loss: 0.0239 acc: 0.6695\n",
      "\n",
      "Epoch [138/199] phase: validC train loss: -0.0039 acc: 0.9746 valid loss: 0.0279 acc: 0.6364\n",
      "\n",
      "Epoch [139/199] phase: validA train loss: 0.0018 acc: 0.9574 valid loss: 0.1767 acc: 0.2792\n",
      "\n",
      "Epoch [139/199] phase: validB train loss: 0.0061 acc: 0.8369 valid loss: 0.1518 acc: 0.2421\n",
      "\n",
      "Epoch [139/199] phase: validC train loss: 0.0010 acc: 0.9804 valid loss: 0.0259 acc: 0.6525\n",
      "\n",
      "Epoch [139/199] phase: validC train loss: -0.0017 acc: 0.9746 valid loss: 0.0235 acc: 0.6735\n",
      "\n",
      "Epoch [139/199] phase: validC train loss: -0.0039 acc: 0.9758 valid loss: 0.0302 acc: 0.6306\n",
      "\n",
      "Epoch [140/199] phase: validA train loss: 0.0018 acc: 0.9574 valid loss: 0.1766 acc: 0.2791\n",
      "\n",
      "Epoch [140/199] phase: validB train loss: 0.0060 acc: 0.8401 valid loss: 0.1486 acc: 0.2426\n",
      "\n",
      "Epoch [140/199] phase: validC train loss: 0.0010 acc: 0.9794 valid loss: 0.0301 acc: 0.6269\n",
      "\n",
      "Epoch [140/199] phase: validC train loss: -0.0017 acc: 0.9755 valid loss: 0.0247 acc: 0.6495\n",
      "\n",
      "Epoch [140/199] phase: validC train loss: -0.0040 acc: 0.9768 valid loss: 0.0276 acc: 0.6467\n",
      "\n",
      "Epoch [141/199] phase: validA train loss: 0.0018 acc: 0.9561 valid loss: 0.1736 acc: 0.2786\n",
      "\n",
      "Epoch [141/199] phase: validB train loss: 0.0061 acc: 0.8378 valid loss: 0.1519 acc: 0.2427\n",
      "\n",
      "Epoch [141/199] phase: validC train loss: 0.0011 acc: 0.9778 valid loss: 0.0271 acc: 0.6465\n",
      "\n",
      "Epoch [141/199] phase: validC train loss: -0.0017 acc: 0.9744 valid loss: 0.0267 acc: 0.6417\n",
      "\n",
      "Epoch [141/199] phase: validC train loss: -0.0039 acc: 0.9766 valid loss: 0.0290 acc: 0.6253\n",
      "\n",
      "Epoch [142/199] phase: validA train loss: 0.0018 acc: 0.9556 valid loss: 0.1737 acc: 0.2791\n",
      "\n",
      "Epoch [142/199] phase: validB train loss: 0.0061 acc: 0.8351 valid loss: 0.1529 acc: 0.2421\n",
      "\n",
      "Epoch [142/199] phase: validC train loss: 0.0012 acc: 0.9748 valid loss: 0.0293 acc: 0.6207\n",
      "\n",
      "Epoch [142/199] phase: validC train loss: -0.0017 acc: 0.9739 valid loss: 0.0252 acc: 0.6488\n",
      "\n",
      "Epoch [142/199] phase: validC train loss: -0.0039 acc: 0.9773 valid loss: 0.0265 acc: 0.6635\n",
      "\n",
      "Epoch [143/199] phase: validA train loss: 0.0019 acc: 0.9554 valid loss: 0.1766 acc: 0.2791\n",
      "\n",
      "Epoch [143/199] phase: validB train loss: 0.0061 acc: 0.8403 valid loss: 0.1526 acc: 0.2426\n",
      "\n",
      "Epoch [143/199] phase: validC train loss: 0.0013 acc: 0.9741 valid loss: 0.0249 acc: 0.6756\n",
      "\n",
      "Epoch [143/199] phase: validC train loss: -0.0017 acc: 0.9735 valid loss: 0.0273 acc: 0.6404\n",
      "\n",
      "Epoch [143/199] phase: validC train loss: -0.0039 acc: 0.9753 valid loss: 0.0290 acc: 0.6204\n",
      "\n",
      "Epoch [144/199] phase: validA train loss: 0.0018 acc: 0.9559 valid loss: 0.1742 acc: 0.2793\n",
      "\n",
      "Epoch [144/199] phase: validB train loss: 0.0062 acc: 0.8365 valid loss: 0.1494 acc: 0.2421\n",
      "\n",
      "Epoch [144/199] phase: validC train loss: 0.0012 acc: 0.9759 valid loss: 0.0268 acc: 0.6378\n",
      "\n",
      "Epoch [144/199] phase: validC train loss: -0.0017 acc: 0.9743 valid loss: 0.0254 acc: 0.6521\n",
      "\n",
      "Epoch [144/199] phase: validC train loss: -0.0039 acc: 0.9768 valid loss: 0.0276 acc: 0.6283\n",
      "\n",
      "Epoch [145/199] phase: validA train loss: 0.0018 acc: 0.9575 valid loss: 0.1736 acc: 0.2792\n",
      "\n",
      "Epoch [145/199] phase: validB train loss: 0.0061 acc: 0.8372 valid loss: 0.1492 acc: 0.2424\n",
      "\n",
      "Epoch [145/199] phase: validC train loss: 0.0009 acc: 0.9829 valid loss: 0.0283 acc: 0.6237\n",
      "\n",
      "Epoch [145/199] phase: validC train loss: -0.0017 acc: 0.9741 valid loss: 0.0260 acc: 0.6305\n",
      "\n",
      "Epoch [145/199] phase: validC train loss: -0.0040 acc: 0.9766 valid loss: 0.0270 acc: 0.6417\n",
      "\n",
      "Epoch [146/199] phase: validA train loss: 0.0018 acc: 0.9576 valid loss: 0.1755 acc: 0.2797\n",
      "\n",
      "Epoch [146/199] phase: validB train loss: 0.0060 acc: 0.8412 valid loss: 0.1537 acc: 0.2428\n",
      "\n",
      "Epoch [146/199] phase: validC train loss: 0.0011 acc: 0.9783 valid loss: 0.0259 acc: 0.6546\n",
      "\n",
      "Epoch [146/199] phase: validC train loss: -0.0017 acc: 0.9772 valid loss: 0.0283 acc: 0.6315\n",
      "\n",
      "Epoch [146/199] phase: validC train loss: -0.0039 acc: 0.9776 valid loss: 0.0291 acc: 0.6242\n",
      "\n",
      "Epoch [147/199] phase: validA train loss: 0.0018 acc: 0.9556 valid loss: 0.1777 acc: 0.2789\n",
      "\n",
      "Epoch [147/199] phase: validB train loss: 0.0061 acc: 0.8365 valid loss: 0.1536 acc: 0.2434\n",
      "\n",
      "Epoch [147/199] phase: validC train loss: 0.0009 acc: 0.9819 valid loss: 0.0277 acc: 0.6392\n",
      "\n",
      "Epoch [147/199] phase: validC train loss: -0.0016 acc: 0.9735 valid loss: 0.0281 acc: 0.6322\n",
      "\n",
      "Epoch [147/199] phase: validC train loss: -0.0039 acc: 0.9770 valid loss: 0.0243 acc: 0.6703\n",
      "\n",
      "Epoch [148/199] phase: validA train loss: 0.0019 acc: 0.9547 valid loss: 0.1793 acc: 0.2793\n",
      "\n",
      "Epoch [148/199] phase: validB train loss: 0.0060 acc: 0.8425 valid loss: 0.1544 acc: 0.2424\n",
      "\n",
      "Epoch [148/199] phase: validC train loss: 0.0013 acc: 0.9738 valid loss: 0.0234 acc: 0.6801\n",
      "\n",
      "Epoch [148/199] phase: validC train loss: -0.0017 acc: 0.9745 valid loss: 0.0236 acc: 0.6724\n",
      "\n",
      "Epoch [148/199] phase: validC train loss: -0.0040 acc: 0.9780 valid loss: 0.0241 acc: 0.6732\n",
      "\n",
      "Epoch [149/199] phase: validA train loss: 0.0018 acc: 0.9546 valid loss: 0.1817 acc: 0.2790\n",
      "\n",
      "Epoch [149/199] phase: validB train loss: 0.0061 acc: 0.8384 valid loss: 0.1487 acc: 0.2424\n",
      "\n",
      "Epoch [149/199] phase: validC train loss: 0.0010 acc: 0.9799 valid loss: 0.0256 acc: 0.6564\n",
      "\n",
      "Epoch [149/199] phase: validC train loss: -0.0017 acc: 0.9738 valid loss: 0.0249 acc: 0.6615\n",
      "\n",
      "Epoch [149/199] phase: validC train loss: -0.0039 acc: 0.9759 valid loss: 0.0288 acc: 0.6308\n",
      "\n",
      "Epoch [150/199] phase: validA train loss: 0.0018 acc: 0.9545 valid loss: 0.1717 acc: 0.2790\n",
      "\n",
      "Epoch [150/199] phase: validB train loss: 0.0061 acc: 0.8392 valid loss: 0.1491 acc: 0.2428\n",
      "\n",
      "Epoch [150/199] phase: validC train loss: 0.0011 acc: 0.9774 valid loss: 0.0290 acc: 0.6326\n",
      "\n",
      "Epoch [150/199] phase: validC train loss: -0.0018 acc: 0.9767 valid loss: 0.0269 acc: 0.6316\n",
      "\n",
      "Epoch [150/199] phase: validC train loss: -0.0039 acc: 0.9769 valid loss: 0.0268 acc: 0.6553\n",
      "\n",
      "Epoch [151/199] phase: validA train loss: 0.0018 acc: 0.9580 valid loss: 0.1790 acc: 0.2791\n",
      "\n",
      "Epoch [151/199] phase: validB train loss: 0.0060 acc: 0.8407 valid loss: 0.1515 acc: 0.2424\n",
      "\n",
      "Epoch [151/199] phase: validC train loss: 0.0008 acc: 0.9826 valid loss: 0.0253 acc: 0.6657\n",
      "\n",
      "Epoch [151/199] phase: validC train loss: -0.0017 acc: 0.9757 valid loss: 0.0257 acc: 0.6436\n",
      "\n",
      "Epoch [151/199] phase: validC train loss: -0.0039 acc: 0.9749 valid loss: 0.0257 acc: 0.6638\n",
      "\n",
      "Epoch [152/199] phase: validA train loss: 0.0018 acc: 0.9559 valid loss: 0.1750 acc: 0.2794\n",
      "\n",
      "Epoch [152/199] phase: validB train loss: 0.0061 acc: 0.8383 valid loss: 0.1479 acc: 0.2421\n",
      "\n",
      "Epoch [152/199] phase: validC train loss: 0.0012 acc: 0.9760 valid loss: 0.0258 acc: 0.6616\n",
      "\n",
      "Epoch [152/199] phase: validC train loss: -0.0017 acc: 0.9766 valid loss: 0.0247 acc: 0.6547\n",
      "\n",
      "Epoch [152/199] phase: validC train loss: -0.0039 acc: 0.9776 valid loss: 0.0301 acc: 0.6250\n",
      "\n",
      "Epoch [153/199] phase: validA train loss: 0.0018 acc: 0.9562 valid loss: 0.1756 acc: 0.2788\n",
      "\n",
      "Epoch [153/199] phase: validB train loss: 0.0060 acc: 0.8429 valid loss: 0.1475 acc: 0.2433\n",
      "\n",
      "Epoch [153/199] phase: validC train loss: 0.0009 acc: 0.9811 valid loss: 0.0283 acc: 0.6350\n",
      "\n",
      "Epoch [153/199] phase: validC train loss: -0.0017 acc: 0.9735 valid loss: 0.0241 acc: 0.6660\n",
      "\n",
      "Epoch [153/199] phase: validC train loss: -0.0039 acc: 0.9780 valid loss: 0.0290 acc: 0.6259\n",
      "\n",
      "Epoch [154/199] phase: validA train loss: 0.0018 acc: 0.9585 valid loss: 0.1774 acc: 0.2788\n",
      "\n",
      "Epoch [154/199] phase: validB train loss: 0.0061 acc: 0.8385 valid loss: 0.1532 acc: 0.2425\n",
      "\n",
      "Epoch [154/199] phase: validC train loss: 0.0009 acc: 0.9797 valid loss: 0.0280 acc: 0.6390\n",
      "\n",
      "Epoch [154/199] phase: validC train loss: -0.0018 acc: 0.9778 valid loss: 0.0257 acc: 0.6575\n",
      "\n",
      "Epoch [154/199] phase: validC train loss: -0.0039 acc: 0.9781 valid loss: 0.0293 acc: 0.6286\n",
      "\n",
      "Epoch [155/199] phase: validA train loss: 0.0018 acc: 0.9574 valid loss: 0.1744 acc: 0.2795\n",
      "\n",
      "Epoch [155/199] phase: validB train loss: 0.0060 acc: 0.8392 valid loss: 0.1511 acc: 0.2428\n",
      "\n",
      "Epoch [155/199] phase: validC train loss: 0.0011 acc: 0.9761 valid loss: 0.0266 acc: 0.6462\n",
      "\n",
      "Epoch [155/199] phase: validC train loss: -0.0018 acc: 0.9776 valid loss: 0.0341 acc: 0.5939\n",
      "\n",
      "Epoch [155/199] phase: validC train loss: -0.0039 acc: 0.9771 valid loss: 0.0263 acc: 0.6532\n",
      "\n",
      "Epoch [156/199] phase: validA train loss: 0.0019 acc: 0.9559 valid loss: 0.1729 acc: 0.2791\n",
      "\n",
      "Epoch [156/199] phase: validB train loss: 0.0062 acc: 0.8361 valid loss: 0.1476 acc: 0.2425\n",
      "\n",
      "Epoch [156/199] phase: validC train loss: 0.0011 acc: 0.9782 valid loss: 0.0252 acc: 0.6687\n",
      "\n",
      "Epoch [156/199] phase: validC train loss: -0.0017 acc: 0.9752 valid loss: 0.0264 acc: 0.6442\n",
      "\n",
      "Epoch [156/199] phase: validC train loss: -0.0039 acc: 0.9772 valid loss: 0.0296 acc: 0.6199\n",
      "\n",
      "Epoch [157/199] phase: validA train loss: 0.0019 acc: 0.9567 valid loss: 0.1748 acc: 0.2790\n",
      "\n",
      "Epoch [157/199] phase: validB train loss: 0.0060 acc: 0.8423 valid loss: 0.1499 acc: 0.2430\n",
      "\n",
      "Epoch [157/199] phase: validC train loss: 0.0010 acc: 0.9805 valid loss: 0.0277 acc: 0.6336\n",
      "\n",
      "Epoch [157/199] phase: validC train loss: -0.0017 acc: 0.9744 valid loss: 0.0248 acc: 0.6629\n",
      "\n",
      "Epoch [157/199] phase: validC train loss: -0.0039 acc: 0.9770 valid loss: 0.0302 acc: 0.6231\n",
      "\n",
      "Epoch [158/199] phase: validA train loss: 0.0018 acc: 0.9545 valid loss: 0.1696 acc: 0.2792\n",
      "\n",
      "Epoch [158/199] phase: validB train loss: 0.0061 acc: 0.8392 valid loss: 0.1555 acc: 0.2427\n",
      "\n",
      "Epoch [158/199] phase: validC train loss: 0.0010 acc: 0.9793 valid loss: 0.0303 acc: 0.6241\n",
      "\n",
      "Epoch [158/199] phase: validC train loss: -0.0018 acc: 0.9762 valid loss: 0.0269 acc: 0.6415\n",
      "\n",
      "Epoch [158/199] phase: validC train loss: -0.0039 acc: 0.9764 valid loss: 0.0279 acc: 0.6430\n",
      "\n",
      "Epoch [159/199] phase: validA train loss: 0.0018 acc: 0.9570 valid loss: 0.1731 acc: 0.2785\n",
      "\n",
      "Epoch [159/199] phase: validB train loss: 0.0060 acc: 0.8414 valid loss: 0.1528 acc: 0.2431\n",
      "\n",
      "Epoch [159/199] phase: validC train loss: 0.0010 acc: 0.9798 valid loss: 0.0262 acc: 0.6548\n",
      "\n",
      "Epoch [159/199] phase: validC train loss: -0.0019 acc: 0.9774 valid loss: 0.0242 acc: 0.6578\n",
      "\n",
      "Epoch [159/199] phase: validC train loss: -0.0039 acc: 0.9762 valid loss: 0.0266 acc: 0.6496\n",
      "\n",
      "Epoch [160/199] phase: validA train loss: 0.0018 acc: 0.9568 valid loss: 0.1727 acc: 0.2789\n",
      "\n",
      "Epoch [160/199] phase: validB train loss: 0.0060 acc: 0.8425 valid loss: 0.1504 acc: 0.2424\n",
      "\n",
      "Epoch [160/199] phase: validC train loss: 0.0010 acc: 0.9800 valid loss: 0.0284 acc: 0.6300\n",
      "\n",
      "Epoch [160/199] phase: validC train loss: -0.0017 acc: 0.9754 valid loss: 0.0296 acc: 0.6285\n",
      "\n",
      "Epoch [160/199] phase: validC train loss: -0.0039 acc: 0.9783 valid loss: 0.0277 acc: 0.6465\n",
      "\n",
      "Epoch [161/199] phase: validA train loss: 0.0018 acc: 0.9548 valid loss: 0.1790 acc: 0.2793\n",
      "\n",
      "Epoch [161/199] phase: validB train loss: 0.0060 acc: 0.8441 valid loss: 0.1562 acc: 0.2428\n",
      "\n",
      "Epoch [161/199] phase: validC train loss: 0.0009 acc: 0.9806 valid loss: 0.0270 acc: 0.6489\n",
      "\n",
      "Epoch [161/199] phase: validC train loss: -0.0017 acc: 0.9772 valid loss: 0.0274 acc: 0.6364\n",
      "\n",
      "Epoch [161/199] phase: validC train loss: -0.0039 acc: 0.9786 valid loss: 0.0276 acc: 0.6463\n",
      "\n",
      "Epoch [162/199] phase: validA train loss: 0.0018 acc: 0.9547 valid loss: 0.1744 acc: 0.2794\n",
      "\n",
      "Epoch [162/199] phase: validB train loss: 0.0061 acc: 0.8419 valid loss: 0.1556 acc: 0.2430\n",
      "\n",
      "Epoch [162/199] phase: validC train loss: 0.0009 acc: 0.9813 valid loss: 0.0277 acc: 0.6470\n",
      "\n",
      "Epoch [162/199] phase: validC train loss: -0.0018 acc: 0.9780 valid loss: 0.0252 acc: 0.6433\n",
      "\n",
      "Epoch [162/199] phase: validC train loss: -0.0039 acc: 0.9788 valid loss: 0.0284 acc: 0.6346\n",
      "\n",
      "Epoch [163/199] phase: validA train loss: 0.0019 acc: 0.9544 valid loss: 0.1737 acc: 0.2792\n",
      "\n",
      "Epoch [163/199] phase: validB train loss: 0.0061 acc: 0.8399 valid loss: 0.1516 acc: 0.2428\n",
      "\n",
      "Epoch [163/199] phase: validC train loss: 0.0010 acc: 0.9790 valid loss: 0.0271 acc: 0.6404\n",
      "\n",
      "Epoch [163/199] phase: validC train loss: -0.0017 acc: 0.9759 valid loss: 0.0302 acc: 0.6198\n",
      "\n",
      "Epoch [163/199] phase: validC train loss: -0.0040 acc: 0.9789 valid loss: 0.0268 acc: 0.6507\n",
      "\n",
      "Epoch [164/199] phase: validA train loss: 0.0018 acc: 0.9564 valid loss: 0.1743 acc: 0.2793\n",
      "\n",
      "Epoch [164/199] phase: validB train loss: 0.0061 acc: 0.8412 valid loss: 0.1491 acc: 0.2429\n",
      "\n",
      "Epoch [164/199] phase: validC train loss: 0.0009 acc: 0.9807 valid loss: 0.0273 acc: 0.6478\n",
      "\n",
      "Epoch [164/199] phase: validC train loss: -0.0018 acc: 0.9778 valid loss: 0.0298 acc: 0.6281\n",
      "\n",
      "Epoch [164/199] phase: validC train loss: -0.0039 acc: 0.9774 valid loss: 0.0306 acc: 0.6190\n",
      "\n",
      "Epoch [165/199] phase: validA train loss: 0.0018 acc: 0.9559 valid loss: 0.1756 acc: 0.2789\n",
      "\n",
      "Epoch [165/199] phase: validB train loss: 0.0060 acc: 0.8421 valid loss: 0.1518 acc: 0.2428\n",
      "\n",
      "Epoch [165/199] phase: validC train loss: 0.0011 acc: 0.9779 valid loss: 0.0292 acc: 0.6327\n",
      "\n",
      "Epoch [165/199] phase: validC train loss: -0.0018 acc: 0.9746 valid loss: 0.0258 acc: 0.6478\n",
      "\n",
      "Epoch [165/199] phase: validC train loss: -0.0040 acc: 0.9805 valid loss: 0.0292 acc: 0.6378\n",
      "\n",
      "Epoch [166/199] phase: validA train loss: 0.0018 acc: 0.9570 valid loss: 0.1723 acc: 0.2791\n",
      "\n",
      "Epoch [166/199] phase: validB train loss: 0.0061 acc: 0.8416 valid loss: 0.1557 acc: 0.2427\n",
      "\n",
      "Epoch [166/199] phase: validC train loss: 0.0010 acc: 0.9785 valid loss: 0.0287 acc: 0.6383\n",
      "\n",
      "Epoch [166/199] phase: validC train loss: -0.0018 acc: 0.9792 valid loss: 0.0268 acc: 0.6424\n",
      "\n",
      "Epoch [166/199] phase: validC train loss: -0.0040 acc: 0.9801 valid loss: 0.0269 acc: 0.6556\n",
      "\n",
      "Epoch [167/199] phase: validA train loss: 0.0018 acc: 0.9554 valid loss: 0.1721 acc: 0.2796\n",
      "\n",
      "Epoch [167/199] phase: validB train loss: 0.0060 acc: 0.8419 valid loss: 0.1485 acc: 0.2430\n",
      "\n",
      "Epoch [167/199] phase: validC train loss: 0.0010 acc: 0.9804 valid loss: 0.0277 acc: 0.6483\n",
      "\n",
      "Epoch [167/199] phase: validC train loss: -0.0017 acc: 0.9743 valid loss: 0.0323 acc: 0.6028\n",
      "\n",
      "Epoch [167/199] phase: validC train loss: -0.0041 acc: 0.9792 valid loss: 0.0340 acc: 0.5990\n",
      "\n",
      "Epoch [168/199] phase: validA train loss: 0.0018 acc: 0.9574 valid loss: 0.1762 acc: 0.2787\n",
      "\n",
      "Epoch [168/199] phase: validB train loss: 0.0060 acc: 0.8399 valid loss: 0.1462 acc: 0.2429\n",
      "\n",
      "Epoch [168/199] phase: validC train loss: 0.0008 acc: 0.9837 valid loss: 0.0311 acc: 0.6175\n",
      "\n",
      "Epoch [168/199] phase: validC train loss: -0.0018 acc: 0.9777 valid loss: 0.0277 acc: 0.6433\n",
      "\n",
      "Epoch [168/199] phase: validC train loss: -0.0040 acc: 0.9776 valid loss: 0.0287 acc: 0.6267\n",
      "\n",
      "Epoch [169/199] phase: validA train loss: 0.0018 acc: 0.9564 valid loss: 0.1765 acc: 0.2792\n",
      "\n",
      "Epoch [169/199] phase: validB train loss: 0.0061 acc: 0.8396 valid loss: 0.1519 acc: 0.2431\n",
      "\n",
      "Epoch [169/199] phase: validC train loss: 0.0009 acc: 0.9819 valid loss: 0.0281 acc: 0.6319\n",
      "\n",
      "Epoch [169/199] phase: validC train loss: -0.0018 acc: 0.9763 valid loss: 0.0301 acc: 0.6207\n",
      "\n",
      "Epoch [169/199] phase: validC train loss: -0.0039 acc: 0.9793 valid loss: 0.0264 acc: 0.6425\n",
      "\n",
      "Epoch [170/199] phase: validA train loss: 0.0018 acc: 0.9557 valid loss: 0.1747 acc: 0.2793\n",
      "\n",
      "Epoch [170/199] phase: validB train loss: 0.0061 acc: 0.8382 valid loss: 0.1482 acc: 0.2428\n",
      "\n",
      "Epoch [170/199] phase: validC train loss: 0.0008 acc: 0.9826 valid loss: 0.0254 acc: 0.6488\n",
      "\n",
      "Epoch [170/199] phase: validC train loss: -0.0018 acc: 0.9756 valid loss: 0.0233 acc: 0.6725\n",
      "\n",
      "Epoch [170/199] phase: validC train loss: -0.0041 acc: 0.9798 valid loss: 0.0324 acc: 0.6152\n",
      "\n",
      "Epoch [171/199] phase: validA train loss: 0.0018 acc: 0.9567 valid loss: 0.1746 acc: 0.2795\n",
      "\n",
      "Epoch [171/199] phase: validB train loss: 0.0061 acc: 0.8381 valid loss: 0.1531 acc: 0.2429\n",
      "\n",
      "Epoch [171/199] phase: validC train loss: 0.0010 acc: 0.9800 valid loss: 0.0305 acc: 0.6327\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9817936e2f7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training time: {:10f} minutes'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-a5a397b3c6eb>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(dataloders, model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmdlzAC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                             \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trainC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                             \u001b[0mmdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m                             \u001b[0mopti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-4effc76f42f2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m     24\u001b[0m         )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mweight_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-4effc76f42f2>\u001b[0m in \u001b[0;36mweight_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mkaiming_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-4effc76f42f2>\u001b[0m in \u001b[0;36mkaiming_init\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkaiming_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparsity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/init.py\u001b[0m in \u001b[0;36msparse_\u001b[0;34m(tensor, sparsity, std)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mrow_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mzero_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_zeros\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mzero_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logging.info(\"#### bn acti conv and fc - unlimited bn - adam learning rate 0.001 - scheduler 20 - opt adamw ####\")\n",
    "\n",
    "start_time = time.time()\n",
    "model = train_model(dloaders, model, criterion, optimizer, exp_lr_scheduler, num_epochs=200)\n",
    "print('Training time: {:10f} minutes'.format((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test funciton on conv layers\n",
    "\n",
    "A = list(resnetA.named_parameters())[-14][1]\n",
    "B = list(resnetB.named_parameters())[-14][1]\n",
    "x = torch.cat((A, B), 1)\n",
    "x.shape\n",
    "\n",
    "pool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "inter = Interpolate(size=(1), mode='bilinear')\n",
    "\n",
    "px = pool(x)\n",
    "ix = inter(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
