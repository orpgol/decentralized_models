{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import random\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from scipy.stats import entropy, ks_2samp\n",
    "from scipy.special import kl_div\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard\n",
    "\n",
    "import traceback\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logname = 'logs/decentralized_multi_agent'\n",
    "logging.basicConfig(filename=logname,\n",
    "                            filemode='a',\n",
    "                            format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                            datefmt='%H:%M:%S',\n",
    "                            level=logging.DEBUG)\n",
    "\n",
    "logging.info(\"Running Decentralized Learning test\")\n",
    "\n",
    "logger = logging.getLogger('Decentralized_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5832054cd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Transformations A\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Transformations B\n",
    "RC   = transforms.RandomCrop(32, padding=4)\n",
    "RHF  = transforms.RandomHorizontalFlip()\n",
    "RVF  = transforms.RandomVerticalFlip()\n",
    "NRM  = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "TT   = transforms.ToTensor()\n",
    "TPIL = transforms.ToPILImage()\n",
    "\n",
    "# Transforms object for trainset with augmentation\n",
    "transform_with_aug = transforms.Compose([TPIL, RC, RHF, TT, NRM])\n",
    "# Transforms object for testset with NO augmentation\n",
    "transform_no_aug   = transforms.Compose([TT, NRM])\n",
    "\n",
    "# Downloading/Louding CIFAR10 data\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data/cifar10', train=True,\n",
    "                                        download=True, transform=transform_with_aug)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data/cifar10', train=False,\n",
    "                                       download=True, transform=transform_no_aug)\n",
    "\n",
    "classDict = {'plane':0, 'car':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}\n",
    "\n",
    "# Separating trainset/testset data/label\n",
    "x_train  = trainset.data\n",
    "x_test   = testset.data\n",
    "y_train  = trainset.targets\n",
    "y_test   = testset.targets\n",
    "\n",
    "# Define a function to separate CIFAR classes by class index\n",
    "\n",
    "def get_class_i(x, y, i):\n",
    "    \"\"\"\n",
    "    x: trainset.train_data or testset.test_data\n",
    "    y: trainset.train_labels or testset.test_labels\n",
    "    i: class label, a number between 0 to 9\n",
    "    return: x_i\n",
    "    \"\"\"\n",
    "    # Convert to a numpy array\n",
    "    y = np.array(y)\n",
    "    # Locate position of labels that equal to i\n",
    "    pos_i = np.argwhere(y == i)\n",
    "    # Convert the result into a 1-D list\n",
    "    pos_i = list(pos_i[:,0])\n",
    "    # Collect all data that match the desired label\n",
    "    x_i = [x[j] for j in pos_i]\n",
    "    \n",
    "    return x_i\n",
    "\n",
    "class DatasetMaker(Dataset):\n",
    "    def __init__(self, datasets, transformFunc = transform_no_aug):\n",
    "        \"\"\"\n",
    "        datasets: a list of get_class_i outputs, i.e. a list of list of images for selected classes\n",
    "        \"\"\"\n",
    "        self.datasets = datasets\n",
    "        self.lengths  = [len(d) for d in self.datasets]\n",
    "        self.transformFunc = transformFunc\n",
    "    def __getitem__(self, i):\n",
    "        class_label, index_wrt_class = self.index_of_which_bin(self.lengths, i)\n",
    "        img = self.datasets[class_label][index_wrt_class]\n",
    "        img = self.transformFunc(img)\n",
    "        return img, class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.lengths)\n",
    "    \n",
    "    def index_of_which_bin(self, bin_sizes, absolute_index, verbose=False):\n",
    "        \"\"\"\n",
    "        Given the absolute index, returns which bin it falls in and which element of that bin it corresponds to.\n",
    "        \"\"\"\n",
    "        # Which class/bin does i fall into?\n",
    "        accum = np.add.accumulate(bin_sizes)\n",
    "        if verbose:\n",
    "            print(\"accum =\", accum)\n",
    "        bin_index  = len(np.argwhere(accum <= absolute_index))\n",
    "        if verbose:\n",
    "            print(\"class_label =\", bin_index)\n",
    "        # Which element of the fallent class/bin does i correspond to?\n",
    "        index_wrt_class = absolute_index - np.insert(accum, 0, 0)[bin_index]\n",
    "        if verbose:\n",
    "            print(\"index_wrt_class =\", index_wrt_class)\n",
    "\n",
    "        return bin_index, index_wrt_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are saving a fraction\n",
    "frac = int(len(x_train) * 0.05)\n",
    "x_reserve = x_train[:frac]\n",
    "y_reserve = y_train[:frac]\n",
    "x_train = x_train[frac:]\n",
    "y_train = y_train[frac:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Usage ================== #\n",
    "\n",
    "# \n",
    "trainset1 = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_train, y_train, classDict['plane']), \n",
    "         get_class_i(x_train, y_train, classDict['car']), \n",
    "         get_class_i(x_train, y_train, classDict['bird']),\n",
    "        [],[],[],[],[],[],[]],\n",
    "        transform_with_aug\n",
    "    )\n",
    "trainset2 = \\\n",
    "    DatasetMaker(\n",
    "        [[],[],[],\n",
    "         get_class_i(x_train, y_train, classDict['cat']), \n",
    "         get_class_i(x_train, y_train, classDict['deer']), \n",
    "         get_class_i(x_train, y_train, classDict['dog']), \n",
    "         [],[],[],[]],\n",
    "        transform_with_aug\n",
    "    )\n",
    "trainset3 = \\\n",
    "    DatasetMaker(\n",
    "        [[],[],[],[],[],[],\n",
    "         get_class_i(x_train, y_train, classDict['frog']), \n",
    "         get_class_i(x_train, y_train, classDict['horse']), \n",
    "         get_class_i(x_train, y_train, classDict['ship']), \n",
    "         get_class_i(x_train, y_train, classDict['truck'])],\n",
    "        transform_with_aug\n",
    "    )\n",
    "trainset4 = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_train, y_train, classDict['plane']), \n",
    "         get_class_i(x_train, y_train, classDict['car']), \n",
    "         get_class_i(x_train, y_train, classDict['bird']), \n",
    "         get_class_i(x_train, y_train, classDict['cat']), \n",
    "         get_class_i(x_train, y_train, classDict['deer']),\n",
    "         get_class_i(x_train, y_train, classDict['dog']), \n",
    "         get_class_i(x_train, y_train, classDict['frog']), \n",
    "         get_class_i(x_train, y_train, classDict['horse']), \n",
    "         get_class_i(x_train, y_train, classDict['ship']), \n",
    "         get_class_i(x_train, y_train, classDict['truck'])],\n",
    "        transform_with_aug\n",
    "    )\n",
    "reserved = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_reserve, y_reserve, classDict['plane']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['car']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['bird']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['cat']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['deer']),\n",
    "         get_class_i(x_reserve, y_reserve, classDict['dog']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['frog']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['horse']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['ship']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['truck'])],\n",
    "        transform_with_aug\n",
    "    )\n",
    "testset  = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_test, y_test, classDict['plane']), \n",
    "         get_class_i(x_test, y_test, classDict['car']), \n",
    "         get_class_i(x_test, y_test, classDict['bird']), \n",
    "         get_class_i(x_test, y_test, classDict['cat']), \n",
    "         get_class_i(x_test, y_test, classDict['deer']),\n",
    "         get_class_i(x_test, y_test, classDict['dog']), \n",
    "         get_class_i(x_test, y_test, classDict['frog']), \n",
    "         get_class_i(x_test, y_test, classDict['horse']), \n",
    "         get_class_i(x_test, y_test, classDict['ship']), \n",
    "         get_class_i(x_test, y_test, classDict['truck'])],\n",
    "        transform_no_aug\n",
    "    )\n",
    "\n",
    "superset = torch.utils.data.ConcatDataset([trainset3,reserved])\n",
    "supersetA = torch.utils.data.ConcatDataset([trainset1,reserved])\n",
    "supersetB = torch.utils.data.ConcatDataset([trainset2,reserved])\n",
    "\n",
    "kwargs = {'num_workers': 2, 'pin_memory': False}\n",
    "\n",
    "# Create datasetLoaders from trainset and testset\n",
    "trainsetLoader1   = DataLoader(trainset1, batch_size=128, shuffle=True , **kwargs)\n",
    "trainsetLoader2   = DataLoader(trainset2, batch_size=128, shuffle=True , **kwargs)\n",
    "trainsetLoader3   = DataLoader(trainset3, batch_size=128, shuffle=True , **kwargs)\n",
    "trainsetLoader4   = DataLoader(trainset4, batch_size=128, shuffle=True , **kwargs)\n",
    "reservedLoader    = DataLoader(superset, batch_size=128, shuffle=True , **kwargs)\n",
    "reservedLoaderA    = DataLoader(superset, batch_size=128, shuffle=True , **kwargs)\n",
    "reservedLoaderB    = DataLoader(superset, batch_size=128, shuffle=True , **kwargs)\n",
    "testsetLoader     = DataLoader(testset , batch_size=128, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.3    # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = next(iter(reservedLoader))\n",
    "imshow(torchvision.utils.make_grid(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(device)\n",
    "print(device)\n",
    "\n",
    "# device2 = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decentralized model using reserved data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a knowledge transfer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_init(m):\n",
    "    if isinstance(m, (torch.nn.Linear)):\n",
    "        torch.nn.init.sparse_(m.weight, sparsity=0.33)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "    elif isinstance(m, (torch.nn.Conv2d)):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "    elif isinstance(m, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d)):\n",
    "        m.weight.data.fill_(1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "class Decenter(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super(Decenter, self).__init__()\n",
    "        if len(shape) == 1:\n",
    "            shape = shape[0]\n",
    "            self.dim = 0\n",
    "        elif len(shape) == 2:\n",
    "            shape = shape[1]\n",
    "            self.dim = 1\n",
    "        self.translation = torch.nn.Sequential(\n",
    "#             torch.nn.Tanh(),\n",
    "            torch.nn.Linear(shape*3, shape)\n",
    "        )\n",
    "\n",
    "#         self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, source1, source2, target):\n",
    "        x = torch.cat((source1, source2, target), self.dim)\n",
    "#         x = torch.cat((torch.flatten(source), torch.flatten(target)), 0)\n",
    "#         x = torch.add(torch.flatten(source).to(\"cpu\"), torch.flatten(target).to(\"cpu\"))\n",
    "        res = self.translation(x)\n",
    "#         res = res.reshape(target.shape)\n",
    "        return res\n",
    "    \n",
    "    \n",
    "class Interpolate(torch.nn.Module):\n",
    "    def __init__(self, size, mode):\n",
    "        super(Interpolate, self).__init__()\n",
    "        self.interp = torch.nn.functional.interpolate\n",
    "        self.size = size\n",
    "        self.mode = mode\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.interp(x, size=self.size, mode=self.mode, align_corners=False)\n",
    "        return x\n",
    "    \n",
    "class Reshape(torch.nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "    \n",
    "class Decenter_pooled(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super(Decenter_pooled, self).__init__()\n",
    "        self.shape = shape\n",
    "        self.translation = torch.nn.Sequential(\n",
    "#             torch.nn.BatchNorm2d(channels_out),\n",
    "#             torch.nn.AdaptiveAvgPool2d(1),\n",
    "            Interpolate(size=1, mode='bilinear'),\n",
    "            Reshape(shape[0], shape[1]*2),\n",
    "            torch.nn.Linear(shape[1]*2, shape[1]*shape[-1]*shape[-1]),\n",
    "#             Reshape(shape[0], shape[1] ,1 ,1),\n",
    "        )\n",
    "\n",
    "#         self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        x = torch.cat((source, target), 1)\n",
    "        res = self.translation(x)\n",
    "        res = res.view(self.shape[0], self.shape[1], self.shape[2], self.shape[3])\n",
    "        return res\n",
    "    \n",
    "    \n",
    "class Decenter_conv(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super(Decenter_conv, self).__init__()\n",
    "        self.shape = shape\n",
    "        channels_in = shape[1]*3\n",
    "        channels_out = shape[1]\n",
    "        self.translation = torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm2d(channels_in),\n",
    "            torch.nn.Conv2d(channels_in, channels_out, 3, stride=1, padding=1)\n",
    "#             torch.nn.ConvTranspose2d(channels_in, channels_out, 3, stride=1, padding=1)\n",
    "#             torch.nn.Linear(shape[0]*2, shape[0]*4),\n",
    "#             torch.nn.Dropout(p=0.5),\n",
    "#             torch.nn.Linear(shape[0]*2, shape[0]),\n",
    "#             torch.nn.AdaptiveAvgPool2d((shape[-2],shape[-1])),\n",
    "#             torch.nn.Conv2d(channels_out, channels_out, 3, stride=1, padding=1)\n",
    "\n",
    "        )\n",
    "        self.translation2 = torch.nn.Sequential(\n",
    "            torch.nn.AdaptiveMaxPool2d((shape[-2],shape[-1])),\n",
    "        )\n",
    "\n",
    "#         self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, source1, source2, target):\n",
    "        x = torch.cat((source1, source2, target), 1)\n",
    "#         x = x.reshape(-1, x.shape[0])\n",
    "#         x = torch.cat((torch.flatten(source), torch.flatten(target)), 0)\n",
    "#         x = torch.add(torch.flatten(source).to(\"cpu\"), torch.flatten(target).to(\"cpu\"))\n",
    "        res = self.translation(x)\n",
    "#         res = res.reshape(self.shape)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_dict: dict = {}\n",
    "def fc_hook(layer_name, grad_input, grad_output): \n",
    "    if layer_name not in grad_dict:\n",
    "        grad_dict[layer_name] = {}\n",
    "        grad_dict[layer_name][\"grad_input\"] = []\n",
    "        grad_dict[layer_name][\"grad_output\"] = []\n",
    "        grad_dict[layer_name][\"labels\"] = []\n",
    "        \n",
    "#     print(grad_input)\n",
    "#     print(grad_output)\n",
    "    grad_dict[layer_name][\"grad_input\"].append(grad_input[0].cpu().numpy())\n",
    "    grad_dict[layer_name][\"grad_output\"].append(grad_output[0].cpu().numpy())\n",
    "    \n",
    "# def reserve_step(source, target):\n",
    "    \n",
    "\n",
    "matlst = []\n",
    "fclst = []\n",
    "\n",
    "options = {0: ['trainA', 'validA','reservedAB'], \n",
    "           1: ['trainB','validB','reservedBA'],\n",
    "           2: ['trainC','validC','reservedCA','validC']}\n",
    "\n",
    "def train_model(dataloders, model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    writer = SummaryWriter('runs/') \n",
    "\n",
    "    since = time.time()\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    best_model_wts = 0.0\n",
    "    best_acc = 0.0\n",
    "    dataset_sizes = {'trainA': len(dataloders['trainA'].sampler),\n",
    "                     'trainB': len(dataloders['trainB'].sampler),\n",
    "                     'trainC': len(dataloders['trainC'].sampler),\n",
    "                     'reservedA': len(dataloders['reservedA'].sampler),\n",
    "                     'reservedB': len(dataloders['reservedB'].sampler),\n",
    "                     'reservedCA': len(dataloders['reservedCA'].sampler),\n",
    "                     'reservedAB': len(dataloders['reservedAB'].sampler),\n",
    "                     'reservedBA': len(dataloders['reservedBA'].sampler),\n",
    "                     'validA': len(dataloders['validA'].sampler),\n",
    "                     'validB': len(dataloders['validB'].sampler),\n",
    "                     'validC': len(dataloders['validC'].sampler)}\n",
    "\n",
    "    i = 0\n",
    "    ivc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['trainA', 'validA','trainB','validB','trainC','validC','reservedCA','validC']:\n",
    "#         choice = np.random.choice(range(3), replace=False)\n",
    "#         for phase in options[choice]:\n",
    "            if phase not in ['validA','validB','validC']:\n",
    "                model[phase].train(True)\n",
    "            else:\n",
    "                model['trainA'].train(False)\n",
    "                model['trainB'].train(False)\n",
    "                model['trainC'].train(False)\n",
    "            \n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            if phase in ['reservedCA','reservedAB', 'reservedBA']:\n",
    "                if phase == 'reservedCA':\n",
    "                    sd = model[phase].state_dict()\n",
    "                    for key, value in mdlzAC.items():\n",
    "                        shape = model['trainC'].state_dict()[key].shape\n",
    "                        mdl = value[1](shape).to(device)\n",
    "                        checkpoint = torch.load(value[0])\n",
    "                        mdl.load_state_dict(checkpoint['model_state_dict'])\n",
    "                        mdl.eval()\n",
    "                        sd[key] = mdl(copy.deepcopy(model['trainA'].state_dict()[key]),\n",
    "                                      copy.deepcopy(model['trainB'].state_dict()[key]),\n",
    "                                      copy.deepcopy(model['trainC'].state_dict()[key]))\n",
    "#                         torch.save({'model_state_dict': mdl.state_dict()}, value[0])\n",
    "                        \n",
    "#                         if key == 'conv1.weight':\n",
    "#                             matlst.append(sd[key])\n",
    "#                         elif key == 'fc.weight':\n",
    "#                             fclst.append(sd[key])\n",
    "                    model[phase].load_state_dict(sd)\n",
    "        \n",
    "                elif phase == 'reservedAB':\n",
    "                    sd = model[phase].state_dict()\n",
    "                    for key, value in mdlzAB.items():\n",
    "                        shape = model['trainA'].state_dict()[key].shape\n",
    "                        mdl = value[1](shape).to(device)\n",
    "                        checkpoint = torch.load(value[0])\n",
    "                        mdl.load_state_dict(checkpoint['model_state_dict'])\n",
    "                        mdl.eval()\n",
    "                        sd[key] = mdl(copy.deepcopy(model['trainA'].state_dict()[key]),\n",
    "                                      copy.deepcopy(model['trainB'].state_dict()[key]),\n",
    "                                      copy.deepcopy(model['trainC'].state_dict()[key]))\n",
    "#                         torch.save({'model_state_dict': mdl.state_dict()}, value[0])\n",
    "                        \n",
    "#                         if key == 'conv1.weight':\n",
    "#                             matlst.append(sd[key])\n",
    "#                         elif key == 'fc.weight':\n",
    "#                             fclst.append(sd[key])    \n",
    "                    model[phase].load_state_dict(sd)\n",
    "    \n",
    "                elif phase == 'reservedBA':\n",
    "                    sd = model[phase].state_dict()\n",
    "                    for key, value in mdlzBA.items():\n",
    "                        shape = model['trainB'].state_dict()[key].shape\n",
    "                        mdl = value[1](shape).to(device)\n",
    "                        checkpoint = torch.load(value[0])\n",
    "                        mdl.load_state_dict(checkpoint['model_state_dict'])\n",
    "                        mdl.eval()\n",
    "                        sd[key] = mdl(copy.deepcopy(model['trainA'].state_dict()[key]),\n",
    "                                      copy.deepcopy(model['trainB'].state_dict()[key]),\n",
    "                                      copy.deepcopy(model['trainC'].state_dict()[key]))\n",
    "                    #                         torch.save({'model_state_dict': mdl.state_dict()}, value[0])\n",
    "\n",
    "                    #                         if key == 'conv1.weight':\n",
    "                    #                             matlst.append(sd[key])\n",
    "                    #                         elif key == 'fc.weight':\n",
    "                    #                             fclst.append(sd[key])    \n",
    "                    model[phase].load_state_dict(sd)\n",
    "                    \n",
    "                    \n",
    "            for inputs, labels in dataloders[phase]:\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer[phase].zero_grad()\n",
    "\n",
    "                outputs = model[phase](inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                \n",
    "                if phase in ['reservedCA','reservedAB','reservedBA']:\n",
    "                    loss_a = criterion['trainC'](outputs, labels)\n",
    "#                     batch_size = labels.shape[0]\n",
    "#                     # Dummy input that HAS to be 2D for the scatter (you can use view(-1,1) if needed)\n",
    "#                     y = labels.reshape(-1,1)\n",
    "#                     # One hot encoding buffer that you create out of the loop and just keep reusing\n",
    "#                     y_onehot = torch.FloatTensor(batch_size, 10).to(device)\n",
    "\n",
    "#                     # In your for loop\n",
    "#                     y_onehot.zero_()\n",
    "#                     y_onehot.scatter_(1, y, 1)\n",
    "\n",
    "                    if phase == 'reservedCA':\n",
    "                        outputs2 = model['trainA'](inputs)\n",
    "                        outputs3 = model['trainB'](inputs)\n",
    "                    elif phase == 'reservedAB':\n",
    "                        outputs2 = model['trainC'](inputs)\n",
    "                        outputs3 = model['trainB'](inputs)\n",
    "                    elif phase == 'reservedBA':\n",
    "                        outputs2 = model['trainC'](inputs)\n",
    "                        outputs3 = model['trainA'](inputs)\n",
    "    \n",
    "                    sm = torch.nn.Softmax(dim=1)\n",
    "                    outputs = sm(outputs)\n",
    "                    outputs2 = sm(outputs2)\n",
    "                    outputs3 = sm(outputs3)\n",
    "                    loss_b = criterion[phase](outputs, outputs2)\n",
    "                    loss_c = criterion[phase](outputs, outputs3)\n",
    "                    loss = (loss_a + (loss_b + loss_c)/2)/2\n",
    "                else:\n",
    "                    loss = criterion[phase](outputs, labels)\n",
    "\n",
    "                if phase not in ['validA','validB','validC']:\n",
    "                    loss.backward()\n",
    "                    optimizer[phase].step()\n",
    "                    \n",
    "                    if phase == 'reservedCA':\n",
    "#                         loss_b.backward(retain_graph=False)\n",
    "                        for key, value in mdlzAC.items():\n",
    "                            shape = model['trainC'].state_dict()[key].shape\n",
    "                            mdl = value[1](shape).to(device)\n",
    "                            opti = torch.optim.AdamW(mdl.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "                            checkpoint = torch.load(value[0])\n",
    "                            mdl.load_state_dict(checkpoint['model_state_dict'])\n",
    "                            mdl.train(True)\n",
    "                            opti.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#                             opti.zero_grad()\n",
    "                            opti.step()\n",
    "                            torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                                        'optimizer_state_dict': opti.state_dict(),\n",
    "                                        'factor': checkpoint['factor'],\n",
    "                                        'patience': checkpoint['patience'],\n",
    "                                        'scheduler_state_dict': checkpoint['scheduler_state_dict']},\n",
    "                                        value[0])\n",
    "        \n",
    "                    elif phase == 'reservedAB':\n",
    "#                         loss_b.backward(retain_graph=False)\n",
    "                        for key, value in mdlzAB.items():\n",
    "                            shape = model['trainA'].state_dict()[key].shape\n",
    "                            mdl = value[1](shape).to(device)\n",
    "                            opti = torch.optim.AdamW(mdl.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "                            checkpoint = torch.load(value[0])\n",
    "                            mdl.load_state_dict(checkpoint['model_state_dict'])\n",
    "                            mdl.train(True)\n",
    "                            opti.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#                             opti.zero_grad()\n",
    "                            opti.step()\n",
    "                            torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                                        'optimizer_state_dict': opti.state_dict(),\n",
    "                                        'factor': checkpoint['factor'],\n",
    "                                        'patience': checkpoint['patience'],\n",
    "                                        'scheduler_state_dict': checkpoint['scheduler_state_dict']},\n",
    "                                        value[0])\n",
    "        \n",
    "                    elif phase == 'reservedBA':\n",
    "#                         loss_b.backward(retain_graph=False)\n",
    "                        for key, value in mdlzBA.items():\n",
    "                            shape = model['trainB'].state_dict()[key].shape\n",
    "                            mdl = value[1](shape).to(device)\n",
    "                            opti = torch.optim.AdamW(mdl.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "                            checkpoint = torch.load(value[0])\n",
    "                            mdl.load_state_dict(checkpoint['model_state_dict'])\n",
    "                            mdl.train(True)\n",
    "                            opti.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#                             opti.zero_grad()\n",
    "                            opti.step()\n",
    "                            torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                                        'optimizer_state_dict': opti.state_dict(),\n",
    "                                        'factor': checkpoint['factor'],\n",
    "                                        'patience': checkpoint['patience'],\n",
    "                                        'scheduler_state_dict': checkpoint['scheduler_state_dict']},\n",
    "                                        value[0])\n",
    "                            \n",
    "                    \n",
    "                    ## Back prop hook\n",
    "#                     grad_dict[\"fc\"][\"labels\"].append(labels.cpu().numpy())\n",
    "\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase in ['validA','validB','validC']:\n",
    "                scheduler[phase].step(running_loss)\n",
    "                \n",
    "            elif phase == 'reservedCA':\n",
    "                for key, value in mdlzAC.items():\n",
    "                    checkpoint = torch.load(value[0])\n",
    "                    sched = lr_scheduler.ReduceLROnPlateau(optimizerC, 'min', factor=checkpoint['factor'], patience=checkpoint['patience'])\n",
    "                    sched.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "                    sched.step(running_loss)\n",
    "                    torch.save({'model_state_dict': checkpoint['model_state_dict'],\n",
    "                                'optimizer_state_dict': checkpoint['optimizer_state_dict'],\n",
    "                                'factor': checkpoint['factor'],\n",
    "                                'patience': checkpoint['patience'],\n",
    "                                'scheduler_state_dict': sched.state_dict()},\n",
    "                                value[0])\n",
    "\n",
    "            elif phase == 'reservedAB':\n",
    "                for key, value in mdlzAB.items():\n",
    "                    checkpoint = torch.load(value[0])\n",
    "                    sched = lr_scheduler.ReduceLROnPlateau(optimizerA, 'min', factor=checkpoint['factor'], patience=checkpoint['patience'])\n",
    "                    sched.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "                    sched.step(running_loss)\n",
    "                    torch.save({'model_state_dict': checkpoint['model_state_dict'],\n",
    "                                'optimizer_state_dict': checkpoint['optimizer_state_dict'],\n",
    "                                'factor': checkpoint['factor'],\n",
    "                                'patience': checkpoint['patience'],\n",
    "                                'scheduler_state_dict': sched.state_dict()},\n",
    "                                value[0])\n",
    "                    \n",
    "            elif phase == 'reservedBA':\n",
    "                for key, value in mdlzBA.items():\n",
    "                    checkpoint = torch.load(value[0])\n",
    "                    sched = lr_scheduler.ReduceLROnPlateau(optimizerB, 'min', factor=checkpoint['factor'], patience=checkpoint['patience'])\n",
    "                    sched.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "                    sched.step(running_loss)\n",
    "                    torch.save({'model_state_dict': checkpoint['model_state_dict'],\n",
    "                                'optimizer_state_dict': checkpoint['optimizer_state_dict'],\n",
    "                                'factor': checkpoint['factor'],\n",
    "                                'patience': checkpoint['patience'],\n",
    "                                'scheduler_state_dict': sched.state_dict()},\n",
    "                                value[0])\n",
    "\n",
    "                \n",
    "            if phase not in ['validA','validB','validC']:\n",
    "                train_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                train_epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            else:\n",
    "                valid_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                valid_epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "                print('Epoch [{}/{}] phase: {} train loss: {:.4f} acc: {:.4f} ' \n",
    "                      'valid loss: {:.4f} acc: {:.4f}'.format(\n",
    "                        epoch, num_epochs - 1,\n",
    "                        phase,\n",
    "                        train_epoch_loss, train_epoch_acc, \n",
    "                        valid_epoch_loss, valid_epoch_acc))\n",
    "                print() \n",
    "                logger.info('Epoch [{}/{}] phase: {} train loss: {:.4f} acc: {:.4f} ' \n",
    "                      'valid loss: {:.4f} acc: {:.4f}'.format(\n",
    "                        epoch, num_epochs - 1,\n",
    "                        phase,\n",
    "                        train_epoch_loss, train_epoch_acc, \n",
    "                        valid_epoch_loss, valid_epoch_acc))\n",
    "                \n",
    "                ## Writing to tensorboard\n",
    "#                 if phase == 'validC':\n",
    "#                     ivc += 1\n",
    "#                     if ivc == 2:\n",
    "#                         writer.add_histogram('distribution centers/our_full_mesh', outputs, i)\n",
    "\n",
    "#                         writer.add_scalar('train/loss_our_full_mesh', train_epoch_loss, epoch)\n",
    "#                         writer.add_scalar('train/accuracy_our_full_mesh', train_epoch_acc, epoch)\n",
    "\n",
    "#                         writer.add_scalar('valid/loss_our_full_mesh', valid_epoch_loss, epoch)\n",
    "#                         writer.add_scalar('valid/accuracy_our_full_mesh', valid_epoch_acc, epoch)\n",
    "#                         ivc = 0\n",
    "\n",
    "                \n",
    "            if phase in ['validA','validB','validC'] and valid_epoch_acc > best_acc:\n",
    "                best_acc = valid_epoch_acc\n",
    "                best_model_wts = model[phase].state_dict()\n",
    "\n",
    "            i+=1\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    logger.info('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    writer.close()\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnetA = models.resnet18(pretrained=True)\n",
    "resnetB = models.resnet18(pretrained=True)\n",
    "resnetC = models.resnet18(pretrained=True)\n",
    "# freeze all model parameters\n",
    "# for param in resnet.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# new final layer with 10 classes\n",
    "num_ftrsA = resnetA.fc.in_features\n",
    "resnetA.fc = torch.nn.Linear(num_ftrsA, 10)\n",
    "\n",
    "num_ftrsB = resnetB.fc.in_features\n",
    "resnetB.fc = torch.nn.Linear(num_ftrsB, 10)\n",
    "\n",
    "num_ftrsC = resnetC.fc.in_features\n",
    "resnetC.fc = torch.nn.Linear(num_ftrsC, 10)\n",
    "\n",
    "def fc_backward_hook(module, grad_input, grad_output):  # module is Linear in this case. Ignored.\n",
    "        fc_hook(\"fc\", grad_input, grad_output)\n",
    "resnetA.fc_hook_handle = resnetA.fc.register_backward_hook(fc_backward_hook)\n",
    "resnetB.fc_hook_handle = resnetB.fc.register_backward_hook(fc_backward_hook)\n",
    "resnetC.fc_hook_handle = resnetC.fc.register_backward_hook(fc_backward_hook)\n",
    "\n",
    "\n",
    "def roc_auc_score_micro(y_pred_proba, y_true):\n",
    "    y_pred_proba = y_pred_proba.detach().cpu()\n",
    "    y_true = y_true.detach().cpu()\n",
    "    return metrics.roc_auc_score(\n",
    "        label_binarize(y_true, classes=list(range(y_pred_proba.shape[1]))).ravel(),\n",
    "        y_pred_proba.flatten())\n",
    "\n",
    "\n",
    "resnetA = resnetA.to(device)\n",
    "resnetB = resnetB.to(device)\n",
    "resnetC = resnetC.to(device)\n",
    "\n",
    "criterionA = torch.nn.CrossEntropyLoss()\n",
    "# criterionB = torch.nn.CrossEntropyLoss()\n",
    "# criterionA = torch.nn.KLDivLoss()\n",
    "criterionB = torch.nn.KLDivLoss(reduction = 'batchmean')\n",
    "# criterionB = torch.nn.KLDivLoss(reduction = 'mean')\n",
    "# criterionB = torch.nn.MSELoss()\n",
    "optimizerA = torch.optim.SGD(resnetA.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizerB = torch.optim.SGD(resnetB.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizerC = torch.optim.SGD(resnetC.parameters(), lr=0.01, momentum=0.9)\n",
    "# optimizerA = torch.optim.AdamW(resnetA.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "# optimizerB = torch.optim.AdamW(resnetB.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "# optimizerC = torch.optim.AdamW(resnetC.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "# exp_lr_schedulerA = lr_scheduler.StepLR(optimizerA, step_size=5, gamma=0.01)\n",
    "# exp_lr_schedulerB = lr_scheduler.StepLR(optimizerB, step_size=5, gamma=0.01)\n",
    "# exp_lr_schedulerC = lr_scheduler.StepLR(optimizerC, step_size=5, gamma=0.2)\n",
    "exp_lr_schedulerA = lr_scheduler.ReduceLROnPlateau(optimizerA, 'min', factor=0.90, patience=500)\n",
    "exp_lr_schedulerB = lr_scheduler.ReduceLROnPlateau(optimizerB, 'min', factor=0.90, patience=500)\n",
    "exp_lr_schedulerC = lr_scheduler.ReduceLROnPlateau(optimizerC, 'min', factor=0.90, patience=500)\n",
    "\n",
    "\n",
    "def hwout(Hin, padding, dilation, kernel_size, stride):\n",
    "    return (Hin + 2 * padding - dilation * (kernel_size-1) - 1)/stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_layer = 0\n",
    "max_neurons = 0\n",
    "for prm in resnetC.named_parameters():\n",
    "    num_ftr = np.prod(prm[1].shape)\n",
    "    if num_ftr > max_neurons:\n",
    "         max_neurons = num_ftr\n",
    "         max_layer = prm[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1.weight',\n",
       " 'bn1.weight',\n",
       " 'bn1.bias',\n",
       " 'layer1.0.conv1.weight',\n",
       " 'layer1.0.bn1.weight',\n",
       " 'layer1.0.bn1.bias',\n",
       " 'layer1.0.conv2.weight',\n",
       " 'layer1.0.bn2.weight',\n",
       " 'layer1.0.bn2.bias',\n",
       " 'layer1.1.conv1.weight',\n",
       " 'layer1.1.bn1.weight',\n",
       " 'layer1.1.bn1.bias',\n",
       " 'layer1.1.conv2.weight',\n",
       " 'layer1.1.bn2.weight',\n",
       " 'layer1.1.bn2.bias',\n",
       " 'layer2.0.conv1.weight',\n",
       " 'layer2.0.bn1.weight',\n",
       " 'layer2.0.bn1.bias',\n",
       " 'layer2.0.conv2.weight',\n",
       " 'layer2.0.bn2.weight',\n",
       " 'layer2.0.bn2.bias',\n",
       " 'layer2.0.downsample.0.weight',\n",
       " 'layer2.0.downsample.1.weight',\n",
       " 'layer2.0.downsample.1.bias',\n",
       " 'layer2.1.conv1.weight',\n",
       " 'layer2.1.bn1.weight',\n",
       " 'layer2.1.bn1.bias',\n",
       " 'layer2.1.conv2.weight',\n",
       " 'layer2.1.bn2.weight',\n",
       " 'layer2.1.bn2.bias',\n",
       " 'layer3.0.conv1.weight',\n",
       " 'layer3.0.bn1.weight',\n",
       " 'layer3.0.bn1.bias',\n",
       " 'layer3.0.conv2.weight',\n",
       " 'layer3.0.bn2.weight',\n",
       " 'layer3.0.bn2.bias',\n",
       " 'layer3.0.downsample.0.weight',\n",
       " 'layer3.0.downsample.1.weight',\n",
       " 'layer3.0.downsample.1.bias',\n",
       " 'layer3.1.conv1.weight',\n",
       " 'layer3.1.bn1.weight',\n",
       " 'layer3.1.bn1.bias',\n",
       " 'layer3.1.conv2.weight',\n",
       " 'layer3.1.bn2.weight',\n",
       " 'layer3.1.bn2.bias',\n",
       " 'layer4.0.conv1.weight',\n",
       " 'layer4.0.bn1.weight',\n",
       " 'layer4.0.bn1.bias',\n",
       " 'layer4.0.conv2.weight',\n",
       " 'layer4.0.bn2.weight',\n",
       " 'layer4.0.bn2.bias',\n",
       " 'layer4.0.downsample.0.weight',\n",
       " 'layer4.0.downsample.1.weight',\n",
       " 'layer4.0.downsample.1.bias',\n",
       " 'layer4.1.conv1.weight',\n",
       " 'layer4.1.bn1.weight',\n",
       " 'layer4.1.bn1.bias',\n",
       " 'layer4.1.conv2.weight',\n",
       " 'layer4.1.bn2.weight',\n",
       " 'layer4.1.bn2.bias',\n",
       " 'fc.weight',\n",
       " 'fc.bias']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in resnetC.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "mdlzAC = dict()\n",
    "mdlzAB = dict()\n",
    "mdlzBA = dict()\n",
    "params = []\n",
    "model_dir = './multi_model_chain'\n",
    "conv_layers = ['layer4.1.conv1.weight', 'layer4.0.conv1.weight']\n",
    "bn_layers = ['fc.weight']\n",
    "\n",
    "for prm in resnetC.named_parameters():\n",
    "# for prm in temp_list:\n",
    "#     if 'conv' in prm[0] or 'fc' in prm[0] or 'bn' in prm[0] or 'downsample' in prm[0]:\n",
    "    if prm[0] in bn_layers+conv_layers:\n",
    "        try:\n",
    "            if prm[1].dim() > 2:\n",
    "#                 if prm[0] not in conv_layers:\n",
    "#                     continue\n",
    "                mdl = Decenter_conv(prm[1].shape).to(device)\n",
    "                optimizer = torch.optim.AdamW(mdl.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "                exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5)\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.1,\n",
    "                            'patience': 5,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'A')\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.1,\n",
    "                            'patience': 5,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'B')\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.1,\n",
    "                            'patience': 5,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'C')\n",
    "                mdlzAC[prm[0]] = (model_dir + '/' + prm[0]+'A', Decenter_conv)\n",
    "                mdlzAB[prm[0]] = (model_dir + '/' + prm[0]+'B', Decenter_conv)\n",
    "                mdlzBA[prm[0]] = (model_dir + '/' + prm[0]+'C', Decenter_conv)\n",
    "#                 params += mdl.parameters()\n",
    "#                 pass\n",
    "            else:\n",
    "#                 if prm[0] not in bn_layers:\n",
    "#                     continue\n",
    "                mdl = Decenter(prm[1].shape).to(device)\n",
    "                optimizer = torch.optim.AdamW(mdl.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "                exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=1)\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.5,\n",
    "                            'patience': 1,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'A')\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.5,\n",
    "                            'patience': 1,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'B')\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.5,\n",
    "                            'patience': 1,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'C')\n",
    "                mdlzAC[prm[0]] = (model_dir + '/' + prm[0]+'A', Decenter)\n",
    "                mdlzAB[prm[0]] = (model_dir + '/' + prm[0]+'B', Decenter)\n",
    "                mdlzBA[prm[0]] = (model_dir + '/' + prm[0]+'C', Decenter)\n",
    "#                 params += mdl.parameters()\n",
    "            \n",
    "            del mdl\n",
    "            torch.cuda.empty_cache()\n",
    "        except Exception as e:\n",
    "            print(\"Problem with: \" + prm[0] + \" Size: \" + str(num_ftr))\n",
    "            print(\"Error: \" + str(e))\n",
    "            traceback.print_exc()\n",
    "            print()\n",
    "            pass\n",
    "        \n",
    "# params += list(resnetC.parameters())\n",
    "\n",
    "# optimizerRB = torch.optim.SGD(params, lr=0.01, momentum=0.9)\n",
    "optimizerRC = torch.optim.AdamW(resnetC.parameters(), lr=0.001, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer4.0.conv1.weight': ('./multi_model_chain/layer4.0.conv1.weightA',\n",
       "  __main__.Decenter_conv),\n",
       " 'layer4.1.conv1.weight': ('./multi_model_chain/layer4.1.conv1.weightA',\n",
       "  __main__.Decenter_conv),\n",
       " 'fc.weight': ('./multi_model_chain/fc.weightA', __main__.Decenter)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdlzAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define phases \n",
    "dloaders = {'trainA':trainsetLoader1, 'trainB':reservedLoaderB, 'trainC':reservedLoader,\n",
    "            'validA':testsetLoader, 'validB':testsetLoader, 'validC':testsetLoader,\n",
    "            'reservedA':reservedLoader, 'reservedB':reservedLoader, 'reservedCA':reservedLoader, 'reservedAB':reservedLoader, 'reservedBA':reservedLoaderB}\n",
    "model = {'trainA':resnetA, 'trainB':resnetB, 'trainC':resnetC,\n",
    "         'validA':resnetA, 'validB':resnetB, 'validC':resnetC,\n",
    "         'reservedA':resnetA, 'reservedB':resnetB, 'reservedCA':resnetC, 'reservedAB':resnetA, 'reservedBA':resnetB}\n",
    "optimizer = {'trainA':optimizerA, 'trainB':optimizerB, 'trainC':optimizerC,\n",
    "             'validA':optimizerA, 'validB':optimizerB, 'validC':optimizerC,\n",
    "             'reservedA':optimizerA, 'reservedB':optimizerB, 'reservedCA':optimizerC, 'reservedAB':optimizerA, 'reservedBA':optimizerB}\n",
    "criterion = {'trainA':criterionA, 'trainB':criterionA, 'trainC':criterionA,\n",
    "             'validA':criterionA, 'validB':criterionA, 'validC':criterionA,\n",
    "             'reservedA':criterionB, 'reservedB':criterionB, 'reservedCA':criterionB, 'reservedAB':criterionB, 'reservedBA':criterionB}\n",
    "exp_lr_scheduler = {'trainA':exp_lr_schedulerA, 'trainB':exp_lr_schedulerB, 'trainC':exp_lr_schedulerC,\n",
    "             'validA':exp_lr_schedulerA, 'validB':exp_lr_schedulerB, 'validC':exp_lr_schedulerC,\n",
    "             'reservedA':exp_lr_schedulerA, 'reservedB':exp_lr_schedulerB, 'reservedCA':exp_lr_schedulerC, 'reservedAB':exp_lr_schedulerA, 'reservedBA':exp_lr_schedulerB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/199] phase: validA train loss: 0.0037 acc: 0.8232 valid loss: 0.1218 acc: 0.2717\n",
      "\n",
      "Epoch [0/199] phase: validB train loss: 0.0089 acc: 0.5881 valid loss: 0.0210 acc: 0.3272\n",
      "\n",
      "Epoch [0/199] phase: validC train loss: 0.0054 acc: 0.7931 valid loss: 0.0138 acc: 0.4629\n",
      "\n",
      "Epoch [0/199] phase: validC train loss: -0.0013 acc: 0.8448 valid loss: 0.0121 acc: 0.5033\n",
      "\n",
      "Epoch [1/199] phase: validA train loss: 0.0019 acc: 0.9114 valid loss: 0.1046 acc: 0.2785\n",
      "\n",
      "Epoch [1/199] phase: validB train loss: 0.0071 acc: 0.6850 valid loss: 0.0140 acc: 0.4510\n",
      "\n",
      "Epoch [1/199] phase: validC train loss: 0.0033 acc: 0.8745 valid loss: 0.0114 acc: 0.5385\n",
      "\n",
      "Epoch [1/199] phase: validC train loss: -0.0020 acc: 0.8821 valid loss: 0.0094 acc: 0.6143\n",
      "\n",
      "Epoch [2/199] phase: validA train loss: 0.0014 acc: 0.9327 valid loss: 0.1051 acc: 0.2808\n",
      "\n",
      "Epoch [2/199] phase: validB train loss: 0.0078 acc: 0.6289 valid loss: 0.0171 acc: 0.3584\n",
      "\n",
      "Epoch [2/199] phase: validC train loss: 0.0027 acc: 0.8935 valid loss: 0.0125 acc: 0.5362\n",
      "\n",
      "Epoch [2/199] phase: validC train loss: -0.0021 acc: 0.9025 valid loss: 0.0097 acc: 0.6405\n",
      "\n",
      "Epoch [3/199] phase: validA train loss: 0.0014 acc: 0.9369 valid loss: 0.1111 acc: 0.2796\n",
      "\n",
      "Epoch [3/199] phase: validB train loss: 0.0065 acc: 0.6962 valid loss: 0.0127 acc: 0.4863\n",
      "\n",
      "Epoch [3/199] phase: validC train loss: 0.0024 acc: 0.9057 valid loss: 0.0113 acc: 0.5885\n",
      "\n",
      "Epoch [3/199] phase: validC train loss: -0.0022 acc: 0.9140 valid loss: 0.0101 acc: 0.6251\n",
      "\n",
      "Epoch [4/199] phase: validA train loss: 0.0011 acc: 0.9450 valid loss: 0.1027 acc: 0.2833\n",
      "\n",
      "Epoch [4/199] phase: validB train loss: 0.0062 acc: 0.7156 valid loss: 0.0121 acc: 0.5070\n",
      "\n",
      "Epoch [4/199] phase: validC train loss: 0.0021 acc: 0.9148 valid loss: 0.0107 acc: 0.6134\n",
      "\n",
      "Epoch [4/199] phase: validC train loss: -0.0021 acc: 0.9239 valid loss: 0.0096 acc: 0.6544\n",
      "\n",
      "Epoch [5/199] phase: validA train loss: 0.0010 acc: 0.9539 valid loss: 0.1048 acc: 0.2848\n",
      "\n",
      "Epoch [5/199] phase: validB train loss: 0.0056 acc: 0.7364 valid loss: 0.0134 acc: 0.4916\n",
      "\n",
      "Epoch [5/199] phase: validC train loss: 0.0020 acc: 0.9210 valid loss: 0.0108 acc: 0.6383\n",
      "\n",
      "Epoch [5/199] phase: validC train loss: -0.0023 acc: 0.9269 valid loss: 0.0089 acc: 0.6864\n",
      "\n",
      "Epoch [6/199] phase: validA train loss: 0.0009 acc: 0.9558 valid loss: 0.1037 acc: 0.2841\n",
      "\n",
      "Epoch [6/199] phase: validB train loss: 0.0054 acc: 0.7560 valid loss: 0.0111 acc: 0.5861\n",
      "\n",
      "Epoch [6/199] phase: validC train loss: 0.0018 acc: 0.9273 valid loss: 0.0111 acc: 0.6368\n",
      "\n",
      "Epoch [6/199] phase: validC train loss: -0.0023 acc: 0.9359 valid loss: 0.0090 acc: 0.6970\n",
      "\n",
      "Epoch [7/199] phase: validA train loss: 0.0009 acc: 0.9578 valid loss: 0.1079 acc: 0.2832\n",
      "\n",
      "Epoch [7/199] phase: validB train loss: 0.0045 acc: 0.7900 valid loss: 0.0102 acc: 0.6197\n",
      "\n",
      "Epoch [7/199] phase: validC train loss: 0.0017 acc: 0.9315 valid loss: 0.0115 acc: 0.6241\n",
      "\n",
      "Epoch [7/199] phase: validC train loss: -0.0033 acc: 0.9383 valid loss: 0.0085 acc: 0.6983\n",
      "\n",
      "Epoch [8/199] phase: validA train loss: 0.0007 acc: 0.9649 valid loss: 0.1340 acc: 0.2842\n",
      "\n",
      "Epoch [8/199] phase: validB train loss: 0.0052 acc: 0.7885 valid loss: 0.0102 acc: 0.5869\n",
      "\n",
      "Epoch [8/199] phase: validC train loss: 0.0015 acc: 0.9402 valid loss: 0.0099 acc: 0.6620\n",
      "\n",
      "Epoch [8/199] phase: validC train loss: -0.0033 acc: 0.9459 valid loss: 0.0087 acc: 0.7126\n",
      "\n",
      "Epoch [9/199] phase: validA train loss: 0.0008 acc: 0.9629 valid loss: 0.1220 acc: 0.2848\n",
      "\n",
      "Epoch [9/199] phase: validB train loss: 0.0051 acc: 0.7938 valid loss: 0.0100 acc: 0.5948\n",
      "\n",
      "Epoch [9/199] phase: validC train loss: 0.0014 acc: 0.9415 valid loss: 0.0092 acc: 0.6847\n",
      "\n",
      "Epoch [9/199] phase: validC train loss: -0.0035 acc: 0.9499 valid loss: 0.0097 acc: 0.6889\n",
      "\n",
      "Epoch [10/199] phase: validA train loss: 0.0007 acc: 0.9664 valid loss: 0.1122 acc: 0.2850\n",
      "\n",
      "Epoch [10/199] phase: validB train loss: 0.0051 acc: 0.7937 valid loss: 0.0104 acc: 0.5818\n",
      "\n",
      "Epoch [10/199] phase: validC train loss: 0.0013 acc: 0.9479 valid loss: 0.0122 acc: 0.6182\n",
      "\n",
      "Epoch [10/199] phase: validC train loss: -0.0034 acc: 0.9523 valid loss: 0.0092 acc: 0.7048\n",
      "\n",
      "Epoch [11/199] phase: validA train loss: 0.0006 acc: 0.9725 valid loss: 0.1295 acc: 0.2863\n",
      "\n",
      "Epoch [11/199] phase: validB train loss: 0.0051 acc: 0.7917 valid loss: 0.0106 acc: 0.5751\n",
      "\n",
      "Epoch [11/199] phase: validC train loss: 0.0012 acc: 0.9498 valid loss: 0.0100 acc: 0.6837\n",
      "\n",
      "Epoch [11/199] phase: validC train loss: -0.0034 acc: 0.9549 valid loss: 0.0093 acc: 0.7086\n",
      "\n",
      "Epoch [12/199] phase: validA train loss: 0.0006 acc: 0.9706 valid loss: 0.1343 acc: 0.2840\n",
      "\n",
      "Epoch [12/199] phase: validB train loss: 0.0050 acc: 0.7986 valid loss: 0.0110 acc: 0.5483\n",
      "\n",
      "Epoch [12/199] phase: validC train loss: 0.0012 acc: 0.9534 valid loss: 0.0125 acc: 0.6302\n",
      "\n",
      "Epoch [12/199] phase: validC train loss: -0.0034 acc: 0.9584 valid loss: 0.0098 acc: 0.6985\n",
      "\n",
      "Epoch [13/199] phase: validA train loss: 0.0005 acc: 0.9751 valid loss: 0.1083 acc: 0.2847\n",
      "\n",
      "Epoch [13/199] phase: validB train loss: 0.0054 acc: 0.7922 valid loss: 0.0102 acc: 0.5745\n",
      "\n",
      "Epoch [13/199] phase: validC train loss: 0.0011 acc: 0.9546 valid loss: 0.0104 acc: 0.6863\n",
      "\n",
      "Epoch [13/199] phase: validC train loss: -0.0037 acc: 0.9617 valid loss: 0.0102 acc: 0.6971\n",
      "\n",
      "Epoch [14/199] phase: validA train loss: 0.0005 acc: 0.9752 valid loss: 0.1108 acc: 0.2856\n",
      "\n",
      "Epoch [14/199] phase: validB train loss: 0.0080 acc: 0.7349 valid loss: 0.0109 acc: 0.5454\n",
      "\n",
      "Epoch [14/199] phase: validC train loss: 0.0010 acc: 0.9600 valid loss: 0.0109 acc: 0.6685\n",
      "\n",
      "Epoch [14/199] phase: validC train loss: -0.0038 acc: 0.9667 valid loss: 0.0097 acc: 0.7174\n",
      "\n",
      "Epoch [15/199] phase: validA train loss: 0.0005 acc: 0.9762 valid loss: 0.1083 acc: 0.2836\n",
      "\n",
      "Epoch [15/199] phase: validB train loss: 0.0081 acc: 0.7345 valid loss: 0.0110 acc: 0.5455\n",
      "\n",
      "Epoch [15/199] phase: validC train loss: 0.0010 acc: 0.9574 valid loss: 0.0114 acc: 0.6644\n",
      "\n",
      "Epoch [15/199] phase: validC train loss: -0.0038 acc: 0.9677 valid loss: 0.0098 acc: 0.7122\n",
      "\n",
      "Epoch [16/199] phase: validA train loss: 0.0005 acc: 0.9782 valid loss: 0.1066 acc: 0.2844\n",
      "\n",
      "Epoch [16/199] phase: validB train loss: 0.0081 acc: 0.7351 valid loss: 0.0111 acc: 0.5392\n",
      "\n",
      "Epoch [16/199] phase: validC train loss: 0.0009 acc: 0.9609 valid loss: 0.0124 acc: 0.6453\n",
      "\n",
      "Epoch [16/199] phase: validC train loss: -0.0036 acc: 0.9655 valid loss: 0.0112 acc: 0.6929\n",
      "\n",
      "Epoch [17/199] phase: validA train loss: 0.0004 acc: 0.9793 valid loss: 0.1250 acc: 0.2865\n",
      "\n",
      "Epoch [17/199] phase: validB train loss: 0.0080 acc: 0.7320 valid loss: 0.0108 acc: 0.5548\n",
      "\n",
      "Epoch [17/199] phase: validC train loss: 0.0009 acc: 0.9631 valid loss: 0.0105 acc: 0.6819\n",
      "\n",
      "Epoch [17/199] phase: validC train loss: -0.0037 acc: 0.9701 valid loss: 0.0105 acc: 0.7052\n",
      "\n",
      "Epoch [18/199] phase: validA train loss: 0.0004 acc: 0.9788 valid loss: 0.1125 acc: 0.2870\n",
      "\n",
      "Epoch [18/199] phase: validB train loss: 0.0081 acc: 0.7359 valid loss: 0.0109 acc: 0.5507\n",
      "\n",
      "Epoch [18/199] phase: validC train loss: 0.0008 acc: 0.9668 valid loss: 0.0103 acc: 0.7010\n",
      "\n",
      "Epoch [18/199] phase: validC train loss: -0.0038 acc: 0.9724 valid loss: 0.0103 acc: 0.7034\n",
      "\n",
      "Epoch [19/199] phase: validA train loss: 0.0004 acc: 0.9806 valid loss: 0.1298 acc: 0.2870\n",
      "\n",
      "Epoch [19/199] phase: validB train loss: 0.0082 acc: 0.7270 valid loss: 0.0109 acc: 0.5541\n",
      "\n",
      "Epoch [19/199] phase: validC train loss: 0.0008 acc: 0.9681 valid loss: 0.0106 acc: 0.7013\n",
      "\n",
      "Epoch [19/199] phase: validC train loss: -0.0037 acc: 0.9743 valid loss: 0.0107 acc: 0.7004\n",
      "\n",
      "Epoch [20/199] phase: validA train loss: 0.0004 acc: 0.9833 valid loss: 0.1255 acc: 0.2872\n",
      "\n",
      "Epoch [20/199] phase: validB train loss: 0.0082 acc: 0.7291 valid loss: 0.0109 acc: 0.5439\n",
      "\n",
      "Epoch [20/199] phase: validC train loss: 0.0007 acc: 0.9712 valid loss: 0.0120 acc: 0.6749\n",
      "\n",
      "Epoch [20/199] phase: validC train loss: -0.0038 acc: 0.9740 valid loss: 0.0108 acc: 0.7065\n",
      "\n",
      "Epoch [21/199] phase: validA train loss: 0.0003 acc: 0.9831 valid loss: 0.1193 acc: 0.2860\n",
      "\n",
      "Epoch [21/199] phase: validB train loss: 0.0082 acc: 0.7312 valid loss: 0.0106 acc: 0.5700\n",
      "\n",
      "Epoch [21/199] phase: validC train loss: 0.0007 acc: 0.9705 valid loss: 0.0123 acc: 0.6651\n",
      "\n",
      "Epoch [21/199] phase: validC train loss: -0.0038 acc: 0.9765 valid loss: 0.0104 acc: 0.7094\n",
      "\n",
      "Epoch [22/199] phase: validA train loss: 0.0003 acc: 0.9827 valid loss: 0.1337 acc: 0.2866\n",
      "\n",
      "Epoch [22/199] phase: validB train loss: 0.0082 acc: 0.7299 valid loss: 0.0108 acc: 0.5544\n",
      "\n",
      "Epoch [22/199] phase: validC train loss: 0.0004 acc: 0.9851 valid loss: 0.0104 acc: 0.7110\n",
      "\n",
      "Epoch [22/199] phase: validC train loss: -0.0034 acc: 0.9777 valid loss: 0.0080 acc: 0.6915\n",
      "\n",
      "Epoch [23/199] phase: validA train loss: 0.0004 acc: 0.9826 valid loss: 0.1487 acc: 0.2864\n",
      "\n",
      "Epoch [23/199] phase: validB train loss: 0.0083 acc: 0.7282 valid loss: 0.0112 acc: 0.5396\n",
      "\n",
      "Epoch [23/199] phase: validC train loss: 0.0008 acc: 0.9821 valid loss: 0.0084 acc: 0.6884\n",
      "\n",
      "Epoch [23/199] phase: validC train loss: -0.0034 acc: 0.9778 valid loss: 0.0080 acc: 0.6903\n",
      "\n",
      "Epoch [24/199] phase: validA train loss: 0.0003 acc: 0.9860 valid loss: 0.1257 acc: 0.2862\n",
      "\n",
      "Epoch [24/199] phase: validB train loss: 0.0084 acc: 0.7265 valid loss: 0.0112 acc: 0.5321\n",
      "\n",
      "Epoch [24/199] phase: validC train loss: 0.0009 acc: 0.9831 valid loss: 0.0086 acc: 0.6787\n",
      "\n",
      "Epoch [24/199] phase: validC train loss: -0.0032 acc: 0.9815 valid loss: 0.0078 acc: 0.6969\n",
      "\n",
      "Epoch [25/199] phase: validA train loss: 0.0003 acc: 0.9846 valid loss: 0.1254 acc: 0.2865\n",
      "\n",
      "Epoch [25/199] phase: validB train loss: 0.0085 acc: 0.7253 valid loss: 0.0119 acc: 0.5047\n",
      "\n",
      "Epoch [25/199] phase: validC train loss: 0.0009 acc: 0.9839 valid loss: 0.0086 acc: 0.6812\n",
      "\n",
      "Epoch [25/199] phase: validC train loss: -0.0035 acc: 0.9813 valid loss: 0.0079 acc: 0.6935\n",
      "\n",
      "Epoch [26/199] phase: validA train loss: 0.0003 acc: 0.9880 valid loss: 0.1267 acc: 0.2872\n",
      "\n",
      "Epoch [26/199] phase: validB train loss: 0.0085 acc: 0.7266 valid loss: 0.0112 acc: 0.5343\n",
      "\n",
      "Epoch [26/199] phase: validC train loss: 0.0009 acc: 0.9836 valid loss: 0.0085 acc: 0.6851\n",
      "\n",
      "Epoch [26/199] phase: validC train loss: -0.0033 acc: 0.9821 valid loss: 0.0078 acc: 0.6999\n",
      "\n",
      "Epoch [27/199] phase: validA train loss: 0.0003 acc: 0.9857 valid loss: 0.1283 acc: 0.2869\n",
      "\n",
      "Epoch [27/199] phase: validB train loss: 0.0084 acc: 0.7267 valid loss: 0.0113 acc: 0.5187\n",
      "\n",
      "Epoch [27/199] phase: validC train loss: 0.0008 acc: 0.9852 valid loss: 0.0085 acc: 0.6847\n",
      "\n",
      "Epoch [27/199] phase: validC train loss: -0.0034 acc: 0.9842 valid loss: 0.0078 acc: 0.6973\n",
      "\n",
      "Epoch [28/199] phase: validA train loss: 0.0002 acc: 0.9888 valid loss: 0.1357 acc: 0.2872\n",
      "\n",
      "Epoch [28/199] phase: validB train loss: 0.0084 acc: 0.7242 valid loss: 0.0115 acc: 0.5173\n",
      "\n",
      "Epoch [28/199] phase: validC train loss: 0.0010 acc: 0.9833 valid loss: 0.0078 acc: 0.6975\n",
      "\n",
      "Epoch [28/199] phase: validC train loss: -0.0031 acc: 0.9766 valid loss: 0.0073 acc: 0.7194\n",
      "\n",
      "Epoch [29/199] phase: validA train loss: 0.0003 acc: 0.9887 valid loss: 0.1258 acc: 0.2868\n",
      "\n",
      "Epoch [29/199] phase: validB train loss: 0.0084 acc: 0.7306 valid loss: 0.0113 acc: 0.5292\n",
      "\n",
      "Epoch [29/199] phase: validC train loss: 0.0022 acc: 0.9747 valid loss: 0.0074 acc: 0.7168\n",
      "\n",
      "Epoch [29/199] phase: validC train loss: -0.0030 acc: 0.9730 valid loss: 0.0073 acc: 0.7241\n",
      "\n",
      "Epoch [30/199] phase: validA train loss: 0.0003 acc: 0.9869 valid loss: 0.1267 acc: 0.2877\n",
      "\n",
      "Epoch [30/199] phase: validB train loss: 0.0085 acc: 0.7189 valid loss: 0.0114 acc: 0.5252\n",
      "\n",
      "Epoch [30/199] phase: validC train loss: 0.0023 acc: 0.9739 valid loss: 0.0073 acc: 0.7196\n",
      "\n",
      "Epoch [30/199] phase: validC train loss: -0.0031 acc: 0.9735 valid loss: 0.0072 acc: 0.7250\n",
      "\n",
      "Epoch [31/199] phase: validA train loss: 0.0003 acc: 0.9879 valid loss: 0.1366 acc: 0.2871\n",
      "\n",
      "Epoch [31/199] phase: validB train loss: 0.0085 acc: 0.7289 valid loss: 0.0117 acc: 0.5073\n",
      "\n",
      "Epoch [31/199] phase: validC train loss: 0.0023 acc: 0.9751 valid loss: 0.0073 acc: 0.7244\n",
      "\n",
      "Epoch [31/199] phase: validC train loss: -0.0030 acc: 0.9727 valid loss: 0.0073 acc: 0.7202\n",
      "\n",
      "Epoch [32/199] phase: validA train loss: 0.0003 acc: 0.9868 valid loss: 0.1370 acc: 0.2867\n",
      "\n",
      "Epoch [32/199] phase: validB train loss: 0.0084 acc: 0.7265 valid loss: 0.0112 acc: 0.5291\n",
      "\n",
      "Epoch [32/199] phase: validC train loss: 0.0023 acc: 0.9740 valid loss: 0.0074 acc: 0.7176\n",
      "\n",
      "Epoch [32/199] phase: validC train loss: -0.0029 acc: 0.9738 valid loss: 0.0073 acc: 0.7245\n",
      "\n",
      "Epoch [33/199] phase: validA train loss: 0.0002 acc: 0.9893 valid loss: 0.1318 acc: 0.2888\n",
      "\n",
      "Epoch [33/199] phase: validB train loss: 0.0084 acc: 0.7239 valid loss: 0.0114 acc: 0.5219\n",
      "\n",
      "Epoch [33/199] phase: validC train loss: 0.0023 acc: 0.9740 valid loss: 0.0073 acc: 0.7206\n",
      "\n",
      "Epoch [33/199] phase: validC train loss: -0.0028 acc: 0.9731 valid loss: 0.0074 acc: 0.7198\n",
      "\n",
      "Epoch [34/199] phase: validA train loss: 0.0002 acc: 0.9902 valid loss: 0.1256 acc: 0.2866\n",
      "\n",
      "Epoch [34/199] phase: validB train loss: 0.0085 acc: 0.7227 valid loss: 0.0113 acc: 0.5311\n",
      "\n",
      "Epoch [34/199] phase: validC train loss: 0.0023 acc: 0.9747 valid loss: 0.0073 acc: 0.7209\n",
      "\n",
      "Epoch [34/199] phase: validC train loss: -0.0029 acc: 0.9747 valid loss: 0.0074 acc: 0.7199\n",
      "\n",
      "Epoch [35/199] phase: validA train loss: 0.0002 acc: 0.9892 valid loss: 0.1334 acc: 0.2871\n",
      "\n",
      "Epoch [35/199] phase: validB train loss: 0.0084 acc: 0.7279 valid loss: 0.0113 acc: 0.5271\n",
      "\n",
      "Epoch [35/199] phase: validC train loss: 0.0023 acc: 0.9724 valid loss: 0.0074 acc: 0.7177\n",
      "\n",
      "Epoch [35/199] phase: validC train loss: -0.0030 acc: 0.9724 valid loss: 0.0073 acc: 0.7223\n",
      "\n",
      "Epoch [36/199] phase: validA train loss: 0.0002 acc: 0.9903 valid loss: 0.1342 acc: 0.2885\n",
      "\n",
      "Epoch [36/199] phase: validB train loss: 0.0085 acc: 0.7236 valid loss: 0.0112 acc: 0.5296\n",
      "\n",
      "Epoch [36/199] phase: validC train loss: 0.0024 acc: 0.9727 valid loss: 0.0074 acc: 0.7202\n",
      "\n",
      "Epoch [36/199] phase: validC train loss: -0.0029 acc: 0.9707 valid loss: 0.0073 acc: 0.7260\n",
      "\n",
      "Epoch [37/199] phase: validA train loss: 0.0002 acc: 0.9905 valid loss: 0.1342 acc: 0.2860\n",
      "\n",
      "Epoch [37/199] phase: validB train loss: 0.0084 acc: 0.7263 valid loss: 0.0118 acc: 0.4991\n",
      "\n",
      "Epoch [37/199] phase: validC train loss: 0.0023 acc: 0.9748 valid loss: 0.0073 acc: 0.7224\n",
      "\n",
      "Epoch [37/199] phase: validC train loss: -0.0029 acc: 0.9735 valid loss: 0.0074 acc: 0.7222\n",
      "\n",
      "Epoch [38/199] phase: validA train loss: 0.0002 acc: 0.9915 valid loss: 0.1360 acc: 0.2864\n",
      "\n",
      "Epoch [38/199] phase: validB train loss: 0.0085 acc: 0.7264 valid loss: 0.0117 acc: 0.5077\n",
      "\n",
      "Epoch [38/199] phase: validC train loss: 0.0024 acc: 0.9742 valid loss: 0.0073 acc: 0.7221\n",
      "\n",
      "Epoch [38/199] phase: validC train loss: -0.0030 acc: 0.9715 valid loss: 0.0073 acc: 0.7230\n",
      "\n",
      "Epoch [39/199] phase: validA train loss: 0.0002 acc: 0.9894 valid loss: 0.1390 acc: 0.2886\n",
      "\n",
      "Epoch [39/199] phase: validB train loss: 0.0085 acc: 0.7244 valid loss: 0.0115 acc: 0.5099\n",
      "\n",
      "Epoch [39/199] phase: validC train loss: 0.0024 acc: 0.9726 valid loss: 0.0073 acc: 0.7229\n",
      "\n",
      "Epoch [39/199] phase: validC train loss: -0.0028 acc: 0.9719 valid loss: 0.0073 acc: 0.7233\n",
      "\n",
      "Epoch [40/199] phase: validA train loss: 0.0002 acc: 0.9899 valid loss: 0.1256 acc: 0.2873\n",
      "\n",
      "Epoch [40/199] phase: validB train loss: 0.0085 acc: 0.7242 valid loss: 0.0112 acc: 0.5322\n",
      "\n",
      "Epoch [40/199] phase: validC train loss: 0.0024 acc: 0.9707 valid loss: 0.0074 acc: 0.7168\n",
      "\n",
      "Epoch [40/199] phase: validC train loss: -0.0029 acc: 0.9712 valid loss: 0.0073 acc: 0.7239\n",
      "\n",
      "Epoch [41/199] phase: validA train loss: 0.0002 acc: 0.9918 valid loss: 0.1331 acc: 0.2866\n",
      "\n",
      "Epoch [41/199] phase: validB train loss: 0.0085 acc: 0.7230 valid loss: 0.0117 acc: 0.5118\n",
      "\n",
      "Epoch [41/199] phase: validC train loss: 0.0024 acc: 0.9731 valid loss: 0.0073 acc: 0.7208\n",
      "\n",
      "Epoch [41/199] phase: validC train loss: -0.0028 acc: 0.9725 valid loss: 0.0073 acc: 0.7226\n",
      "\n",
      "Epoch [42/199] phase: validA train loss: 0.0001 acc: 0.9939 valid loss: 0.1364 acc: 0.2875\n",
      "\n",
      "Epoch [42/199] phase: validB train loss: 0.0085 acc: 0.7251 valid loss: 0.0113 acc: 0.5334\n",
      "\n",
      "Epoch [42/199] phase: validC train loss: 0.0024 acc: 0.9750 valid loss: 0.0074 acc: 0.7191\n",
      "\n",
      "Epoch [42/199] phase: validC train loss: -0.0030 acc: 0.9723 valid loss: 0.0074 acc: 0.7217\n",
      "\n",
      "Epoch [43/199] phase: validA train loss: 0.0002 acc: 0.9928 valid loss: 0.1399 acc: 0.2882\n",
      "\n",
      "Epoch [43/199] phase: validB train loss: 0.0084 acc: 0.7242 valid loss: 0.0114 acc: 0.5273\n",
      "\n",
      "Epoch [43/199] phase: validC train loss: 0.0024 acc: 0.9716 valid loss: 0.0073 acc: 0.7232\n",
      "\n",
      "Epoch [43/199] phase: validC train loss: -0.0029 acc: 0.9730 valid loss: 0.0073 acc: 0.7231\n",
      "\n",
      "Epoch [44/199] phase: validA train loss: 0.0002 acc: 0.9904 valid loss: 0.1398 acc: 0.2876\n",
      "\n",
      "Epoch [44/199] phase: validB train loss: 0.0085 acc: 0.7234 valid loss: 0.0115 acc: 0.5236\n",
      "\n",
      "Epoch [44/199] phase: validC train loss: 0.0024 acc: 0.9728 valid loss: 0.0073 acc: 0.7212\n",
      "\n",
      "Epoch [44/199] phase: validC train loss: -0.0028 acc: 0.9711 valid loss: 0.0073 acc: 0.7246\n",
      "\n",
      "Epoch [45/199] phase: validA train loss: 0.0002 acc: 0.9919 valid loss: 0.1281 acc: 0.2888\n",
      "\n",
      "Epoch [45/199] phase: validB train loss: 0.0084 acc: 0.7264 valid loss: 0.0114 acc: 0.5194\n",
      "\n",
      "Epoch [45/199] phase: validC train loss: 0.0024 acc: 0.9728 valid loss: 0.0073 acc: 0.7204\n",
      "\n",
      "Epoch [45/199] phase: validC train loss: -0.0029 acc: 0.9715 valid loss: 0.0074 acc: 0.7181\n",
      "\n",
      "Epoch [46/199] phase: validA train loss: 0.0001 acc: 0.9933 valid loss: 0.1380 acc: 0.2881\n",
      "\n",
      "Epoch [46/199] phase: validB train loss: 0.0085 acc: 0.7219 valid loss: 0.0115 acc: 0.5244\n",
      "\n",
      "Epoch [46/199] phase: validC train loss: 0.0024 acc: 0.9720 valid loss: 0.0073 acc: 0.7232\n",
      "\n",
      "Epoch [46/199] phase: validC train loss: -0.0029 acc: 0.9728 valid loss: 0.0073 acc: 0.7212\n",
      "\n",
      "Epoch [47/199] phase: validA train loss: 0.0001 acc: 0.9941 valid loss: 0.1408 acc: 0.2882\n",
      "\n",
      "Epoch [47/199] phase: validB train loss: 0.0085 acc: 0.7197 valid loss: 0.0115 acc: 0.5222\n",
      "\n",
      "Epoch [47/199] phase: validC train loss: 0.0024 acc: 0.9714 valid loss: 0.0073 acc: 0.7235\n",
      "\n",
      "Epoch [47/199] phase: validC train loss: -0.0028 acc: 0.9698 valid loss: 0.0073 acc: 0.7237\n",
      "\n",
      "Epoch [48/199] phase: validA train loss: 0.0001 acc: 0.9937 valid loss: 0.1345 acc: 0.2852\n",
      "\n",
      "Epoch [48/199] phase: validB train loss: 0.0085 acc: 0.7188 valid loss: 0.0117 acc: 0.5132\n",
      "\n",
      "Epoch [48/199] phase: validC train loss: 0.0024 acc: 0.9718 valid loss: 0.0072 acc: 0.7245\n",
      "\n",
      "Epoch [48/199] phase: validC train loss: -0.0029 acc: 0.9693 valid loss: 0.0072 acc: 0.7249\n",
      "\n",
      "Epoch [49/199] phase: validA train loss: 0.0001 acc: 0.9933 valid loss: 0.1531 acc: 0.2853\n",
      "\n",
      "Epoch [49/199] phase: validB train loss: 0.0085 acc: 0.7222 valid loss: 0.0120 acc: 0.4937\n",
      "\n",
      "Epoch [49/199] phase: validC train loss: 0.0024 acc: 0.9735 valid loss: 0.0073 acc: 0.7227\n",
      "\n",
      "Epoch [49/199] phase: validC train loss: -0.0028 acc: 0.9715 valid loss: 0.0073 acc: 0.7238\n",
      "\n",
      "Epoch [50/199] phase: validA train loss: 0.0002 acc: 0.9939 valid loss: 0.1520 acc: 0.2883\n",
      "\n",
      "Epoch [50/199] phase: validB train loss: 0.0085 acc: 0.7226 valid loss: 0.0113 acc: 0.5238\n",
      "\n",
      "Epoch [50/199] phase: validC train loss: 0.0024 acc: 0.9719 valid loss: 0.0073 acc: 0.7234\n",
      "\n",
      "Epoch [50/199] phase: validC train loss: -0.0027 acc: 0.9710 valid loss: 0.0074 acc: 0.7162\n",
      "\n",
      "Epoch [51/199] phase: validA train loss: 0.0002 acc: 0.9922 valid loss: 0.1407 acc: 0.2885\n",
      "\n",
      "Epoch [51/199] phase: validB train loss: 0.0085 acc: 0.7201 valid loss: 0.0115 acc: 0.5203\n",
      "\n",
      "Epoch [51/199] phase: validC train loss: 0.0024 acc: 0.9702 valid loss: 0.0073 acc: 0.7233\n",
      "\n",
      "Epoch [51/199] phase: validC train loss: -0.0027 acc: 0.9719 valid loss: 0.0073 acc: 0.7210\n",
      "\n",
      "Epoch [52/199] phase: validA train loss: 0.0002 acc: 0.9916 valid loss: 0.1440 acc: 0.2870\n",
      "\n",
      "Epoch [52/199] phase: validB train loss: 0.0085 acc: 0.7256 valid loss: 0.0117 acc: 0.5119\n",
      "\n",
      "Epoch [52/199] phase: validC train loss: 0.0024 acc: 0.9706 valid loss: 0.0073 acc: 0.7208\n",
      "\n",
      "Epoch [52/199] phase: validC train loss: -0.0029 acc: 0.9719 valid loss: 0.0073 acc: 0.7199\n",
      "\n",
      "Epoch [53/199] phase: validA train loss: 0.0002 acc: 0.9908 valid loss: 0.1334 acc: 0.2877\n",
      "\n",
      "Epoch [53/199] phase: validB train loss: 0.0085 acc: 0.7237 valid loss: 0.0116 acc: 0.5180\n",
      "\n",
      "Epoch [53/199] phase: validC train loss: 0.0024 acc: 0.9725 valid loss: 0.0072 acc: 0.7243\n",
      "\n",
      "Epoch [53/199] phase: validC train loss: -0.0028 acc: 0.9708 valid loss: 0.0073 acc: 0.7206\n",
      "\n",
      "Epoch [54/199] phase: validA train loss: 0.0001 acc: 0.9932 valid loss: 0.1417 acc: 0.2870\n",
      "\n",
      "Epoch [54/199] phase: validB train loss: 0.0085 acc: 0.7206 valid loss: 0.0114 acc: 0.5218\n",
      "\n",
      "Epoch [54/199] phase: validC train loss: 0.0024 acc: 0.9732 valid loss: 0.0073 acc: 0.7231\n",
      "\n",
      "Epoch [54/199] phase: validC train loss: -0.0028 acc: 0.9718 valid loss: 0.0073 acc: 0.7212\n",
      "\n",
      "Epoch [55/199] phase: validA train loss: 0.0002 acc: 0.9927 valid loss: 0.1513 acc: 0.2874\n",
      "\n",
      "Epoch [55/199] phase: validB train loss: 0.0085 acc: 0.7204 valid loss: 0.0117 acc: 0.5031\n",
      "\n",
      "Epoch [55/199] phase: validC train loss: 0.0024 acc: 0.9704 valid loss: 0.0073 acc: 0.7226\n",
      "\n",
      "Epoch [55/199] phase: validC train loss: -0.0028 acc: 0.9715 valid loss: 0.0073 acc: 0.7203\n",
      "\n",
      "Epoch [56/199] phase: validA train loss: 0.0001 acc: 0.9944 valid loss: 0.1378 acc: 0.2868\n",
      "\n",
      "Epoch [56/199] phase: validB train loss: 0.0085 acc: 0.7247 valid loss: 0.0116 acc: 0.5205\n",
      "\n",
      "Epoch [56/199] phase: validC train loss: 0.0023 acc: 0.9737 valid loss: 0.0073 acc: 0.7202\n",
      "\n",
      "Epoch [56/199] phase: validC train loss: -0.0028 acc: 0.9702 valid loss: 0.0073 acc: 0.7221\n",
      "\n",
      "Epoch [57/199] phase: validA train loss: 0.0001 acc: 0.9943 valid loss: 0.1390 acc: 0.2868\n",
      "\n",
      "Epoch [57/199] phase: validB train loss: 0.0085 acc: 0.7208 valid loss: 0.0116 acc: 0.5137\n",
      "\n",
      "Epoch [57/199] phase: validC train loss: 0.0024 acc: 0.9727 valid loss: 0.0073 acc: 0.7205\n",
      "\n",
      "Epoch [57/199] phase: validC train loss: -0.0029 acc: 0.9729 valid loss: 0.0074 acc: 0.7182\n",
      "\n",
      "Epoch [58/199] phase: validA train loss: 0.0001 acc: 0.9937 valid loss: 0.1346 acc: 0.2871\n",
      "\n",
      "Epoch [58/199] phase: validB train loss: 0.0085 acc: 0.7229 valid loss: 0.0115 acc: 0.5157\n",
      "\n",
      "Epoch [58/199] phase: validC train loss: 0.0023 acc: 0.9711 valid loss: 0.0073 acc: 0.7228\n",
      "\n",
      "Epoch [58/199] phase: validC train loss: -0.0028 acc: 0.9706 valid loss: 0.0073 acc: 0.7228\n",
      "\n",
      "Epoch [59/199] phase: validA train loss: 0.0001 acc: 0.9953 valid loss: 0.1524 acc: 0.2873\n",
      "\n",
      "Epoch [59/199] phase: validB train loss: 0.0085 acc: 0.7209 valid loss: 0.0119 acc: 0.5035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"#### bn acti conv and fc - unlimited bn - adam learning rate 0.001 - scheduler 20 - opt adamw ####\")\n",
    "\n",
    "start_time = time.time()\n",
    "model = train_model(dloaders, model, criterion, optimizer, exp_lr_scheduler, num_epochs=200)\n",
    "print('Training time: {:10f} minutes'.format((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test funciton on conv layers\n",
    "\n",
    "A = list(resnetA.named_parameters())[-14][1]\n",
    "B = list(resnetB.named_parameters())[-14][1]\n",
    "x = torch.cat((A, B), 1)\n",
    "x.shape\n",
    "\n",
    "pool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "inter = Interpolate(size=(1), mode='bilinear')\n",
    "\n",
    "px = pool(x)\n",
    "ix = inter(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = b = list(resnetC.named_parameters())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 7, 7])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.cat((a, b, b), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 9, 7, 7])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 7, 7])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.nn.AdaptiveAvgPool2d((7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = torch.nn.Conv2d(9, 3, 3, stride=1, padding=1).to(device)\n",
    "c2 = torch.nn.Conv2d(6, 3, 3, stride=1, padding=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = p(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 7, 7])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = c1(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 6, 7, 7])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = c2(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 7, 7])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
