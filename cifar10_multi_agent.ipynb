{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import random\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from scipy.stats import entropy, ks_2samp\n",
    "from scipy.special import kl_div\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# %load_ext tensorboard\n",
    "\n",
    "import traceback\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logname = 'logs/decentralized_multi_agent'\n",
    "logging.basicConfig(filename=logname,\n",
    "                            filemode='a',\n",
    "                            format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                            datefmt='%H:%M:%S',\n",
    "                            level=logging.DEBUG)\n",
    "\n",
    "logging.info(\"Running Decentralized Learning test\")\n",
    "\n",
    "logger = logging.getLogger('Decentralized_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdc15473410>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reproduce randomness for fair comparison\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Standard transformations for improving CIFAR10. \n",
    "\n",
    "# Transformations A\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Transformations B\n",
    "RC   = transforms.RandomCrop(32, padding=4)\n",
    "RHF  = transforms.RandomHorizontalFlip()\n",
    "RVF  = transforms.RandomVerticalFlip()\n",
    "NRM  = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "TT   = transforms.ToTensor()\n",
    "TPIL = transforms.ToPILImage()\n",
    "\n",
    "# Transforms object for trainset with augmentation\n",
    "transform_with_aug = transforms.Compose([TPIL, RC, RHF, TT, NRM])\n",
    "# Transforms object for testset with NO augmentation\n",
    "transform_no_aug   = transforms.Compose([TT, NRM])\n",
    "\n",
    "# Downloading/Louding CIFAR10 data\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data/cifar10', train=True,\n",
    "                                        download=True, transform=transform_with_aug)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data/cifar10', train=False,\n",
    "                                       download=True, transform=transform_no_aug)\n",
    "\n",
    "classDict = {'plane':0, 'car':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}\n",
    "\n",
    "# Separating trainset/testset data/label\n",
    "x_train  = trainset.data\n",
    "x_test   = testset.data\n",
    "y_train  = trainset.targets\n",
    "y_test   = testset.targets\n",
    "\n",
    "# Define a function to separate CIFAR classes by class index\n",
    "\n",
    "def get_class_i(x, y, i):\n",
    "    \"\"\"\n",
    "    x: trainset.train_data or testset.test_data\n",
    "    y: trainset.train_labels or testset.test_labels\n",
    "    i: class label, a number between 0 to 9\n",
    "    return: x_i\n",
    "    \"\"\"\n",
    "    # Convert to a numpy array\n",
    "    y = np.array(y)\n",
    "    # Locate position of labels that equal to i\n",
    "    pos_i = np.argwhere(y == i)\n",
    "    # Convert the result into a 1-D list\n",
    "    pos_i = list(pos_i[:,0])\n",
    "    # Collect all data that match the desired label\n",
    "    x_i = [x[j] for j in pos_i]\n",
    "    \n",
    "    return x_i\n",
    "\n",
    "class DatasetMaker(Dataset):\n",
    "    def __init__(self, datasets, transformFunc = transform_no_aug):\n",
    "        \"\"\"\n",
    "        datasets: a list of get_class_i outputs, i.e. a list of list of images for selected classes\n",
    "        \"\"\"\n",
    "        self.datasets = datasets\n",
    "        self.lengths  = [len(d) for d in self.datasets]\n",
    "        self.transformFunc = transformFunc\n",
    "    def __getitem__(self, i):\n",
    "        class_label, index_wrt_class = self.index_of_which_bin(self.lengths, i)\n",
    "        img = self.datasets[class_label][index_wrt_class]\n",
    "        img = self.transformFunc(img)\n",
    "        return img, class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.lengths)\n",
    "    \n",
    "    def index_of_which_bin(self, bin_sizes, absolute_index, verbose=False):\n",
    "        \"\"\"\n",
    "        Given the absolute index, returns which bin it falls in and which element of that bin it corresponds to.\n",
    "        \"\"\"\n",
    "        # Which class/bin does i fall into?\n",
    "        accum = np.add.accumulate(bin_sizes)\n",
    "        if verbose:\n",
    "            print(\"accum =\", accum)\n",
    "        bin_index  = len(np.argwhere(accum <= absolute_index))\n",
    "        if verbose:\n",
    "            print(\"class_label =\", bin_index)\n",
    "        # Which element of the fallent class/bin does i correspond to?\n",
    "        index_wrt_class = absolute_index - np.insert(accum, 0, 0)[bin_index]\n",
    "        if verbose:\n",
    "            print(\"index_wrt_class =\", index_wrt_class)\n",
    "\n",
    "        return bin_index, index_wrt_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are saving a fraction of random data to be used in training\n",
    "frac = int(len(x_train) * 0.05)\n",
    "x_reserve = x_train[:frac]\n",
    "y_reserve = y_train[:frac]\n",
    "x_train = x_train[frac:]\n",
    "y_train = y_train[frac:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Usage ================== #\n",
    "\n",
    "# \n",
    "trainset1 = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_train, y_train, classDict['plane']), \n",
    "         get_class_i(x_train, y_train, classDict['car']), \n",
    "         get_class_i(x_train, y_train, classDict['bird']),\n",
    "        [],[],[],[],[],[],[]],\n",
    "        transform_with_aug\n",
    "    )\n",
    "trainset2 = \\\n",
    "    DatasetMaker(\n",
    "        [[],[],[],\n",
    "         get_class_i(x_train, y_train, classDict['cat']), \n",
    "         get_class_i(x_train, y_train, classDict['deer']), \n",
    "         get_class_i(x_train, y_train, classDict['dog']), \n",
    "         [],[],[],[]],\n",
    "        transform_with_aug\n",
    "    )\n",
    "trainset3 = \\\n",
    "    DatasetMaker(\n",
    "        [[],[],[],[],[],[],\n",
    "         get_class_i(x_train, y_train, classDict['frog']), \n",
    "         get_class_i(x_train, y_train, classDict['horse']), \n",
    "         get_class_i(x_train, y_train, classDict['ship']), \n",
    "         get_class_i(x_train, y_train, classDict['truck'])],\n",
    "        transform_with_aug\n",
    "    )\n",
    "trainset4 = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_train, y_train, classDict['plane']), \n",
    "         get_class_i(x_train, y_train, classDict['car']), \n",
    "         get_class_i(x_train, y_train, classDict['bird']), \n",
    "         get_class_i(x_train, y_train, classDict['cat']), \n",
    "         get_class_i(x_train, y_train, classDict['deer']),\n",
    "         get_class_i(x_train, y_train, classDict['dog']), \n",
    "         get_class_i(x_train, y_train, classDict['frog']), \n",
    "         get_class_i(x_train, y_train, classDict['horse']), \n",
    "         get_class_i(x_train, y_train, classDict['ship']), \n",
    "         get_class_i(x_train, y_train, classDict['truck'])],\n",
    "        transform_with_aug\n",
    "    )\n",
    "reserved = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_reserve, y_reserve, classDict['plane']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['car']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['bird']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['cat']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['deer']),\n",
    "         get_class_i(x_reserve, y_reserve, classDict['dog']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['frog']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['horse']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['ship']), \n",
    "         get_class_i(x_reserve, y_reserve, classDict['truck'])],\n",
    "        transform_with_aug\n",
    "    )\n",
    "testset  = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_test, y_test, classDict['plane']), \n",
    "         get_class_i(x_test, y_test, classDict['car']), \n",
    "         get_class_i(x_test, y_test, classDict['bird']), \n",
    "         get_class_i(x_test, y_test, classDict['cat']), \n",
    "         get_class_i(x_test, y_test, classDict['deer']),\n",
    "         get_class_i(x_test, y_test, classDict['dog']), \n",
    "         get_class_i(x_test, y_test, classDict['frog']), \n",
    "         get_class_i(x_test, y_test, classDict['horse']), \n",
    "         get_class_i(x_test, y_test, classDict['ship']), \n",
    "         get_class_i(x_test, y_test, classDict['truck'])],\n",
    "        transform_no_aug\n",
    "    )\n",
    "\n",
    "superset = torch.utils.data.ConcatDataset([trainset3,reserved])\n",
    "supersetA = torch.utils.data.ConcatDataset([trainset1,reserved])\n",
    "supersetB = torch.utils.data.ConcatDataset([trainset2,reserved])\n",
    "\n",
    "kwargs = {'num_workers': 2, 'pin_memory': False}\n",
    "\n",
    "# Create datasetLoaders from trainset and testset\n",
    "trainsetLoader1   = DataLoader(trainset1, batch_size=128, shuffle=True , **kwargs)\n",
    "trainsetLoader2   = DataLoader(trainset2, batch_size=128, shuffle=True , **kwargs)\n",
    "trainsetLoader3   = DataLoader(trainset3, batch_size=128, shuffle=True , **kwargs)\n",
    "trainsetLoader4   = DataLoader(trainset4, batch_size=128, shuffle=True , **kwargs)\n",
    "reservedLoader    = DataLoader(superset, batch_size=128, shuffle=True , **kwargs)\n",
    "reservedLoaderA    = DataLoader(supersetA, batch_size=128, shuffle=True , **kwargs)\n",
    "reservedLoaderB    = DataLoader(supersetB, batch_size=128, shuffle=True , **kwargs)\n",
    "testsetLoader     = DataLoader(testset , batch_size=128, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.3    # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test that things are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = next(iter(reservedLoader))\n",
    "imshow(torchvision.utils.make_grid(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 32, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decide on a GPU to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(device)\n",
    "print(device)\n",
    "\n",
    "# device2 = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decentralized Pairwise Knowledge Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models used in knowledge transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_init(m):\n",
    "    if isinstance(m, (torch.nn.Linear)):\n",
    "        torch.nn.init.sparse_(m.weight, sparsity=0.33)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "    elif isinstance(m, (torch.nn.Conv2d)):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "    elif isinstance(m, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d)):\n",
    "        m.weight.data.fill_(1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "class Decenter(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super(Decenter, self).__init__()\n",
    "        if len(shape) == 1:\n",
    "            shape = shape[0]\n",
    "            self.dim = 0\n",
    "        elif len(shape) == 2:\n",
    "            shape = shape[1]\n",
    "            self.dim = 1\n",
    "        self.translation = torch.nn.Sequential(\n",
    "#             torch.nn.Tanh(),\n",
    "            torch.nn.Linear(shape*3, shape)\n",
    "        )\n",
    "\n",
    "#         self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, source1, source2, target):\n",
    "        x = torch.cat((source1, source2, target), self.dim)\n",
    "#         x = torch.cat((torch.flatten(source), torch.flatten(target)), 0)\n",
    "#         x = torch.add(torch.flatten(source).to(\"cpu\"), torch.flatten(target).to(\"cpu\"))\n",
    "        res = self.translation(x)\n",
    "#         res = res.reshape(target.shape)\n",
    "        return res\n",
    "    \n",
    "    \n",
    "class Interpolate(torch.nn.Module):\n",
    "    def __init__(self, size, mode):\n",
    "        super(Interpolate, self).__init__()\n",
    "        self.interp = torch.nn.functional.interpolate\n",
    "        self.size = size\n",
    "        self.mode = mode\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.interp(x, size=self.size, mode=self.mode, align_corners=False)\n",
    "        return x\n",
    "    \n",
    "class Reshape(torch.nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "    \n",
    "class Decenter_pooled(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super(Decenter_pooled, self).__init__()\n",
    "        self.shape = shape\n",
    "        self.translation = torch.nn.Sequential(\n",
    "#             torch.nn.BatchNorm2d(channels_out),\n",
    "#             torch.nn.AdaptiveAvgPool2d(1),\n",
    "            Interpolate(size=1, mode='bilinear'),\n",
    "            Reshape(shape[0], shape[1]*2),\n",
    "            torch.nn.Linear(shape[1]*2, shape[1]*shape[-1]*shape[-1]),\n",
    "#             Reshape(shape[0], shape[1] ,1 ,1),\n",
    "        )\n",
    "\n",
    "#         self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        x = torch.cat((source, target), 1)\n",
    "        res = self.translation(x)\n",
    "        res = res.view(self.shape[0], self.shape[1], self.shape[2], self.shape[3])\n",
    "        return res\n",
    "    \n",
    "    \n",
    "class Decenter_conv(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super(Decenter_conv, self).__init__()\n",
    "        self.shape = shape\n",
    "        channels_in = shape[1]*3\n",
    "        channels_out = shape[1]\n",
    "        self.translation = torch.nn.Sequential(\n",
    "#             torch.nn.BatchNorm2d(channels_in),\n",
    "            torch.nn.Conv2d(channels_in, channels_out, 1, stride=1, padding=0)\n",
    "#             torch.nn.ConvTranspose2d(channels_in, channels_out, 3, stride=1, padding=1)\n",
    "#             torch.nn.Linear(shape[0]*2, shape[0]*4),\n",
    "#             torch.nn.Dropout(p=0.5),\n",
    "#             torch.nn.Linear(shape[0]*2, shape[0]),\n",
    "#             torch.nn.AdaptiveAvgPool2d((shape[-2],shape[-1])),\n",
    "#             torch.nn.Conv2d(channels_out, channels_out, 3, stride=1, padding=1)\n",
    "\n",
    "        )\n",
    "        self.translation2 = torch.nn.Sequential(\n",
    "            torch.nn.AdaptiveMaxPool2d((shape[-2],shape[-1])),\n",
    "        )\n",
    "\n",
    "#         self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, source1, source2, target):\n",
    "        x = torch.cat((source1, source2, target), 1)\n",
    "#         x = x.reshape(-1, x.shape[0])\n",
    "#         x = torch.cat((torch.flatten(source), torch.flatten(target)), 0)\n",
    "#         x = torch.add(torch.flatten(source).to(\"cpu\"), torch.flatten(target).to(\"cpu\"))\n",
    "        res = self.translation(x)\n",
    "#         res = res.reshape(self.shape)\n",
    "        return res\n",
    "\n",
    "class Special(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Special, self).__init__()\n",
    "        self.w1 = torch.nn.Parameter(torch.tensor(0.3333333))\n",
    "        self.w2 = torch.nn.Parameter(torch.tensor(0.3333333))\n",
    "        self.w3 = torch.nn.Parameter(torch.tensor(0.3333333))\n",
    "        \n",
    "    def forward(self, source1, source2, target, x):\n",
    "        s1 = copy.deepcopy(source1.state_dict())\n",
    "        s2 = copy.deepcopy(source2.state_dict())\n",
    "        t = copy.deepcopy(target.state_dict())\n",
    "        \n",
    "        w_glob = copy.deepcopy(t)\n",
    "        for k in mdlzAC.keys():\n",
    "            w_glob[k] = s1[k]*self.w1+s2[k]*self.w2+t[k]*self.w3\n",
    "#         target.load_state_dict(w_glob)\n",
    "        \n",
    "        return w_glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the local training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "### Hooks are used to investigate the effect of gradiant decent on weights. Not necessary for simply reproducing paper results. \n",
    "grad_dict: dict = {}\n",
    "def fc_hook(layer_name, grad_input, grad_output): \n",
    "    if layer_name not in grad_dict:\n",
    "        grad_dict[layer_name] = {}\n",
    "        grad_dict[layer_name][\"grad_input\"] = []\n",
    "        grad_dict[layer_name][\"grad_output\"] = []\n",
    "        grad_dict[layer_name][\"labels\"] = []\n",
    "        \n",
    "#     print(grad_input)\n",
    "#     print(grad_output)\n",
    "    grad_dict[layer_name][\"grad_input\"].append(grad_input[0].cpu().numpy())\n",
    "    grad_dict[layer_name][\"grad_output\"].append(grad_output[0].cpu().numpy())\n",
    "    \n",
    "# def reserve_step(source, target):\n",
    "    \n",
    "\n",
    "matlst = []\n",
    "fclst = []\n",
    "reslist = []\n",
    "\n",
    "## Option are used for simulating remote agents using pairwise knowledge transfer \n",
    "options = {0: ['trainA', 'validA','reservedAB'], \n",
    "           1: ['trainB','validB','reservedBA'],\n",
    "           2: ['trainC','validC','reservedCA','validC']}\n",
    "\n",
    "dtype = torch.float\n",
    "\n",
    "def train_model(dataloders, model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "\n",
    "#     writer = SummaryWriter('runs/') \n",
    "\n",
    "    since = time.time()\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    best_model_wts = 0.0\n",
    "    best_acc = 0.0\n",
    "    dataset_sizes = {'trainA': len(dataloders['trainA'].sampler),\n",
    "                     'trainB': len(dataloders['trainB'].sampler),\n",
    "                     'trainC': len(dataloders['trainC'].sampler),\n",
    "                     'reservedA': len(dataloders['reservedA'].sampler),\n",
    "                     'reservedB': len(dataloders['reservedB'].sampler),\n",
    "                     'reservedCA': len(dataloders['reservedCA'].sampler),\n",
    "                     'reservedAB': len(dataloders['reservedAB'].sampler),\n",
    "                     'reservedBA': len(dataloders['reservedBA'].sampler),\n",
    "                     'validA': len(dataloders['validA'].sampler),\n",
    "                     'validB': len(dataloders['validB'].sampler),\n",
    "                     'validC': len(dataloders['validC'].sampler)}\n",
    "\n",
    "    i = z = 0\n",
    "    ivc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['trainA', 'validA','trainB','validB','trainC','validC','reservedCA','validC']:  ## this sequense simualtes a half mesh configuation\n",
    "#         choice = np.random.choice(range(3), replace=False)\n",
    "#         for phase in options[choice]:\n",
    "            if phase not in ['validA','validB','validC']:\n",
    "                model[phase].train(True)\n",
    "            else:\n",
    "                model['trainA'].train(False)\n",
    "                model['trainB'].train(False)\n",
    "                model['trainC'].train(False)\n",
    "            \n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0        \n",
    "                    \n",
    "            for inputs, labels in dataloders[phase]:\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer[phase].zero_grad()\n",
    "                \n",
    "                ## if its a transfer phase, swap layers using the pipline models\n",
    "#                 if phase in ['reservedCA','reservedAB', 'reservedBA']:\n",
    "                if phase == 'reservedCA':\n",
    "                        sd = model[phase].state_dict()\n",
    "                        for key, value in mdlzAC.items():\n",
    "                            shape = model['trainC'].state_dict()[key].shape\n",
    "                            mdl = value[1](shape).to(device)\n",
    "                            checkpoint = torch.load(value[0])\n",
    "                            mdl.load_state_dict(checkpoint['model_state_dict'])\n",
    "                            mdl.eval()\n",
    "                            sd[key] = mdl(copy.deepcopy(model['trainA'].state_dict()[key]),\n",
    "                                          copy.deepcopy(model['trainB'].state_dict()[key]),\n",
    "                                          copy.deepcopy(model['trainC'].state_dict()[key]))\n",
    "    #                         torch.save({'model_state_dict': mdl.state_dict()}, value[0])\n",
    "\n",
    "    #                         if key == 'conv1.weight':\n",
    "    #                             matlst.append(sd[key])\n",
    "    #                         elif key == 'fc.weight':\n",
    "    #                             fclst.append(sd[key])\n",
    "                        model[phase].load_state_dict(sd)\n",
    "        \n",
    "                #print(list(model[phase].parameters()))\n",
    "                outputs = model[phase](inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                \n",
    "                ## if its a transfer phase, compute remote loss term\n",
    "                if phase in ['reservedCA','reservedAB','reservedBA']:\n",
    "                    loss_a = criterion['trainC'](outputs, labels)\n",
    "#                     batch_size = labels.shape[0]\n",
    "#                     # Dummy input that HAS to be 2D for the scatter (you can use view(-1,1) if needed)\n",
    "#                     y = labels.reshape(-1,1)\n",
    "#                     # One hot encoding buffer that you create out of the loop and just keep reusing\n",
    "#                     y_onehot = torch.FloatTensor(batch_size, 10).to(device)\n",
    "\n",
    "#                     # In your for loop\n",
    "#                     y_onehot.zero_()\n",
    "#                     y_onehot.scatter_(1, y, 1)\n",
    "\n",
    "                    if phase == 'reservedCA':\n",
    "                        outputs2 = model['trainA'](inputs)\n",
    "                        outputs3 = model['trainB'](inputs)\n",
    "                    elif phase == 'reservedAB':\n",
    "                        outputs2 = model['trainC'](inputs)\n",
    "                        outputs3 = model['trainB'](inputs)\n",
    "                    elif phase == 'reservedBA':\n",
    "                        outputs2 = model['trainC'](inputs)\n",
    "                        outputs3 = model['trainA'](inputs)\n",
    "    \n",
    "#                     sm = torch.nn.Softmax(dim=1)\n",
    "                    sm = torch.nn.LogSoftmax(dim=1)\n",
    "                    outputs = sm(outputs)\n",
    "                    outputs2 = sm(outputs2)\n",
    "                    outputs3 = sm(outputs3)\n",
    "                    loss_b = criterion[phase](outputs, outputs2)\n",
    "                    loss_c = criterion[phase](outputs, outputs3)\n",
    "#                     loss = (loss_a + (loss_b + loss_c)*0.5)*0.5\n",
    "\n",
    "                    loss_d = criterion[phase](sd['fc.weight'], model['trainA'].state_dict()['fc.weight'])\n",
    "                    loss_e = criterion[phase](sd['fc.weight'], model['trainB'].state_dict()['fc.weight'])\n",
    "                    loss = (loss_a*0.7 + (loss_b + loss_c)*0.3 + (loss_d + loss_e)*0.0)\n",
    "                    \n",
    "                ## if its not a transfer phase, compute local loss term\n",
    "                else:\n",
    "                    loss = criterion[phase](outputs, labels)\n",
    "\n",
    "                ## if its not a validation phase, optimize our models\n",
    "                if phase not in ['validA','validB','validC']:\n",
    "                    loss.backward()\n",
    "                    if phase == 'reservedCA':\n",
    "#                       loss_b.backward(retain_graph=False)\n",
    "                        for key, value in mdlzAC.items():\n",
    "                            shape = model['trainC'].state_dict()[key].shape\n",
    "                            mdl = value[1](shape).to(device)\n",
    "                            opti = torch.optim.AdamW(mdl.parameters(), lr=0.01, betas=(0.9, 0.999))\n",
    "                            checkpoint = torch.load(value[0])\n",
    "                            mdl.load_state_dict(checkpoint['model_state_dict'])\n",
    "                            mdl.train(True)\n",
    "                            opti.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#                             opti.zero_grad()\n",
    "                            opti.step()\n",
    "                            torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                                        'optimizer_state_dict': opti.state_dict(),\n",
    "                                        'factor': checkpoint['factor'],\n",
    "                                        'patience': checkpoint['patience'],\n",
    "                                        'scheduler_state_dict': checkpoint['scheduler_state_dict']},\n",
    "                                        value[0])\n",
    "                    else:\n",
    "                        optimizer[phase].step()\n",
    "                            \n",
    "                    \n",
    "                    ## Back prop hook\n",
    "#                     grad_dict[\"fc\"][\"labels\"].append(labels.cpu().numpy())\n",
    "\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            ## update scheduler for each model\n",
    "            if phase in ['validA','validB','validC']:\n",
    "                scheduler[phase].step(running_loss)\n",
    "                \n",
    "            elif phase == 'reservedCA':\n",
    "                for key, value in mdlzAC.items():\n",
    "                    checkpoint = torch.load(value[0])\n",
    "                    sched = lr_scheduler.ReduceLROnPlateau(optimizerC, 'min', factor=checkpoint['factor'], patience=checkpoint['patience'])\n",
    "                    sched.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "                    sched.step(running_loss)\n",
    "                    torch.save({'model_state_dict': checkpoint['model_state_dict'],\n",
    "                                'optimizer_state_dict': checkpoint['optimizer_state_dict'],\n",
    "                                'factor': checkpoint['factor'],\n",
    "                                'patience': checkpoint['patience'],\n",
    "                                'scheduler_state_dict': sched.state_dict()},\n",
    "                                value[0])\n",
    "\n",
    "#             elif phase == 'reservedAB':\n",
    "#                 for key, value in mdlzAB.items():\n",
    "#                     checkpoint = torch.load(value[0])\n",
    "#                     sched = lr_scheduler.ReduceLROnPlateau(optimizerA, 'min', factor=checkpoint['factor'], patience=checkpoint['patience'])\n",
    "#                     sched.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "#                     sched.step(running_loss)\n",
    "#                     torch.save({'model_state_dict': checkpoint['model_state_dict'],\n",
    "#                                 'optimizer_state_dict': checkpoint['optimizer_state_dict'],\n",
    "#                                 'factor': checkpoint['factor'],\n",
    "#                                 'patience': checkpoint['patience'],\n",
    "#                                 'scheduler_state_dict': sched.state_dict()},\n",
    "#                                 value[0])\n",
    "                    \n",
    "#             elif phase == 'reservedBA':\n",
    "#                 for key, value in mdlzBA.items():\n",
    "#                     checkpoint = torch.load(value[0])\n",
    "#                     sched = lr_scheduler.ReduceLROnPlateau(optimizerB, 'min', factor=checkpoint['factor'], patience=checkpoint['patience'])\n",
    "#                     sched.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "#                     sched.step(running_loss)\n",
    "#                     torch.save({'model_state_dict': checkpoint['model_state_dict'],\n",
    "#                                 'optimizer_state_dict': checkpoint['optimizer_state_dict'],\n",
    "#                                 'factor': checkpoint['factor'],\n",
    "#                                 'patience': checkpoint['patience'],\n",
    "#                                 'scheduler_state_dict': sched.state_dict()},\n",
    "#                                 value[0])\n",
    "\n",
    "                \n",
    "            ## report results\n",
    "            if phase not in ['validA','validB','validC']:\n",
    "                train_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                train_epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            else:\n",
    "                valid_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                valid_epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "                print('Epoch [{}/{}] phase: {} train loss: {:.4f} acc: {:.4f} ' \n",
    "                      'valid loss: {:.4f} acc: {:.4f}'.format(\n",
    "                        epoch, num_epochs - 1,\n",
    "                        phase,\n",
    "                        train_epoch_loss, train_epoch_acc, \n",
    "                        valid_epoch_loss, valid_epoch_acc))\n",
    "                print() \n",
    "                logger.info('Epoch [{}/{}] phase: {} train loss: {:.4f} acc: {:.4f} ' \n",
    "                      'valid loss: {:.4f} acc: {:.4f}'.format(\n",
    "                        epoch, num_epochs - 1,\n",
    "                        phase,\n",
    "                        train_epoch_loss, train_epoch_acc, \n",
    "                        valid_epoch_loss, valid_epoch_acc))\n",
    "                \n",
    "                ## Writing to tensorboard\n",
    "                if phase == 'validC':\n",
    "                    ivc += 1\n",
    "                    if ivc == 2:\n",
    "#                         writer.add_histogram('distribution centers/our_half_mesh_transfer', outputs, i)\n",
    "\n",
    "#                         writer.add_scalar('train/loss_our_half_mesh_tansfer', train_epoch_loss, epoch)\n",
    "#                         writer.add_scalar('train/accuracy_our_half_mesh_tansfer', train_epoch_acc, epoch)\n",
    "\n",
    "#                         writer.add_scalar('valid/loss_our_half_mesh_tansfer', valid_epoch_loss, epoch)\n",
    "#                         writer.add_scalar('valid/accuracy_our_half_mesh_tansfer', valid_epoch_acc, epoch)\n",
    "                        reslist.append(valid_epoch_acc.item())\n",
    "                        ivc = 0\n",
    "\n",
    "                \n",
    "            if phase in ['validC'] and valid_epoch_acc > best_acc:\n",
    "                best_acc = valid_epoch_acc\n",
    "                best_model_wts = model[phase].state_dict()\n",
    "\n",
    "            i+=1\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    logger.info('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "#     writer.close()\n",
    "    model['validC'].load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Define models for network of learners, optimizers, and loss terms\n",
    "\n",
    "resnetA = models.resnet50(pretrained=True)\n",
    "resnetB = models.resnet50(pretrained=True)\n",
    "resnetC = models.resnet50(pretrained=True)\n",
    "# freeze all model parameters\n",
    "# for param in resnet.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# new final layer with 10 classes\n",
    "num_ftrsA = resnetA.fc.in_features\n",
    "resnetA.fc = torch.nn.Linear(num_ftrsA, 10)\n",
    "\n",
    "num_ftrsB = resnetB.fc.in_features\n",
    "resnetB.fc = torch.nn.Linear(num_ftrsB, 10)\n",
    "\n",
    "num_ftrsC = resnetC.fc.in_features\n",
    "resnetC.fc = torch.nn.Linear(num_ftrsC, 10)\n",
    "\n",
    "def fc_backward_hook(module, grad_input, grad_output):  # module is Linear in this case. Ignored.\n",
    "        fc_hook(\"fc\", grad_input, grad_output)\n",
    "resnetA.fc_hook_handle = resnetA.fc.register_backward_hook(fc_backward_hook)\n",
    "resnetB.fc_hook_handle = resnetB.fc.register_backward_hook(fc_backward_hook)\n",
    "resnetC.fc_hook_handle = resnetC.fc.register_backward_hook(fc_backward_hook)\n",
    "\n",
    "\n",
    "def roc_auc_score_micro(y_pred_proba, y_true):\n",
    "    y_pred_proba = y_pred_proba.detach().cpu()\n",
    "    y_true = y_true.detach().cpu()\n",
    "    return metrics.roc_auc_score(\n",
    "        label_binarize(y_true, classes=list(range(y_pred_proba.shape[1]))).ravel(),\n",
    "        y_pred_proba.flatten())\n",
    "\n",
    "\n",
    "resnetA = resnetA.to(device)\n",
    "resnetB = resnetB.to(device)\n",
    "resnetC = resnetC.to(device)\n",
    "\n",
    "criterionA = torch.nn.CrossEntropyLoss()\n",
    "# criterionB = torch.nn.CrossEntropyLoss()\n",
    "# criterionA = torch.nn.KLDivLoss()\n",
    "criterionB = torch.nn.KLDivLoss(reduction = 'batchmean')\n",
    "# criterionB = torch.nn.KLDivLoss(reduction = 'mean')\n",
    "# criterionB = torch.nn.MSELoss()\n",
    "optimizerA = torch.optim.SGD(resnetA.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizerB = torch.optim.SGD(resnetB.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizerC = torch.optim.SGD(resnetC.parameters(), lr=0.01, momentum=0.9)\n",
    "# optimizerA = torch.optim.AdamW(resnetA.parameters(), lr=0.01, betas=(0.9, 0.999))\n",
    "# optimizerB = torch.optim.AdamW(resnetB.parameters(), lr=0.01, betas=(0.9, 0.999))\n",
    "# optimizerC = torch.optim.AdamW(resnetC.parameters(), lr=0.01, betas=(0.9, 0.999))\n",
    "\n",
    "# exp_lr_schedulerA = lr_scheduler.StepLR(optimizerA, step_size=5, gamma=0.01)\n",
    "# exp_lr_schedulerB = lr_scheduler.StepLR(optimizerB, step_size=5, gamma=0.01)\n",
    "# exp_lr_schedulerC = lr_scheduler.StepLR(optimizerC, step_size=5, gamma=0.2)\n",
    "exp_lr_schedulerA = lr_scheduler.ReduceLROnPlateau(optimizerA, 'min', factor=0.90, patience=500)\n",
    "exp_lr_schedulerB = lr_scheduler.ReduceLROnPlateau(optimizerB, 'min', factor=0.90, patience=500)\n",
    "exp_lr_schedulerC = lr_scheduler.ReduceLROnPlateau(optimizerC, 'min', factor=0.90, patience=500)\n",
    "\n",
    "\n",
    "def hwout(Hin, padding, dilation, kernel_size, stride):\n",
    "    return (Hin + 2 * padding - dilation * (kernel_size-1) - 1)/stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for finding largest layer\n",
    "\n",
    "max_layer = 0\n",
    "max_neurons = 0\n",
    "for prm in resnetC.named_parameters():\n",
    "    num_ftr = np.prod(prm[1].shape)\n",
    "    if num_ftr > max_neurons:\n",
    "         max_neurons = num_ftr\n",
    "         max_layer = prm[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1.weight',\n",
       " 'bn1.weight',\n",
       " 'bn1.bias',\n",
       " 'layer1.0.conv1.weight',\n",
       " 'layer1.0.bn1.weight',\n",
       " 'layer1.0.bn1.bias',\n",
       " 'layer1.0.conv2.weight',\n",
       " 'layer1.0.bn2.weight',\n",
       " 'layer1.0.bn2.bias',\n",
       " 'layer1.0.conv3.weight',\n",
       " 'layer1.0.bn3.weight',\n",
       " 'layer1.0.bn3.bias',\n",
       " 'layer1.0.downsample.0.weight',\n",
       " 'layer1.0.downsample.1.weight',\n",
       " 'layer1.0.downsample.1.bias',\n",
       " 'layer1.1.conv1.weight',\n",
       " 'layer1.1.bn1.weight',\n",
       " 'layer1.1.bn1.bias',\n",
       " 'layer1.1.conv2.weight',\n",
       " 'layer1.1.bn2.weight',\n",
       " 'layer1.1.bn2.bias',\n",
       " 'layer1.1.conv3.weight',\n",
       " 'layer1.1.bn3.weight',\n",
       " 'layer1.1.bn3.bias',\n",
       " 'layer1.2.conv1.weight',\n",
       " 'layer1.2.bn1.weight',\n",
       " 'layer1.2.bn1.bias',\n",
       " 'layer1.2.conv2.weight',\n",
       " 'layer1.2.bn2.weight',\n",
       " 'layer1.2.bn2.bias',\n",
       " 'layer1.2.conv3.weight',\n",
       " 'layer1.2.bn3.weight',\n",
       " 'layer1.2.bn3.bias',\n",
       " 'layer2.0.conv1.weight',\n",
       " 'layer2.0.bn1.weight',\n",
       " 'layer2.0.bn1.bias',\n",
       " 'layer2.0.conv2.weight',\n",
       " 'layer2.0.bn2.weight',\n",
       " 'layer2.0.bn2.bias',\n",
       " 'layer2.0.conv3.weight',\n",
       " 'layer2.0.bn3.weight',\n",
       " 'layer2.0.bn3.bias',\n",
       " 'layer2.0.downsample.0.weight',\n",
       " 'layer2.0.downsample.1.weight',\n",
       " 'layer2.0.downsample.1.bias',\n",
       " 'layer2.1.conv1.weight',\n",
       " 'layer2.1.bn1.weight',\n",
       " 'layer2.1.bn1.bias',\n",
       " 'layer2.1.conv2.weight',\n",
       " 'layer2.1.bn2.weight',\n",
       " 'layer2.1.bn2.bias',\n",
       " 'layer2.1.conv3.weight',\n",
       " 'layer2.1.bn3.weight',\n",
       " 'layer2.1.bn3.bias',\n",
       " 'layer2.2.conv1.weight',\n",
       " 'layer2.2.bn1.weight',\n",
       " 'layer2.2.bn1.bias',\n",
       " 'layer2.2.conv2.weight',\n",
       " 'layer2.2.bn2.weight',\n",
       " 'layer2.2.bn2.bias',\n",
       " 'layer2.2.conv3.weight',\n",
       " 'layer2.2.bn3.weight',\n",
       " 'layer2.2.bn3.bias',\n",
       " 'layer2.3.conv1.weight',\n",
       " 'layer2.3.bn1.weight',\n",
       " 'layer2.3.bn1.bias',\n",
       " 'layer2.3.conv2.weight',\n",
       " 'layer2.3.bn2.weight',\n",
       " 'layer2.3.bn2.bias',\n",
       " 'layer2.3.conv3.weight',\n",
       " 'layer2.3.bn3.weight',\n",
       " 'layer2.3.bn3.bias',\n",
       " 'layer3.0.conv1.weight',\n",
       " 'layer3.0.bn1.weight',\n",
       " 'layer3.0.bn1.bias',\n",
       " 'layer3.0.conv2.weight',\n",
       " 'layer3.0.bn2.weight',\n",
       " 'layer3.0.bn2.bias',\n",
       " 'layer3.0.conv3.weight',\n",
       " 'layer3.0.bn3.weight',\n",
       " 'layer3.0.bn3.bias',\n",
       " 'layer3.0.downsample.0.weight',\n",
       " 'layer3.0.downsample.1.weight',\n",
       " 'layer3.0.downsample.1.bias',\n",
       " 'layer3.1.conv1.weight',\n",
       " 'layer3.1.bn1.weight',\n",
       " 'layer3.1.bn1.bias',\n",
       " 'layer3.1.conv2.weight',\n",
       " 'layer3.1.bn2.weight',\n",
       " 'layer3.1.bn2.bias',\n",
       " 'layer3.1.conv3.weight',\n",
       " 'layer3.1.bn3.weight',\n",
       " 'layer3.1.bn3.bias',\n",
       " 'layer3.2.conv1.weight',\n",
       " 'layer3.2.bn1.weight',\n",
       " 'layer3.2.bn1.bias',\n",
       " 'layer3.2.conv2.weight',\n",
       " 'layer3.2.bn2.weight',\n",
       " 'layer3.2.bn2.bias',\n",
       " 'layer3.2.conv3.weight',\n",
       " 'layer3.2.bn3.weight',\n",
       " 'layer3.2.bn3.bias',\n",
       " 'layer3.3.conv1.weight',\n",
       " 'layer3.3.bn1.weight',\n",
       " 'layer3.3.bn1.bias',\n",
       " 'layer3.3.conv2.weight',\n",
       " 'layer3.3.bn2.weight',\n",
       " 'layer3.3.bn2.bias',\n",
       " 'layer3.3.conv3.weight',\n",
       " 'layer3.3.bn3.weight',\n",
       " 'layer3.3.bn3.bias',\n",
       " 'layer3.4.conv1.weight',\n",
       " 'layer3.4.bn1.weight',\n",
       " 'layer3.4.bn1.bias',\n",
       " 'layer3.4.conv2.weight',\n",
       " 'layer3.4.bn2.weight',\n",
       " 'layer3.4.bn2.bias',\n",
       " 'layer3.4.conv3.weight',\n",
       " 'layer3.4.bn3.weight',\n",
       " 'layer3.4.bn3.bias',\n",
       " 'layer3.5.conv1.weight',\n",
       " 'layer3.5.bn1.weight',\n",
       " 'layer3.5.bn1.bias',\n",
       " 'layer3.5.conv2.weight',\n",
       " 'layer3.5.bn2.weight',\n",
       " 'layer3.5.bn2.bias',\n",
       " 'layer3.5.conv3.weight',\n",
       " 'layer3.5.bn3.weight',\n",
       " 'layer3.5.bn3.bias',\n",
       " 'layer4.0.conv1.weight',\n",
       " 'layer4.0.bn1.weight',\n",
       " 'layer4.0.bn1.bias',\n",
       " 'layer4.0.conv2.weight',\n",
       " 'layer4.0.bn2.weight',\n",
       " 'layer4.0.bn2.bias',\n",
       " 'layer4.0.conv3.weight',\n",
       " 'layer4.0.bn3.weight',\n",
       " 'layer4.0.bn3.bias',\n",
       " 'layer4.0.downsample.0.weight',\n",
       " 'layer4.0.downsample.1.weight',\n",
       " 'layer4.0.downsample.1.bias',\n",
       " 'layer4.1.conv1.weight',\n",
       " 'layer4.1.bn1.weight',\n",
       " 'layer4.1.bn1.bias',\n",
       " 'layer4.1.conv2.weight',\n",
       " 'layer4.1.bn2.weight',\n",
       " 'layer4.1.bn2.bias',\n",
       " 'layer4.1.conv3.weight',\n",
       " 'layer4.1.bn3.weight',\n",
       " 'layer4.1.bn3.bias',\n",
       " 'layer4.2.conv1.weight',\n",
       " 'layer4.2.bn1.weight',\n",
       " 'layer4.2.bn1.bias',\n",
       " 'layer4.2.conv2.weight',\n",
       " 'layer4.2.bn2.weight',\n",
       " 'layer4.2.bn2.bias',\n",
       " 'layer4.2.conv3.weight',\n",
       " 'layer4.2.bn3.weight',\n",
       " 'layer4.2.bn3.bias',\n",
       " 'fc.weight',\n",
       " 'fc.bias']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in resnetC.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "### Define our transfer pipeline and attach models, and parameters. Model chains are saved to disk for memory efficient execution.\n",
    "mdlzAC = dict()\n",
    "mdlzAB = dict()\n",
    "mdlzBA = dict()\n",
    "params = []\n",
    "model_dir = './multi_model_chain'\n",
    "conv_layers = []\n",
    "bn_layers = ['fc.weight']\n",
    "\n",
    "for prm in resnetC.named_parameters():\n",
    "# for prm in temp_list:\n",
    "#     if 'conv' in prm[0] or 'fc' in prm[0] or 'bn' in prm[0] or 'downsample' in prm[0]:\n",
    "    if prm[0] in bn_layers+conv_layers:\n",
    "#     if 'conv' in prm[0] or 'fc' in prm[0]:\n",
    "        try:\n",
    "#             mdl = Special().to(device)\n",
    "            if prm[1].dim() > 2:\n",
    "#                 if prm[0] not in conv_layers:\n",
    "#                     continue\n",
    "                mdl = Decenter_conv(prm[1].shape).to(device)\n",
    "                optimizer = torch.optim.AdamW(mdl.parameters(), lr=0.01, betas=(0.9, 0.999))\n",
    "                exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=900)\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.1,\n",
    "                            'patience': 900,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'A')\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.1,\n",
    "                            'patience': 900,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'B')\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.1,\n",
    "                            'patience': 900,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'C')\n",
    "#                 mdlzAC[prm[0]] = (mdl, optimizer, exp_lr_scheduler)\n",
    "                mdlzAC[prm[0]] = (model_dir + '/' + prm[0]+'A', Decenter_conv)\n",
    "#                 params += mdl.parameters()\n",
    "#                 pass\n",
    "            else:\n",
    "#                 if prm[0] not in bn_layers:\n",
    "#                     continue\n",
    "                mdl = Decenter(prm[1].shape).to(device)\n",
    "                optimizer = torch.optim.AdamW(mdl.parameters(), lr=0.01, betas=(0.9, 0.999))\n",
    "                exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=900)\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.5,\n",
    "                            'patience': 900,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'A')\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.5,\n",
    "                            'patience': 900,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'B')\n",
    "                torch.save({'model_state_dict': mdl.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'factor': 0.5,\n",
    "                            'patience': 900,\n",
    "                            'scheduler_state_dict': exp_lr_scheduler.state_dict()},\n",
    "                           model_dir + '/' + prm[0]+'C')\n",
    "                mdlzAC[prm[0]] = (model_dir + '/' + prm[0]+'A', Decenter)\n",
    "#                 params += mdl.parameters()\n",
    "            \n",
    "            del mdl\n",
    "            torch.cuda.empty_cache()\n",
    "        except Exception as e:\n",
    "            print(\"Problem with: \" + prm[0] + \" Size: \" + str(num_ftr))\n",
    "            print(\"Error: \" + str(e))\n",
    "            traceback.print_exc()\n",
    "            print()\n",
    "            pass\n",
    "        \n",
    "# params += list(resnetC.parameters())\n",
    "\n",
    "# optimizerRB = torch.optim.SGD(params, lr=0.01, momentum=0.9)\n",
    "# mdlAC = Special().to(device)\n",
    "# optimizerAC = torch.optim.AdamW(mdlAC.parameters(), lr=0.01, betas=(0.9, 0.999))\n",
    "# exp_lr_schedulerAC = lr_scheduler.ReduceLROnPlateau(optimizerAC, 'min', factor=0.1, patience=900)\n",
    "# optimizerRC = torch.optim.AdamW(resnetC.parameters(), lr=0.001, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fc.weight': ('./multi_model_chain/fc.weightA', __main__.Decenter)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdlzAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define phases and associated pareameters\n",
    "dloaders = {'trainA':trainsetLoader1, 'trainB':trainsetLoader2, 'trainC':reservedLoader,\n",
    "            'validA':testsetLoader, 'validB':testsetLoader, 'validC':testsetLoader,\n",
    "            'reservedA':reservedLoader, 'reservedB':reservedLoader, 'reservedCA':reservedLoader, 'reservedAB':reservedLoaderA, 'reservedBA':reservedLoaderB}\n",
    "model = {'trainA':resnetA, 'trainB':resnetB, 'trainC':resnetC,\n",
    "         'validA':resnetA, 'validB':resnetB, 'validC':resnetC,\n",
    "         'reservedA':resnetA, 'reservedB':resnetB, 'reservedCA':resnetC, 'reservedAB':resnetA, 'reservedBA':resnetB}\n",
    "optimizer = {'trainA':optimizerA, 'trainB':optimizerB, 'trainC':optimizerC,\n",
    "             'validA':optimizerA, 'validB':optimizerB, 'validC':optimizerC,\n",
    "             'reservedA':optimizerA, 'reservedB':optimizerB, 'reservedCA':optimizerC, 'reservedAB':optimizerA, 'reservedBA':optimizerB}\n",
    "criterion = {'trainA':criterionA, 'trainB':criterionA, 'trainC':criterionA,\n",
    "             'validA':criterionA, 'validB':criterionA, 'validC':criterionA,\n",
    "             'reservedA':criterionB, 'reservedB':criterionB, 'reservedCA':criterionB, 'reservedAB':criterionB, 'reservedBA':criterionB}\n",
    "exp_lr_scheduler = {'trainA':exp_lr_schedulerA, 'trainB':exp_lr_schedulerB, 'trainC':exp_lr_schedulerC,\n",
    "             'validA':exp_lr_schedulerA, 'validB':exp_lr_schedulerB, 'validC':exp_lr_schedulerC,\n",
    "             'reservedA':exp_lr_schedulerA, 'reservedB':exp_lr_schedulerB, 'reservedCA':exp_lr_schedulerC, 'reservedAB':exp_lr_schedulerA, 'reservedBA':exp_lr_schedulerB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/59] phase: validA train loss: 0.0036 acc: 0.8319 valid loss: 0.0983 acc: 0.2622\n",
      "\n",
      "Epoch [0/59] phase: validB train loss: 0.0060 acc: 0.6811 valid loss: 0.0862 acc: 0.2333\n",
      "\n",
      "Epoch [0/59] phase: validC train loss: 0.0054 acc: 0.7938 valid loss: 0.0133 acc: 0.4238\n",
      "\n",
      "Epoch [0/59] phase: validC train loss: 0.0121 acc: 0.1854 valid loss: 0.0180 acc: 0.0979\n",
      "\n",
      "Epoch [1/59] phase: validA train loss: 0.0019 acc: 0.9170 valid loss: 0.0891 acc: 0.2789\n",
      "\n",
      "Epoch [1/59] phase: validB train loss: 0.0050 acc: 0.7422 valid loss: 0.0685 acc: 0.2271\n",
      "\n",
      "Epoch [1/59] phase: validC train loss: 0.0037 acc: 0.8685 valid loss: 0.0125 acc: 0.5104\n",
      "\n",
      "Epoch [1/59] phase: validC train loss: 0.0107 acc: 0.6206 valid loss: 0.0156 acc: 0.5444\n",
      "\n",
      "Epoch [2/59] phase: validA train loss: 0.0015 acc: 0.9302 valid loss: 0.0987 acc: 0.2814\n",
      "\n",
      "Epoch [2/59] phase: validB train loss: 0.0043 acc: 0.7720 valid loss: 0.0749 acc: 0.2373\n",
      "\n",
      "Epoch [2/59] phase: validC train loss: 0.0031 acc: 0.8902 valid loss: 0.0103 acc: 0.5844\n",
      "\n",
      "Epoch [2/59] phase: validC train loss: 0.0096 acc: 0.6643 valid loss: 0.0134 acc: 0.6233\n",
      "\n",
      "Epoch [3/59] phase: validA train loss: 0.0012 acc: 0.9472 valid loss: 0.0952 acc: 0.2835\n",
      "\n",
      "Epoch [3/59] phase: validB train loss: 0.0037 acc: 0.8061 valid loss: 0.0691 acc: 0.2426\n",
      "\n",
      "Epoch [3/59] phase: validC train loss: 0.0027 acc: 0.9032 valid loss: 0.0103 acc: 0.6167\n",
      "\n",
      "Epoch [3/59] phase: validC train loss: 0.0084 acc: 0.6899 valid loss: 0.0118 acc: 0.6669\n",
      "\n",
      "Epoch [4/59] phase: validA train loss: 0.0011 acc: 0.9493 valid loss: 0.0923 acc: 0.2869\n",
      "\n",
      "Epoch [4/59] phase: validB train loss: 0.0034 acc: 0.8238 valid loss: 0.0685 acc: 0.2441\n",
      "\n",
      "Epoch [4/59] phase: validC train loss: 0.0026 acc: 0.9046 valid loss: 0.0090 acc: 0.6640\n",
      "\n",
      "Epoch [4/59] phase: validC train loss: 0.0078 acc: 0.7406 valid loss: 0.0109 acc: 0.6987\n",
      "\n",
      "Epoch [5/59] phase: validA train loss: 0.0008 acc: 0.9625 valid loss: 0.0959 acc: 0.2868\n",
      "\n",
      "Epoch [5/59] phase: validB train loss: 0.0033 acc: 0.8312 valid loss: 0.0649 acc: 0.2471\n",
      "\n",
      "Epoch [5/59] phase: validC train loss: 0.0022 acc: 0.9185 valid loss: 0.0106 acc: 0.6373\n",
      "\n",
      "Epoch [5/59] phase: validC train loss: 0.0066 acc: 0.7791 valid loss: 0.0097 acc: 0.7130\n",
      "\n",
      "Epoch [6/59] phase: validA train loss: 0.0008 acc: 0.9615 valid loss: 0.0924 acc: 0.2873\n",
      "\n",
      "Epoch [6/59] phase: validB train loss: 0.0029 acc: 0.8483 valid loss: 0.0651 acc: 0.2501\n",
      "\n",
      "Epoch [6/59] phase: validC train loss: 0.0019 acc: 0.9251 valid loss: 0.0093 acc: 0.6636\n",
      "\n",
      "Epoch [6/59] phase: validC train loss: 0.0057 acc: 0.8033 valid loss: 0.0089 acc: 0.7254\n",
      "\n",
      "Epoch [7/59] phase: validA train loss: 0.0007 acc: 0.9687 valid loss: 0.0949 acc: 0.2882\n",
      "\n",
      "Epoch [7/59] phase: validB train loss: 0.0028 acc: 0.8571 valid loss: 0.0674 acc: 0.2465\n",
      "\n",
      "Epoch [7/59] phase: validC train loss: 0.0018 acc: 0.9336 valid loss: 0.0087 acc: 0.6827\n",
      "\n",
      "Epoch [7/59] phase: validC train loss: 0.0051 acc: 0.8194 valid loss: 0.0084 acc: 0.7469\n",
      "\n",
      "Epoch [8/59] phase: validA train loss: 0.0006 acc: 0.9736 valid loss: 0.0996 acc: 0.2890\n",
      "\n",
      "Epoch [8/59] phase: validB train loss: 0.0027 acc: 0.8630 valid loss: 0.0701 acc: 0.2526\n",
      "\n",
      "Epoch [8/59] phase: validC train loss: 0.0016 acc: 0.9390 valid loss: 0.0095 acc: 0.6812\n",
      "\n",
      "Epoch [8/59] phase: validC train loss: 0.0044 acc: 0.8468 valid loss: 0.0077 acc: 0.7435\n",
      "\n",
      "Epoch [9/59] phase: validA train loss: 0.0005 acc: 0.9759 valid loss: 0.0978 acc: 0.2877\n",
      "\n",
      "Epoch [9/59] phase: validB train loss: 0.0026 acc: 0.8749 valid loss: 0.0706 acc: 0.2530\n",
      "\n",
      "Epoch [9/59] phase: validC train loss: 0.0015 acc: 0.9424 valid loss: 0.0105 acc: 0.6546\n",
      "\n",
      "Epoch [9/59] phase: validC train loss: 0.0040 acc: 0.8633 valid loss: 0.0074 acc: 0.7479\n",
      "\n",
      "Epoch [10/59] phase: validA train loss: 0.0005 acc: 0.9782 valid loss: 0.0901 acc: 0.2879\n",
      "\n",
      "Epoch [10/59] phase: validB train loss: 0.0021 acc: 0.8928 valid loss: 0.0719 acc: 0.2513\n",
      "\n",
      "Epoch [10/59] phase: validC train loss: 0.0014 acc: 0.9445 valid loss: 0.0112 acc: 0.6450\n",
      "\n",
      "Epoch [10/59] phase: validC train loss: 0.0035 acc: 0.8930 valid loss: 0.0070 acc: 0.7511\n",
      "\n",
      "Epoch [11/59] phase: validA train loss: 0.0005 acc: 0.9793 valid loss: 0.1009 acc: 0.2876\n",
      "\n",
      "Epoch [11/59] phase: validB train loss: 0.0022 acc: 0.8907 valid loss: 0.0699 acc: 0.2523\n",
      "\n",
      "Epoch [11/59] phase: validC train loss: 0.0013 acc: 0.9483 valid loss: 0.0093 acc: 0.6903\n",
      "\n",
      "Epoch [11/59] phase: validC train loss: 0.0032 acc: 0.8943 valid loss: 0.0067 acc: 0.7575\n",
      "\n",
      "Epoch [12/59] phase: validA train loss: 0.0004 acc: 0.9811 valid loss: 0.1072 acc: 0.2873\n",
      "\n",
      "Epoch [12/59] phase: validB train loss: 0.0021 acc: 0.8918 valid loss: 0.0743 acc: 0.2542\n",
      "\n",
      "Epoch [12/59] phase: validC train loss: 0.0012 acc: 0.9540 valid loss: 0.0109 acc: 0.6786\n",
      "\n",
      "Epoch [12/59] phase: validC train loss: 0.0029 acc: 0.9086 valid loss: 0.0066 acc: 0.7580\n",
      "\n",
      "Epoch [13/59] phase: validA train loss: 0.0004 acc: 0.9831 valid loss: 0.0965 acc: 0.2879\n",
      "\n",
      "Epoch [13/59] phase: validB train loss: 0.0019 acc: 0.9067 valid loss: 0.0758 acc: 0.2553\n",
      "\n",
      "Epoch [13/59] phase: validC train loss: 0.0011 acc: 0.9578 valid loss: 0.0111 acc: 0.6763\n",
      "\n",
      "Epoch [13/59] phase: validC train loss: 0.0025 acc: 0.9152 valid loss: 0.0062 acc: 0.7590\n",
      "\n",
      "Epoch [14/59] phase: validA train loss: 0.0004 acc: 0.9830 valid loss: 0.1032 acc: 0.2878\n",
      "\n",
      "Epoch [14/59] phase: validB train loss: 0.0017 acc: 0.9144 valid loss: 0.0731 acc: 0.2530\n",
      "\n",
      "Epoch [14/59] phase: validC train loss: 0.0010 acc: 0.9577 valid loss: 0.0100 acc: 0.6906\n",
      "\n",
      "Epoch [14/59] phase: validC train loss: 0.0025 acc: 0.9176 valid loss: 0.0063 acc: 0.7608\n",
      "\n",
      "Epoch [15/59] phase: validA train loss: 0.0003 acc: 0.9841 valid loss: 0.1049 acc: 0.2897\n",
      "\n",
      "Epoch [15/59] phase: validB train loss: 0.0029 acc: 0.8550 valid loss: 0.0690 acc: 0.2464\n",
      "\n",
      "Epoch [15/59] phase: validC train loss: 0.0010 acc: 0.9592 valid loss: 0.0110 acc: 0.6757\n",
      "\n",
      "Epoch [15/59] phase: validC train loss: 0.0021 acc: 0.9385 valid loss: 0.0064 acc: 0.7490\n",
      "\n",
      "Epoch [16/59] phase: validA train loss: 0.0003 acc: 0.9865 valid loss: 0.0980 acc: 0.2880\n",
      "\n",
      "Epoch [16/59] phase: validB train loss: 0.0020 acc: 0.8980 valid loss: 0.0698 acc: 0.2516\n",
      "\n",
      "Epoch [16/59] phase: validC train loss: 0.0009 acc: 0.9635 valid loss: 0.0116 acc: 0.6677\n",
      "\n",
      "Epoch [16/59] phase: validC train loss: 0.0020 acc: 0.9334 valid loss: 0.0063 acc: 0.7533\n",
      "\n",
      "Epoch [17/59] phase: validA train loss: 0.0003 acc: 0.9872 valid loss: 0.1088 acc: 0.2887\n",
      "\n",
      "Epoch [17/59] phase: validB train loss: 0.0016 acc: 0.9197 valid loss: 0.0742 acc: 0.2525\n",
      "\n",
      "Epoch [17/59] phase: validC train loss: 0.0009 acc: 0.9654 valid loss: 0.0126 acc: 0.6508\n",
      "\n",
      "Epoch [17/59] phase: validC train loss: 0.0019 acc: 0.9374 valid loss: 0.0064 acc: 0.7404\n",
      "\n",
      "Epoch [18/59] phase: validA train loss: 0.0003 acc: 0.9871 valid loss: 0.1108 acc: 0.2883\n",
      "\n",
      "Epoch [18/59] phase: validB train loss: 0.0015 acc: 0.9261 valid loss: 0.0784 acc: 0.2545\n",
      "\n",
      "Epoch [18/59] phase: validC train loss: 0.0008 acc: 0.9672 valid loss: 0.0111 acc: 0.6780\n",
      "\n",
      "Epoch [18/59] phase: validC train loss: 0.0017 acc: 0.9451 valid loss: 0.0062 acc: 0.7492\n",
      "\n",
      "Epoch [19/59] phase: validA train loss: 0.0003 acc: 0.9880 valid loss: 0.1152 acc: 0.2887\n",
      "\n",
      "Epoch [19/59] phase: validB train loss: 0.0014 acc: 0.9301 valid loss: 0.0821 acc: 0.2539\n",
      "\n",
      "Epoch [19/59] phase: validC train loss: 0.0009 acc: 0.9646 valid loss: 0.0104 acc: 0.6884\n",
      "\n",
      "Epoch [19/59] phase: validC train loss: 0.0016 acc: 0.9499 valid loss: 0.0062 acc: 0.7554\n",
      "\n",
      "Epoch [20/59] phase: validA train loss: 0.0003 acc: 0.9879 valid loss: 0.1021 acc: 0.2890\n",
      "\n",
      "Epoch [20/59] phase: validB train loss: 0.0013 acc: 0.9357 valid loss: 0.0798 acc: 0.2543\n",
      "\n",
      "Epoch [20/59] phase: validC train loss: 0.0008 acc: 0.9696 valid loss: 0.0115 acc: 0.6764\n",
      "\n",
      "Epoch [20/59] phase: validC train loss: 0.0015 acc: 0.9504 valid loss: 0.0064 acc: 0.7400\n",
      "\n",
      "Epoch [21/59] phase: validA train loss: 0.0002 acc: 0.9898 valid loss: 0.1116 acc: 0.2892\n",
      "\n",
      "Epoch [21/59] phase: validB train loss: 0.0013 acc: 0.9388 valid loss: 0.0774 acc: 0.2571\n",
      "\n",
      "Epoch [21/59] phase: validC train loss: 0.0007 acc: 0.9696 valid loss: 0.0112 acc: 0.6847\n",
      "\n",
      "Epoch [21/59] phase: validC train loss: 0.0014 acc: 0.9515 valid loss: 0.0061 acc: 0.7523\n",
      "\n",
      "Epoch [22/59] phase: validA train loss: 0.0002 acc: 0.9907 valid loss: 0.1159 acc: 0.2879\n",
      "\n",
      "Epoch [22/59] phase: validB train loss: 0.0011 acc: 0.9445 valid loss: 0.0795 acc: 0.2539\n",
      "\n",
      "Epoch [22/59] phase: validC train loss: 0.0007 acc: 0.9742 valid loss: 0.0104 acc: 0.7033\n",
      "\n",
      "Epoch [22/59] phase: validC train loss: 0.0014 acc: 0.9441 valid loss: 0.0061 acc: 0.7520\n",
      "\n",
      "Epoch [23/59] phase: validA train loss: 0.0002 acc: 0.9904 valid loss: 0.1085 acc: 0.2889\n",
      "\n",
      "Epoch [23/59] phase: validB train loss: 0.0011 acc: 0.9489 valid loss: 0.0793 acc: 0.2528\n",
      "\n",
      "Epoch [23/59] phase: validC train loss: 0.0007 acc: 0.9733 valid loss: 0.0131 acc: 0.6624\n",
      "\n",
      "Epoch [23/59] phase: validC train loss: 0.0013 acc: 0.9545 valid loss: 0.0066 acc: 0.7365\n",
      "\n",
      "Epoch [24/59] phase: validA train loss: 0.0002 acc: 0.9921 valid loss: 0.1199 acc: 0.2892\n",
      "\n",
      "Epoch [24/59] phase: validB train loss: 0.0012 acc: 0.9416 valid loss: 0.0801 acc: 0.2512\n",
      "\n",
      "Epoch [24/59] phase: validC train loss: 0.0006 acc: 0.9755 valid loss: 0.0119 acc: 0.6897\n",
      "\n",
      "Epoch [24/59] phase: validC train loss: 0.0011 acc: 0.9643 valid loss: 0.0064 acc: 0.7486\n",
      "\n",
      "Epoch [25/59] phase: validA train loss: 0.0002 acc: 0.9899 valid loss: 0.1248 acc: 0.2889\n",
      "\n",
      "Epoch [25/59] phase: validB train loss: 0.0010 acc: 0.9506 valid loss: 0.0826 acc: 0.2525\n",
      "\n",
      "Epoch [25/59] phase: validC train loss: 0.0006 acc: 0.9774 valid loss: 0.0104 acc: 0.7109\n",
      "\n",
      "Epoch [25/59] phase: validC train loss: 0.0011 acc: 0.9614 valid loss: 0.0061 acc: 0.7613\n",
      "\n",
      "Epoch [26/59] phase: validA train loss: 0.0002 acc: 0.9904 valid loss: 0.1055 acc: 0.2898\n",
      "\n",
      "Epoch [26/59] phase: validB train loss: 0.0009 acc: 0.9557 valid loss: 0.0844 acc: 0.2543\n",
      "\n",
      "Epoch [26/59] phase: validC train loss: 0.0006 acc: 0.9762 valid loss: 0.0121 acc: 0.6732\n",
      "\n",
      "Epoch [26/59] phase: validC train loss: 0.0011 acc: 0.9618 valid loss: 0.0064 acc: 0.7488\n",
      "\n",
      "Epoch [27/59] phase: validA train loss: 0.0002 acc: 0.9913 valid loss: 0.1177 acc: 0.2893\n",
      "\n",
      "Epoch [27/59] phase: validB train loss: 0.0009 acc: 0.9577 valid loss: 0.0829 acc: 0.2539\n",
      "\n",
      "Epoch [27/59] phase: validC train loss: 0.0005 acc: 0.9786 valid loss: 0.0118 acc: 0.6841\n",
      "\n",
      "Epoch [27/59] phase: validC train loss: 0.0010 acc: 0.9621 valid loss: 0.0064 acc: 0.7515\n",
      "\n",
      "Epoch [28/59] phase: validA train loss: 0.0002 acc: 0.9913 valid loss: 0.1170 acc: 0.2901\n",
      "\n",
      "Epoch [28/59] phase: validB train loss: 0.0008 acc: 0.9596 valid loss: 0.0838 acc: 0.2568\n",
      "\n",
      "Epoch [28/59] phase: validC train loss: 0.0005 acc: 0.9803 valid loss: 0.0136 acc: 0.6782\n",
      "\n",
      "Epoch [28/59] phase: validC train loss: 0.0008 acc: 0.9737 valid loss: 0.0067 acc: 0.7443\n",
      "\n",
      "Epoch [29/59] phase: validA train loss: 0.0002 acc: 0.9920 valid loss: 0.1263 acc: 0.2903\n",
      "\n",
      "Epoch [29/59] phase: validB train loss: 0.0009 acc: 0.9620 valid loss: 0.0882 acc: 0.2513\n",
      "\n",
      "Epoch [29/59] phase: validC train loss: 0.0005 acc: 0.9786 valid loss: 0.0121 acc: 0.6785\n",
      "\n",
      "Epoch [29/59] phase: validC train loss: 0.0009 acc: 0.9714 valid loss: 0.0067 acc: 0.7463\n",
      "\n",
      "Epoch [30/59] phase: validA train loss: 0.0002 acc: 0.9926 valid loss: 0.1103 acc: 0.2897\n",
      "\n",
      "Epoch [30/59] phase: validB train loss: 0.0008 acc: 0.9634 valid loss: 0.0878 acc: 0.2554\n",
      "\n",
      "Epoch [30/59] phase: validC train loss: 0.0004 acc: 0.9829 valid loss: 0.0128 acc: 0.6782\n",
      "\n",
      "Epoch [30/59] phase: validC train loss: 0.0008 acc: 0.9742 valid loss: 0.0070 acc: 0.7344\n",
      "\n",
      "Epoch [31/59] phase: validA train loss: 0.0002 acc: 0.9915 valid loss: 0.1126 acc: 0.2905\n",
      "\n",
      "Epoch [31/59] phase: validB train loss: 0.0007 acc: 0.9662 valid loss: 0.0897 acc: 0.2561\n",
      "\n",
      "Epoch [31/59] phase: validC train loss: 0.0004 acc: 0.9827 valid loss: 0.0120 acc: 0.6973\n",
      "\n",
      "Epoch [31/59] phase: validC train loss: 0.0008 acc: 0.9703 valid loss: 0.0072 acc: 0.7383\n",
      "\n",
      "Epoch [32/59] phase: validA train loss: 0.0002 acc: 0.9928 valid loss: 0.1098 acc: 0.2899\n",
      "\n",
      "Epoch [32/59] phase: validB train loss: 0.0008 acc: 0.9642 valid loss: 0.0901 acc: 0.2550\n",
      "\n",
      "Epoch [32/59] phase: validC train loss: 0.0004 acc: 0.9814 valid loss: 0.0124 acc: 0.6785\n",
      "\n",
      "Epoch [32/59] phase: validC train loss: 0.0007 acc: 0.9739 valid loss: 0.0070 acc: 0.7380\n",
      "\n",
      "Epoch [33/59] phase: validA train loss: 0.0001 acc: 0.9943 valid loss: 0.1180 acc: 0.2897\n",
      "\n",
      "Epoch [33/59] phase: validB train loss: 0.0006 acc: 0.9712 valid loss: 0.0861 acc: 0.2556\n",
      "\n",
      "Epoch [33/59] phase: validC train loss: 0.0004 acc: 0.9834 valid loss: 0.0123 acc: 0.6853\n",
      "\n",
      "Epoch [33/59] phase: validC train loss: 0.0007 acc: 0.9759 valid loss: 0.0071 acc: 0.7360\n",
      "\n",
      "Epoch [34/59] phase: validA train loss: 0.0001 acc: 0.9946 valid loss: 0.1157 acc: 0.2892\n",
      "\n",
      "Epoch [34/59] phase: validB train loss: 0.0007 acc: 0.9670 valid loss: 0.0852 acc: 0.2568\n",
      "\n",
      "Epoch [34/59] phase: validC train loss: 0.0004 acc: 0.9846 valid loss: 0.0119 acc: 0.6978\n",
      "\n",
      "Epoch [34/59] phase: validC train loss: 0.0006 acc: 0.9768 valid loss: 0.0068 acc: 0.7520\n",
      "\n",
      "Epoch [35/59] phase: validA train loss: 0.0001 acc: 0.9947 valid loss: 0.1310 acc: 0.2891\n",
      "\n",
      "Epoch [35/59] phase: validB train loss: 0.0006 acc: 0.9728 valid loss: 0.0892 acc: 0.2556\n",
      "\n",
      "Epoch [35/59] phase: validC train loss: 0.0004 acc: 0.9844 valid loss: 0.0129 acc: 0.6748\n",
      "\n",
      "Epoch [35/59] phase: validC train loss: 0.0006 acc: 0.9796 valid loss: 0.0071 acc: 0.7391\n",
      "\n",
      "Epoch [36/59] phase: validA train loss: 0.0002 acc: 0.9935 valid loss: 0.1126 acc: 0.2898\n",
      "\n",
      "Epoch [36/59] phase: validB train loss: 0.0006 acc: 0.9714 valid loss: 0.0937 acc: 0.2549\n",
      "\n",
      "Epoch [36/59] phase: validC train loss: 0.0004 acc: 0.9828 valid loss: 0.0120 acc: 0.6896\n",
      "\n",
      "Epoch [36/59] phase: validC train loss: 0.0006 acc: 0.9798 valid loss: 0.0070 acc: 0.7413\n",
      "\n",
      "Epoch [37/59] phase: validA train loss: 0.0002 acc: 0.9927 valid loss: 0.1137 acc: 0.2912\n",
      "\n",
      "Epoch [37/59] phase: validB train loss: 0.0011 acc: 0.9518 valid loss: 0.0782 acc: 0.2528\n",
      "\n",
      "Epoch [37/59] phase: validC train loss: 0.0004 acc: 0.9849 valid loss: 0.0132 acc: 0.6725\n",
      "\n",
      "Epoch [37/59] phase: validC train loss: 0.0007 acc: 0.9735 valid loss: 0.0075 acc: 0.7305\n",
      "\n",
      "Epoch [38/59] phase: validA train loss: 0.0001 acc: 0.9956 valid loss: 0.1204 acc: 0.2911\n",
      "\n",
      "Epoch [38/59] phase: validB train loss: 0.0030 acc: 0.8618 valid loss: 0.0636 acc: 0.2452\n",
      "\n",
      "Epoch [38/59] phase: validC train loss: 0.0004 acc: 0.9849 valid loss: 0.0135 acc: 0.6739\n",
      "\n",
      "Epoch [38/59] phase: validC train loss: 0.0005 acc: 0.9846 valid loss: 0.0072 acc: 0.7349\n",
      "\n",
      "Epoch [39/59] phase: validA train loss: 0.0001 acc: 0.9949 valid loss: 0.1161 acc: 0.2902\n",
      "\n",
      "Epoch [39/59] phase: validB train loss: 0.0018 acc: 0.9160 valid loss: 0.0776 acc: 0.2530\n",
      "\n",
      "Epoch [39/59] phase: validC train loss: 0.0003 acc: 0.9880 valid loss: 0.0129 acc: 0.6836\n",
      "\n",
      "Epoch [39/59] phase: validC train loss: 0.0005 acc: 0.9827 valid loss: 0.0075 acc: 0.7306\n",
      "\n",
      "Epoch [40/59] phase: validA train loss: 0.0001 acc: 0.9964 valid loss: 0.1170 acc: 0.2895\n",
      "\n",
      "Epoch [40/59] phase: validB train loss: 0.0014 acc: 0.9346 valid loss: 0.1566 acc: 0.2463\n",
      "\n",
      "Epoch [40/59] phase: validC train loss: 0.0003 acc: 0.9871 valid loss: 0.0121 acc: 0.6883\n",
      "\n",
      "Epoch [40/59] phase: validC train loss: 0.0005 acc: 0.9822 valid loss: 0.0074 acc: 0.7330\n",
      "\n",
      "Epoch [41/59] phase: validA train loss: 0.0001 acc: 0.9943 valid loss: 0.1159 acc: 0.2912\n",
      "\n",
      "Epoch [41/59] phase: validB train loss: 0.0053 acc: 0.7441 valid loss: 0.0602 acc: 0.2161\n",
      "\n",
      "Epoch [41/59] phase: validC train loss: 0.0003 acc: 0.9867 valid loss: 0.0126 acc: 0.6851\n",
      "\n",
      "Epoch [41/59] phase: validC train loss: 0.0004 acc: 0.9867 valid loss: 0.0076 acc: 0.7275\n",
      "\n",
      "Epoch [42/59] phase: validA train loss: 0.0001 acc: 0.9942 valid loss: 0.1159 acc: 0.2901\n",
      "\n",
      "Epoch [42/59] phase: validB train loss: 0.0039 acc: 0.8094 valid loss: 0.0907 acc: 0.2302\n",
      "\n",
      "Epoch [42/59] phase: validC train loss: 0.0003 acc: 0.9870 valid loss: 0.0129 acc: 0.6810\n",
      "\n",
      "Epoch [42/59] phase: validC train loss: 0.0005 acc: 0.9830 valid loss: 0.0076 acc: 0.7300\n",
      "\n",
      "Epoch [43/59] phase: validA train loss: 0.0001 acc: 0.9948 valid loss: 0.1167 acc: 0.2900\n",
      "\n",
      "Epoch [43/59] phase: validB train loss: 0.0028 acc: 0.8623 valid loss: 0.0916 acc: 0.2455\n",
      "\n",
      "Epoch [43/59] phase: validC train loss: 0.0003 acc: 0.9899 valid loss: 0.0112 acc: 0.7187\n",
      "\n",
      "Epoch [43/59] phase: validC train loss: 0.0005 acc: 0.9836 valid loss: 0.0074 acc: 0.7442\n",
      "\n",
      "Epoch [44/59] phase: validA train loss: 0.0001 acc: 0.9953 valid loss: 0.1228 acc: 0.2894\n",
      "\n",
      "Epoch [44/59] phase: validB train loss: 0.0018 acc: 0.9106 valid loss: 0.0922 acc: 0.2476\n",
      "\n",
      "Epoch [44/59] phase: validC train loss: 0.0003 acc: 0.9894 valid loss: 0.0145 acc: 0.6623\n",
      "\n",
      "Epoch [44/59] phase: validC train loss: 0.0004 acc: 0.9873 valid loss: 0.0081 acc: 0.7187\n",
      "\n",
      "Epoch [45/59] phase: validA train loss: 0.0001 acc: 0.9945 valid loss: 0.1254 acc: 0.2896\n",
      "\n",
      "Epoch [45/59] phase: validB train loss: 0.0015 acc: 0.9299 valid loss: 0.0922 acc: 0.2500\n",
      "\n",
      "Epoch [45/59] phase: validC train loss: 0.0003 acc: 0.9891 valid loss: 0.0127 acc: 0.6865\n",
      "\n",
      "Epoch [45/59] phase: validC train loss: 0.0004 acc: 0.9856 valid loss: 0.0076 acc: 0.7322\n",
      "\n",
      "Epoch [46/59] phase: validA train loss: 0.0001 acc: 0.9946 valid loss: 0.1215 acc: 0.2896\n",
      "\n",
      "Epoch [46/59] phase: validB train loss: 0.0012 acc: 0.9442 valid loss: 0.0926 acc: 0.2535\n",
      "\n",
      "Epoch [46/59] phase: validC train loss: 0.0003 acc: 0.9887 valid loss: 0.0126 acc: 0.6913\n",
      "\n",
      "Epoch [46/59] phase: validC train loss: 0.0004 acc: 0.9842 valid loss: 0.0075 acc: 0.7402\n",
      "\n",
      "Epoch [47/59] phase: validA train loss: 0.0001 acc: 0.9968 valid loss: 0.1224 acc: 0.2908\n",
      "\n",
      "Epoch [47/59] phase: validB train loss: 0.0010 acc: 0.9512 valid loss: 0.0937 acc: 0.2497\n",
      "\n",
      "Epoch [47/59] phase: validC train loss: 0.0003 acc: 0.9885 valid loss: 0.0133 acc: 0.6836\n",
      "\n",
      "Epoch [47/59] phase: validC train loss: 0.0003 acc: 0.9878 valid loss: 0.0079 acc: 0.7327\n",
      "\n",
      "Epoch [48/59] phase: validA train loss: 0.0001 acc: 0.9968 valid loss: 0.1215 acc: 0.2899\n",
      "\n",
      "Epoch [48/59] phase: validB train loss: 0.0009 acc: 0.9552 valid loss: 0.0929 acc: 0.2533\n",
      "\n",
      "Epoch [48/59] phase: validC train loss: 0.0003 acc: 0.9892 valid loss: 0.0147 acc: 0.6582\n",
      "\n",
      "Epoch [48/59] phase: validC train loss: 0.0004 acc: 0.9861 valid loss: 0.0084 acc: 0.7159\n",
      "\n",
      "Epoch [49/59] phase: validA train loss: 0.0001 acc: 0.9947 valid loss: 0.1236 acc: 0.2894\n",
      "\n",
      "Epoch [49/59] phase: validB train loss: 0.0008 acc: 0.9605 valid loss: 0.0930 acc: 0.2513\n",
      "\n",
      "Epoch [49/59] phase: validC train loss: 0.0003 acc: 0.9897 valid loss: 0.0129 acc: 0.6846\n",
      "\n",
      "Epoch [49/59] phase: validC train loss: 0.0003 acc: 0.9865 valid loss: 0.0081 acc: 0.7232\n",
      "\n",
      "Epoch [50/59] phase: validA train loss: 0.0001 acc: 0.9959 valid loss: 0.1227 acc: 0.2905\n",
      "\n",
      "Epoch [50/59] phase: validB train loss: 0.0007 acc: 0.9659 valid loss: 0.0957 acc: 0.2514\n",
      "\n",
      "Epoch [50/59] phase: validC train loss: 0.0002 acc: 0.9930 valid loss: 0.0129 acc: 0.6985\n",
      "\n",
      "Epoch [50/59] phase: validC train loss: 0.0004 acc: 0.9844 valid loss: 0.0075 acc: 0.7486\n",
      "\n",
      "Epoch [51/59] phase: validA train loss: 0.0001 acc: 0.9971 valid loss: 0.1220 acc: 0.2911\n",
      "\n",
      "Epoch [51/59] phase: validB train loss: 0.0007 acc: 0.9692 valid loss: 0.0978 acc: 0.2534\n",
      "\n",
      "Epoch [51/59] phase: validC train loss: 0.0003 acc: 0.9893 valid loss: 0.0124 acc: 0.7018\n",
      "\n",
      "Epoch [51/59] phase: validC train loss: 0.0003 acc: 0.9880 valid loss: 0.0077 acc: 0.7407\n",
      "\n",
      "Epoch [52/59] phase: validA train loss: 0.0001 acc: 0.9961 valid loss: 0.1150 acc: 0.2904\n",
      "\n",
      "Epoch [52/59] phase: validB train loss: 0.0007 acc: 0.9693 valid loss: 0.0965 acc: 0.2535\n",
      "\n",
      "Epoch [52/59] phase: validC train loss: 0.0002 acc: 0.9903 valid loss: 0.0127 acc: 0.6954\n",
      "\n",
      "Epoch [52/59] phase: validC train loss: 0.0003 acc: 0.9878 valid loss: 0.0078 acc: 0.7383\n",
      "\n",
      "Epoch [53/59] phase: validA train loss: 0.0001 acc: 0.9968 valid loss: 0.1198 acc: 0.2890\n",
      "\n",
      "Epoch [53/59] phase: validB train loss: 0.0008 acc: 0.9626 valid loss: 0.0992 acc: 0.2531\n",
      "\n",
      "Epoch [53/59] phase: validC train loss: 0.0002 acc: 0.9904 valid loss: 0.0153 acc: 0.6653\n",
      "\n",
      "Epoch [53/59] phase: validC train loss: 0.0003 acc: 0.9880 valid loss: 0.0083 acc: 0.7246\n",
      "\n",
      "Epoch [54/59] phase: validA train loss: 0.0001 acc: 0.9968 valid loss: 0.1284 acc: 0.2906\n",
      "\n",
      "Epoch [54/59] phase: validB train loss: 0.0007 acc: 0.9691 valid loss: 0.0971 acc: 0.2556\n",
      "\n",
      "Epoch [54/59] phase: validC train loss: 0.0002 acc: 0.9906 valid loss: 0.0134 acc: 0.6889\n",
      "\n",
      "Epoch [54/59] phase: validC train loss: 0.0004 acc: 0.9832 valid loss: 0.0082 acc: 0.7343\n",
      "\n",
      "Epoch [55/59] phase: validA train loss: 0.0001 acc: 0.9965 valid loss: 0.1282 acc: 0.2903\n",
      "\n",
      "Epoch [55/59] phase: validB train loss: 0.0006 acc: 0.9732 valid loss: 0.0965 acc: 0.2554\n",
      "\n",
      "Epoch [55/59] phase: validC train loss: 0.0002 acc: 0.9902 valid loss: 0.0122 acc: 0.7014\n",
      "\n",
      "Epoch [55/59] phase: validC train loss: 0.0003 acc: 0.9857 valid loss: 0.0083 acc: 0.7299\n",
      "\n",
      "Epoch [56/59] phase: validA train loss: 0.0001 acc: 0.9964 valid loss: 0.1263 acc: 0.2893\n",
      "\n",
      "Epoch [56/59] phase: validB train loss: 0.0005 acc: 0.9762 valid loss: 0.0973 acc: 0.2528\n",
      "\n",
      "Epoch [56/59] phase: validC train loss: 0.0002 acc: 0.9908 valid loss: 0.0142 acc: 0.6827\n",
      "\n",
      "Epoch [56/59] phase: validC train loss: 0.0003 acc: 0.9876 valid loss: 0.0085 acc: 0.7246\n",
      "\n",
      "Epoch [57/59] phase: validA train loss: 0.0001 acc: 0.9954 valid loss: 0.1151 acc: 0.2896\n",
      "\n",
      "Epoch [57/59] phase: validB train loss: 0.0005 acc: 0.9795 valid loss: 0.0988 acc: 0.2549\n",
      "\n",
      "Epoch [57/59] phase: validC train loss: 0.0002 acc: 0.9903 valid loss: 0.0135 acc: 0.6843\n",
      "\n",
      "Epoch [57/59] phase: validC train loss: 0.0003 acc: 0.9880 valid loss: 0.0084 acc: 0.7252\n",
      "\n",
      "Epoch [58/59] phase: validA train loss: 0.0001 acc: 0.9959 valid loss: 0.1225 acc: 0.2900\n",
      "\n",
      "Epoch [58/59] phase: validB train loss: 0.0005 acc: 0.9784 valid loss: 0.0998 acc: 0.2554\n",
      "\n",
      "Epoch [58/59] phase: validC train loss: 0.0002 acc: 0.9927 valid loss: 0.0127 acc: 0.7029\n",
      "\n",
      "Epoch [58/59] phase: validC train loss: 0.0002 acc: 0.9905 valid loss: 0.0084 acc: 0.7263\n",
      "\n",
      "Epoch [59/59] phase: validA train loss: 0.0001 acc: 0.9971 valid loss: 0.1278 acc: 0.2909\n",
      "\n",
      "Epoch [59/59] phase: validB train loss: 0.0005 acc: 0.9785 valid loss: 0.1012 acc: 0.2550\n",
      "\n",
      "Epoch [59/59] phase: validC train loss: 0.0002 acc: 0.9912 valid loss: 0.0131 acc: 0.6838\n",
      "\n",
      "Epoch [59/59] phase: validC train loss: 0.0003 acc: 0.9862 valid loss: 0.0082 acc: 0.7345\n",
      "\n",
      "Best val Acc: 0.761300\n",
      "Training time: 154.943113 minutes\n"
     ]
    }
   ],
   "source": [
    "### Run decentralized pairwised knowledge transfer\n",
    "\n",
    "logging.info(\"#### bn acti conv and fc - unlimited bn - adam learning rate 0.001 - scheduler 20 - opt adamw ####\")\n",
    "\n",
    "start_time = time.time()\n",
    "model = train_model(dloaders, model, criterion, optimizer, exp_lr_scheduler, num_epochs=60)\n",
    "print('Training time: {:10f} minutes'.format((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0979,\n",
       " 0.5444,\n",
       " 0.6233000000000001,\n",
       " 0.6669,\n",
       " 0.6987,\n",
       " 0.7130000000000001,\n",
       " 0.7254,\n",
       " 0.7469,\n",
       " 0.7435,\n",
       " 0.7479,\n",
       " 0.7511,\n",
       " 0.7575000000000001,\n",
       " 0.758,\n",
       " 0.759,\n",
       " 0.7608,\n",
       " 0.749,\n",
       " 0.7533000000000001,\n",
       " 0.7404000000000001,\n",
       " 0.7492000000000001,\n",
       " 0.7554000000000001,\n",
       " 0.74,\n",
       " 0.7523000000000001,\n",
       " 0.752,\n",
       " 0.7365,\n",
       " 0.7486,\n",
       " 0.7613000000000001,\n",
       " 0.7488,\n",
       " 0.7515000000000001,\n",
       " 0.7443000000000001,\n",
       " 0.7463000000000001,\n",
       " 0.7344,\n",
       " 0.7383000000000001,\n",
       " 0.738,\n",
       " 0.736,\n",
       " 0.752,\n",
       " 0.7391000000000001,\n",
       " 0.7413000000000001,\n",
       " 0.7305,\n",
       " 0.7349,\n",
       " 0.7306,\n",
       " 0.733,\n",
       " 0.7275,\n",
       " 0.73,\n",
       " 0.7442000000000001,\n",
       " 0.7187,\n",
       " 0.7322000000000001,\n",
       " 0.7402000000000001,\n",
       " 0.7327,\n",
       " 0.7159,\n",
       " 0.7232000000000001,\n",
       " 0.7486,\n",
       " 0.7407,\n",
       " 0.7383000000000001,\n",
       " 0.7246,\n",
       " 0.7343000000000001,\n",
       " 0.7299,\n",
       " 0.7246,\n",
       " 0.7252000000000001,\n",
       " 0.7263000000000001,\n",
       " 0.7345]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reslist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ground - Generate confusion matrices of TP,FP,FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = torch.zeros(10, 10)\n",
    "for inputs, labels in dloaders['validC']:\n",
    "    inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    "\n",
    "    outputs = model['validC'](inputs)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    \n",
    "    for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[634.,   6.,  34.,   5.,  15.,   0.,  23.,  18., 165., 100.],\n",
      "        [  8., 736.,   0.,   1.,   0.,   1.,   8.,   0.,  79., 167.],\n",
      "        [ 39.,   0., 595.,  26.,  66.,  24., 156.,  54.,  27.,  13.],\n",
      "        [ 12.,   4.,  60., 349.,  38., 173., 197.,  96.,  34.,  37.],\n",
      "        [ 13.,   1.,  83.,  40., 588.,  12., 104., 127.,  19.,  13.],\n",
      "        [  3.,   1.,  50.,  78.,  31., 602.,  76., 124.,  12.,  23.],\n",
      "        [  1.,   0.,  10.,   9.,   7.,   5., 958.,   3.,   1.,   6.],\n",
      "        [  3.,   1.,   9.,  11.,   5.,  10.,   4., 939.,   7.,  11.],\n",
      "        [  6.,   2.,   0.,   2.,   3.,   1.,   4.,   1., 968.,  13.],\n",
      "        [  3.,  15.,   1.,   2.,   0.,   1.,   2.,   3.,  20., 953.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = torch.zeros(10, 10)\n",
    "for inputs, labels in dloaders['validC']:\n",
    "    inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    "\n",
    "    outputs = model['validC'](inputs)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    \n",
    "    for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[544.,   6.,  40.,   7.,  17.,   2.,  31.,  42., 224.,  87.],\n",
      "        [  5., 618.,   1.,   5.,   2.,   2.,  26.,   9.,  73., 259.],\n",
      "        [ 36.,   0., 449.,  49.,  64.,  24., 240., 101.,  27.,  10.],\n",
      "        [ 12.,   1.,  33., 404.,  22.,  97., 252., 117.,  38.,  24.],\n",
      "        [  4.,   1.,  34.,  29., 489.,  21., 164., 225.,  26.,   7.],\n",
      "        [  2.,   1.,  19., 128.,  16., 538., 108., 156.,  19.,  13.],\n",
      "        [  1.,   0.,   2.,   4.,   4.,   2., 981.,   6.,   0.,   0.],\n",
      "        [  3.,   0.,   1.,   8.,   5.,   5.,   5., 966.,   2.,   5.],\n",
      "        [  5.,   2.,   4.,   1.,   0.,   0.,   4.,   5., 968.,  11.],\n",
      "        [  0.,   4.,   1.,   3.,   0.,   2.,   3.,  10.,  20., 957.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with knowledge transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = torch.zeros(10, 10)\n",
    "for inputs, labels in dloaders['validC']:\n",
    "    inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    "\n",
    "    outputs = model['validC'](inputs)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    \n",
    "    for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[680.,   8.,  52.,   1.,   9.,   2.,  10.,  26., 128.,  84.],\n",
      "        [ 10., 730.,   0.,   3.,   0.,   2.,   9.,   4.,  38., 204.],\n",
      "        [ 64.,   3., 590.,  34.,  33.,  36., 141.,  60.,  21.,  18.],\n",
      "        [ 31.,   4.,  44., 374.,  26., 157., 176., 131.,  26.,  31.],\n",
      "        [ 33.,   1.,  60.,  35., 540.,  14., 114., 184.,  12.,   7.],\n",
      "        [ 13.,   2.,  41.,  80.,   9., 625.,  63., 135.,  13.,  19.],\n",
      "        [  3.,   1.,  11.,   6.,   6.,   4., 952.,   9.,   2.,   6.],\n",
      "        [  6.,   0.,   4.,   9.,   6.,   9.,   4., 941.,   8.,  13.],\n",
      "        [ 11.,   1.,   0.,   2.,   2.,   0.,   4.,   4., 959.,  17.],\n",
      "        [  3.,  14.,   1.,   3.,   0.,   0.,   1.,   5.,  19., 954.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
